package com.vlq.audioprocessor;

public interface AudioCaptureCallback {
    void onAudioDataCaptured(float[] audioData, int length);
}

И

package com.vlq.audioprocessor;

import android.app.Notification;
import android.app.NotificationChannel;
import android.app.NotificationManager;
import android.app.PendingIntent;
import android.app.Service;
import android.content.Context;
import android.content.Intent;
import android.media.AudioAttributes;
import android.media.AudioFormat;
import android.media.AudioManager;
import android.media.AudioPlaybackCaptureConfiguration;
import android.media.AudioRecord;
import android.media.AudioTrack;
import android.media.projection.MediaProjection;
import android.media.projection.MediaProjectionManager;
import android.os.Binder;
import android.os.Build;
import android.os.Handler;
import android.os.HandlerThread;
import android.os.IBinder;
import android.os.Process;
import android.util.Log;
import android.webkit.WebView;
import androidx.core.app.NotificationCompat;
import java.util.concurrent.atomic.AtomicBoolean;
import android.media.MediaRecorder;
import android.content.pm.ServiceInfo;

public class AudioProcessingService extends Service {
    private static final String TAG = "AudioProcessingService";
    private static final String CHANNEL_ID = "AudioProcessingChannel";
    private static final int NOTIFICATION_ID = 1;
    private static final int SAMPLE_RATE = 48000;
    private static final int BUFFER_SIZE_MULTIPLIER = 2;

    private MediaProjectionManager projectionManager;
    private MediaProjection mediaProjection;
    private AudioRecord audioRecord;
    private AudioProcessor audioProcessor;
    private AudioTrack audioTrack;
    private WebViewAudioCapture webViewAudioCapture;
    private AudioManager audioManager;
    
    private final IBinder binder = new LocalBinder();
    private final AtomicBoolean isProcessing = new AtomicBoolean(false);
    private final AtomicBoolean isInitialized = new AtomicBoolean(false);
    private int currentAudioSessionId = -1;

    private HandlerThread serviceThread;
    private Handler serviceHandler;
    private Thread processingThread;

    private static final int AUDIO_SESSION_INVALID = -1;
private final Object processLock = new Object();
    
    public class LocalBinder extends Binder {
        public AudioProcessingService getService() {
            return AudioProcessingService.this;
        }
    }

    @Override
public void onCreate() {
    super.onCreate();
    serviceThread = new HandlerThread("AudioServiceThread", Process.THREAD_PRIORITY_AUDIO);
    serviceThread.start();
    serviceHandler = new Handler(serviceThread.getLooper());

    serviceHandler.post(() -> {
        projectionManager = (MediaProjectionManager) getSystemService(Context.MEDIA_PROJECTION_SERVICE);
        audioManager = (AudioManager) getSystemService(Context.AUDIO_SERVICE);
        createNotificationChannel();
        startForeground(NOTIFICATION_ID, createNotification(), 
            ServiceInfo.FOREGROUND_SERVICE_TYPE_MEDIA_PLAYBACK 
            | ServiceInfo.FOREGROUND_SERVICE_TYPE_MEDIA_PROJECTION 
            | ServiceInfo.FOREGROUND_SERVICE_TYPE_DATA_SYNC);
    });
}
    
    private void initializeFallbackAudio() {
    try {
        // Базовая конфигурация
        int minBuffer = AudioRecord.getMinBufferSize(
            SAMPLE_RATE,
            AudioFormat.CHANNEL_IN_STEREO,
            AudioFormat.ENCODING_PCM_FLOAT
        );

        AudioFormat audioFormat = new AudioFormat.Builder()
            .setEncoding(AudioFormat.ENCODING_PCM_FLOAT)
            .setSampleRate(SAMPLE_RATE)
            .setChannelMask(AudioFormat.CHANNEL_IN_STEREO)
            .build();

        audioRecord = new AudioRecord.Builder()
            .setAudioFormat(audioFormat)
            .setBufferSizeInBytes(minBuffer * 2)
            .setAudioSource(MediaRecorder.AudioSource.VOICE_RECOGNITION)
            .build();

        if (audioRecord.getState() == AudioRecord.STATE_INITIALIZED) {
            audioRecord.startRecording();
        }
    } catch (Exception e) {
        Log.e(TAG, "Error in fallback audio init: " + e.getMessage());
    }
}
    
    private void initializeAudioSystem() {
    synchronized (processLock) {
        try {
            AudioAttributes attributes = new AudioAttributes.Builder()
                .setUsage(AudioAttributes.USAGE_MEDIA)
                .setContentType(AudioAttributes.CONTENT_TYPE_MUSIC)
                .setFlags(AudioAttributes.FLAG_LOW_LATENCY)
                .build();

            AudioFormat format = new AudioFormat.Builder()
                .setEncoding(AudioFormat.ENCODING_PCM_FLOAT)
                .setSampleRate(SAMPLE_RATE)
                .setChannelMask(AudioFormat.CHANNEL_OUT_STEREO)
                .build();

            int bufferSize = AudioTrack.getMinBufferSize(
                SAMPLE_RATE,
                AudioFormat.CHANNEL_OUT_STEREO,
                AudioFormat.ENCODING_PCM_FLOAT
            );

            audioTrack = new AudioTrack.Builder()
                .setAudioAttributes(attributes)
                .setAudioFormat(format)
                .setBufferSizeInBytes(bufferSize * 2)
                .setTransferMode(AudioTrack.MODE_STREAM)
                .setPerformanceMode(AudioTrack.PERFORMANCE_MODE_LOW_LATENCY)
                .setSessionId(currentAudioSessionId)
                .build();

            if (audioTrack.getState() == AudioTrack.STATE_INITIALIZED) {
                audioTrack.play();
                isInitialized.set(true);
            }

        } catch (Exception e) {
            Log.e(TAG, "Error initializing audio system: " + e.getMessage());
            initializeFallbackAudio();
        }
    }
}

    private void createNotificationChannel() {
        if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.O) {
            NotificationChannel channel = new NotificationChannel(
                CHANNEL_ID,
                "Audio Processing",
                NotificationManager.IMPORTANCE_LOW
            );
            channel.setSound(null, null);
            channel.setShowBadge(false);
            channel.enableVibration(false);
            channel.setLockscreenVisibility(Notification.VISIBILITY_PUBLIC);

            NotificationManager manager = getSystemService(NotificationManager.class);
            if (manager != null) {
                manager.createNotificationChannel(channel);
            }
        }
    }

    private Notification createNotification() {
        Intent notificationIntent = new Intent(this, MainActivity.class);
        notificationIntent.setFlags(Intent.FLAG_ACTIVITY_SINGLE_TOP);

        PendingIntent pendingIntent = PendingIntent.getActivity(
            this, 0, notificationIntent, 
            PendingIntent.FLAG_IMMUTABLE | PendingIntent.FLAG_UPDATE_CURRENT
        );

        NotificationCompat.Builder builder = new NotificationCompat.Builder(this, CHANNEL_ID)
            .setContentTitle("VLQ Audio Processor")
            .setContentText(isProcessing.get() ? "Processing audio..." : "Ready")
            .setSmallIcon(R.drawable.ic_launcher_foreground)
            .setPriority(NotificationCompat.PRIORITY_LOW)
            .setOngoing(true)
            .setContentIntent(pendingIntent)
            .setCategory(NotificationCompat.CATEGORY_SERVICE)
            .setVisibility(NotificationCompat.VISIBILITY_PUBLIC);

        if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.S) {
            builder.setForegroundServiceBehavior(
                NotificationCompat.FOREGROUND_SERVICE_IMMEDIATE
            );
        }

        return builder.build();
    }

    @Override
    public IBinder onBind(Intent intent) {
        return binder;
    }

    @Override
    public int onStartCommand(Intent intent, int flags, int startId) {
        if (intent != null) {
            final int resultCode = intent.getIntExtra("resultCode", -1);
            final Intent data = intent.getParcelableExtra("resultData");
            if (resultCode != -1 && data != null) {
                serviceHandler.post(() -> initializeMediaProjection(resultCode, data));
            }
        }
        return START_NOT_STICKY;
    }
    
    private void setupHyperOSOptimizations() {
    if (audioManager != null) {
        try {
            // Отключаем системные эффекты HyperOS
            audioManager.setParameters("SET_EFFECT_ENABLED=0");
            audioManager.setParameters("SET_SOUND_EFFECT=0");
            
            // Настраиваем прямой вывод
            audioManager.setParameters("SET_DIRECT_OUTPUT_PATH=1");
            audioManager.setParameters("SET_OFFLOAD_PLAYBACK=0");
            
            // Оптимизируем буферы
            int bufferSize = Math.max(4096, AudioTrack.getMinBufferSize(
                SAMPLE_RATE,
                AudioFormat.CHANNEL_OUT_STEREO,
                AudioFormat.ENCODING_PCM_FLOAT
            ));
            
            audioManager.setParameters("SET_BUFFER_SIZE=" + bufferSize);
            
            // Настраиваем аудио поток
            audioManager.setStreamVolume(AudioManager.STREAM_MUSIC, 0, 0);
            audioManager.setParameters("SET_AUDIO_TRACK_DIRECT=1");
            
        } catch (Exception e) {
            Log.e(TAG, "Error in setupHyperOSOptimizations: " + e.getMessage());
        }
    }
}

    private void setupMtkOptimizations() {
    if (audioManager != null) {
        try {
            audioManager.setParameters("MTK_AUDIO_PATH=fast");
            audioManager.setParameters("MTK_STREAM_TYPE=AUDIO_STREAM_DEEP_BUFFER");
            audioManager.setParameters("MTK_AUDIO_TRACK_DIRECT=0");
            audioManager.setParameters("MTK_AUDIO_LATENCY=1");
            audioManager.setParameters("MTK_AUDIO_PROCESSING=1");
            audioManager.setParameters("MTK_HIFI_AUDIO=1");
            audioManager.setParameters("MTK_AUDIO_32BIT=1");
            
            // Оптимизация буферов
            int bufferSize = Math.max(4096, AudioTrack.getMinBufferSize(
                SAMPLE_RATE,
                AudioFormat.CHANNEL_OUT_STEREO,
                AudioFormat.ENCODING_PCM_FLOAT
            ));
            
            audioManager.setParameters("MTK_AUDIO_BUFFER_SIZE=" + bufferSize);
        } catch (Exception e) {
            Log.e(TAG, "Error setting MTK parameters: " + e.getMessage());
        }
    }
}
    
    public synchronized void initializeMediaProjection(int resultCode, Intent data) {
        serviceHandler.post(() -> {
            try {
                if (projectionManager == null) {
                    projectionManager = (MediaProjectionManager) getSystemService(Context.MEDIA_PROJECTION_SERVICE);
                }
                
                if (mediaProjection == null) {
                    mediaProjection = projectionManager.getMediaProjection(resultCode, data);
                    if (mediaProjection != null) {
                        mediaProjection.registerCallback(new MediaProjection.Callback() {
                            @Override
                            public void onStop() {
                                serviceHandler.post(() -> stopSelf());
                            }
                        }, serviceHandler);
                        initializeAudioProcessor();
                    } else {
                        Log.e(TAG, "Failed to create MediaProjection");
                        stopSelf();
                    }
                }
            } catch (Exception e) {
                Log.e(TAG, "Error initializing MediaProjection: " + e.getMessage());
                stopSelf();
            }
        });
    }

    private void initializeAudioProcessor() {
    serviceHandler.post(() -> {
        try {
            if (!isInitialized.get() && mediaProjection != null) {
                // Генерация и проверка ID аудио сессии
                currentAudioSessionId = audioManager.generateAudioSessionId();
                if (currentAudioSessionId <= 0) {
                    throw new IllegalStateException("Не удалось сгенерировать валидный ID аудио сессии");
                }

                // Проверка состояния аудио
                if (audioManager.getStreamVolume(AudioManager.STREAM_MUSIC) == 0) {
                    Log.w(TAG, "Громкость STREAM_MUSIC установлена на 0");
                }
                
                // Создание и проверка AudioProcessor
                audioProcessor = new AudioProcessor(getApplicationContext());
                if (audioProcessor == null) {
                    throw new IllegalStateException("Не удалось создать AudioProcessor");
                }
                audioProcessor.attachToSession(currentAudioSessionId);

                // Конфигурация захвата аудио
                AudioPlaybackCaptureConfiguration config = new AudioPlaybackCaptureConfiguration.Builder(mediaProjection)
                    .addMatchingUsage(AudioAttributes.USAGE_MEDIA)
                    .addMatchingUsage(AudioAttributes.USAGE_GAME)
                    .addMatchingUsage(AudioAttributes.USAGE_UNKNOWN)
                    .build();

                AudioFormat audioFormat = new AudioFormat.Builder()
                    .setEncoding(AudioFormat.ENCODING_PCM_FLOAT)
                    .setSampleRate(SAMPLE_RATE)
                    .setChannelMask(AudioFormat.CHANNEL_IN_STEREO)
                    .build();

                // Расчет и проверка размера буфера
                int minBufferSize = AudioRecord.getMinBufferSize(
                    SAMPLE_RATE,
                    AudioFormat.CHANNEL_IN_STEREO,
                    AudioFormat.ENCODING_PCM_FLOAT
                );
                
                if (minBufferSize == AudioRecord.ERROR || minBufferSize == AudioRecord.ERROR_BAD_VALUE) {
                    throw new IllegalStateException("Формат аудио не поддерживается устройством");
                }
                
                int optimizedBufferSize = minBufferSize * BUFFER_SIZE_MULTIPLIER;

                // Создание AudioRecord с обработкой ошибок
                try {
                    audioRecord = new AudioRecord.Builder()
                        .setAudioFormat(audioFormat)
                        .setBufferSizeInBytes(optimizedBufferSize)
                        .setAudioPlaybackCaptureConfig(config)
                        .build();
                } catch (UnsupportedOperationException e) {
                    throw new IllegalStateException("Устройство не поддерживает необходимую конфигурацию AudioRecord", e);
                }

                // Настройка атрибутов аудио воспроизведения
                AudioAttributes attributes = new AudioAttributes.Builder()
                    .setUsage(AudioAttributes.USAGE_MEDIA)
                    .setContentType(AudioAttributes.CONTENT_TYPE_MUSIC)
                    .setFlags(AudioAttributes.FLAG_LOW_LATENCY)
                    .build();

                // Создание AudioTrack с обработкой ошибок
                try {
                    audioTrack = new AudioTrack.Builder()
                        .setAudioAttributes(attributes)
                        .setAudioFormat(audioFormat)
                        .setBufferSizeInBytes(optimizedBufferSize)
                        .setTransferMode(AudioTrack.MODE_STREAM)
                        .setPerformanceMode(AudioTrack.PERFORMANCE_MODE_LOW_LATENCY)
                        .setSessionId(currentAudioSessionId)
                        .build();
                } catch (UnsupportedOperationException e) {
                    throw new IllegalStateException("Устройство не поддерживает необходимую конфигурацию AudioTrack", e);
                }

                // Проверка инициализации компонентов
                if (audioRecord.getState() != AudioRecord.STATE_INITIALIZED) {
                    throw new IllegalStateException("AudioRecord не инициализирован");
                }
                
                if (audioTrack.getState() != AudioTrack.STATE_INITIALIZED) {
                    throw new IllegalStateException("AudioTrack не инициализирован");
                }

                // Запуск компонентов
                try {
                    audioRecord.startRecording();
                    audioTrack.play();
                } catch (IllegalStateException e) {
                    throw new IllegalStateException("Не удалось запустить аудио компоненты", e);
                }

                isInitialized.set(true);
                updateNotification();
                startAudioProcessingThread();
                Log.d(TAG, "Аудио компоненты успешно инициализированы. SessionId: " + currentAudioSessionId);
            }
        } catch (Exception e) {
            Log.e(TAG, "Ошибка инициализации AudioProcessor: " + e.getMessage());
            releaseResources();
            stopSelf();
        }
    });
}

private void initializeAudioComponents(AudioPlaybackCaptureConfiguration config) {
    synchronized (processLock) {
        try {
            if (currentAudioSessionId == AUDIO_SESSION_INVALID) {
                currentAudioSessionId = audioManager.generateAudioSessionId();
                if (currentAudioSessionId == AudioManager.ERROR) {
                    throw new IllegalStateException("Could not generate audio session ID");
                }
            }
            
            // Явно указываем ENCODING_PCM_FLOAT для обоих компонентов
            AudioFormat audioFormat = new AudioFormat.Builder()
                .setEncoding(AudioFormat.ENCODING_PCM_FLOAT) // Важно!
                .setSampleRate(48000)
                .setChannelMask(AudioFormat.CHANNEL_IN_STEREO)
                .build();

            int bufferSize = 12300;

            audioRecord = new AudioRecord.Builder()
                .setAudioFormat(audioFormat)
                .setBufferSizeInBytes(bufferSize)
                .setAudioPlaybackCaptureConfig(config)
                .build();

            if (audioRecord.getState() != AudioRecord.STATE_INITIALIZED) {
                throw new IllegalStateException("AudioRecord not initialized");
            }

            // Используем тот же формат для AudioTrack
            audioTrack = new AudioTrack.Builder()
                .setAudioAttributes(new AudioAttributes.Builder()
                    .setUsage(AudioAttributes.USAGE_MEDIA)
                    .setContentType(AudioAttributes.CONTENT_TYPE_MUSIC)
                    .setFlags(AudioAttributes.FLAG_LOW_LATENCY)
                    .build())
                .setAudioFormat(audioFormat) // Тот же формат!
                .setBufferSizeInBytes(bufferSize)
                .setTransferMode(AudioTrack.MODE_STREAM)
                .setPerformanceMode(AudioTrack.PERFORMANCE_MODE_LOW_LATENCY)
                .setSessionId(currentAudioSessionId)
                .build();

            if (audioTrack.getState() != AudioTrack.STATE_INITIALIZED) {
                throw new IllegalStateException("AudioTrack not initialized");
            }

            audioRecord.startRecording();
            audioTrack.play();
            
            isInitialized.set(true);

        } catch (Exception e) {
            Log.e(TAG, "Error in initializeAudioComponents: " + e.getMessage());
            releaseResources();
            throw new IllegalStateException("Failed to initialize audio components", e);
        }
    }
}
    
    private void startAudioProcessingThread() {
        if (processingThread != null && processingThread.isAlive()) {
            return;
        }

        processingThread = new Thread(() -> {
            android.os.Process.setThreadPriority(android.os.Process.THREAD_PRIORITY_URGENT_AUDIO);
            float[] buffer = new float[4096];
            
            while (!Thread.interrupted() && isInitialized.get()) {
                if (isProcessing.get() && audioRecord != null && audioTrack != null) {
                    int read = audioRecord.read(buffer, 0, buffer.length, AudioRecord.READ_BLOCKING);
                    if (read > 0) {
                        if (audioProcessor != null) {
                            audioProcessor.processAudio(buffer);
                        }
                        audioTrack.write(buffer, 0, read, AudioTrack.WRITE_BLOCKING);
                    }
                }
            }
        }, "AudioProcessingThread");
        
        processingThread.start();
    }


    public void startProcessing() {
    serviceHandler.post(() -> {
        if (!isInitialized.get()) {
            Log.e(TAG, "Cannot start processing - not initialized");
            return;
        }
        if (!isProcessing.get()) {
            isProcessing.set(true);
            if (audioProcessor != null) {
                audioProcessor.setProcessingEnabled(true);
            }
            if (webViewAudioCapture != null) {
                webViewAudioCapture.startCapture();
                // Блокируем системный звук
                if (audioManager != null) {
                    audioManager.setStreamVolume(AudioManager.STREAM_MUSIC, 0, 0);
                    audioManager.setStreamMute(AudioManager.STREAM_MUSIC, true);
                }
            }
            updateNotification();
        }
    });
}

    public void stopProcessing() {
        serviceHandler.post(() -> {
            if (isProcessing.get()) {
                isProcessing.set(false);
                if (audioProcessor != null) {
                    audioProcessor.setProcessingEnabled(false);
                }
                if (webViewAudioCapture != null) {
                    webViewAudioCapture.stopCapture();
                }
                updateNotification();
            }
        });
    }

    private void updateNotification() {
        NotificationManager notificationManager = getSystemService(NotificationManager.class);
        if (notificationManager != null) {
            notificationManager.notify(NOTIFICATION_ID, createNotification());
        }
    }

    private void releaseResources() {
        serviceHandler.post(() -> {
            if (processingThread != null) {
                processingThread.interrupt();
                try {
                    processingThread.join(1000);
                } catch (InterruptedException e) {
                    Log.e(TAG, "Error waiting for processing thread to finish", e);
                }
                processingThread = null;
            }

            if (audioRecord != null) {
                try {
                    if (audioRecord.getState() == AudioRecord.STATE_INITIALIZED) {
                        audioRecord.stop();
                    }
                } catch (IllegalStateException e) {
                    Log.e(TAG, "Error stopping AudioRecord: " + e.getMessage());
                } finally {
                    audioRecord.release();
                    audioRecord = null;
                }
            }

            if (audioTrack != null) {
                try {
                    if (audioTrack.getState() == AudioTrack.STATE_INITIALIZED) {
                        audioTrack.stop();
                    }
                } catch (IllegalStateException e) {
                    Log.e(TAG, "Error stopping AudioTrack: " + e.getMessage());
                } finally {
                    audioTrack.release();
                    audioTrack = null;
                }
            }

            if (audioProcessor != null) {
                audioProcessor.release();
                audioProcessor = null;
            }

            if (webViewAudioCapture != null) {
                webViewAudioCapture.release();
                webViewAudioCapture = null;
            }

            if (mediaProjection != null) {
                mediaProjection.stop();
                mediaProjection = null;
            }

            isProcessing.set(false);
            isInitialized.set(false);
        });
    }

    @Override
    public void onDestroy() {
        stopProcessing();
        releaseResources();
        
        if (serviceThread != null) {
            serviceThread.quitSafely();
            try {
                serviceThread.join(1000);
            } catch (InterruptedException e) {
                Log.e(TAG, "Error shutting down service thread", e);
            }
        }
        
        stopForeground(true);
        super.onDestroy();
    }

    @Override
    public void onTaskRemoved(Intent rootIntent) {
        stopSelf();
        super.onTaskRemoved(rootIntent);
    }

    public void updateAudioSession(int sessionId) {
        if (currentAudioSessionId != sessionId && audioProcessor != null) {
            currentAudioSessionId = sessionId;
            audioProcessor.attachToSession(sessionId);
        }
    }

    public void attachWebView(WebView webView) {
        if (webViewAudioCapture == null) {
            webViewAudioCapture = new WebViewAudioCapture(this, audioProcessor);
        }
        webViewAudioCapture.attachWebView(webView);
    }

    public boolean isProcessing() { return isProcessing.get(); }
    public boolean isInitialized() { return isInitialized.get(); }
    public boolean isMediaProjectionInitialized() { return mediaProjection != null; }
    public AudioProcessor getAudioProcessor() { return audioProcessor; }
    public int getCurrentAudioSessionId() { return currentAudioSessionId; }
}

И

package com.vlq.audioprocessor;

import android.content.Context;
import android.content.SharedPreferences;
import android.media.AudioFormat;
import android.media.AudioManager;
import android.media.AudioTrack;
import android.media.projection.MediaProjection;
import android.os.Handler;
import android.os.Looper;
import android.util.Log;
import android.webkit.WebView;

import java.nio.FloatBuffer;
import java.util.Arrays;
import java.util.Locale;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.LinkedBlockingQueue;
import java.util.concurrent.atomic.AtomicBoolean;
import android.media.AudioDeviceInfo;
import android.os.Build;
import android.os.Handler;
import android.os.Looper;
import android.webkit.WebView;
import android.media.AudioRecord;
import android.media.AudioAttributes;
import android.media.MediaRecorder;
import java.util.concurrent.atomic.AtomicInteger;
import android.media.MediaCodec;
import android.media.MediaFormat;
import android.content.pm.PackageManager;
import java.nio.file.Files;
import java.nio.file.Paths;
import android.util.LruCache;
import java.nio.ByteBuffer;

import android.media.AudioAttributes;

public class AudioProcessor implements AudioProcessorInterface {
    // Существующие определения оставляем без изменений
    private static final String TAG = "AudioProcessor";
    private static final String PREFS_NAME = "AudioProcessorState";
    private final ExecutorService audioInitExecutor = Executors.newSingleThreadExecutor();
    private static final int AUDIO_SESSION_INVALID = -1;
    
    private static final float[][] CHANNEL_MATRIX = {
    {0.866f, 0.134f}, // Front Left -> L/R
    {0.134f, 0.866f}, // Front Right -> L/R
    {0.5f, -0.5f},    // Rear Left с фазовым сдвигом
    {-0.5f, 0.5f},    // Rear Right с фазовым сдвигом
    {0.707f, 0.707f}  // Subwoofer моно
};

    // Добавляем только новые методы
    
    private boolean isPlaying = false;
    
    private AudioDriverType detectDriverType() {
    try {
        String hardware = Build.HARDWARE.toLowerCase();
        String processor = getProcCpuInfo();
        
        if (hardware.contains("mt") || hardware.contains("mediatek") || 
            processor.contains("mt") || processor.contains("mediatek")) {
            return AudioDriverType.MTK;
        } else if (hardware.contains("qcom") || hardware.contains("qualcomm") || 
                   processor.contains("qcom")) {
            return AudioDriverType.QUALCOMM;
        } else if (hardware.contains("samsung") || hardware.contains("exynos")) {
            return AudioDriverType.SAMSUNG;
        }
    } catch (Exception e) {
        Log.e(TAG, "Error detecting driver type: " + e.getMessage());
    }
    return AudioDriverType.GENERIC;
}

private String getProcCpuInfo() {
    try {
        return new String(Files.readAllBytes(Paths.get("/proc/cpuinfo"))).toLowerCase();
    } catch (Exception e) {
        return "";
    }
}
    
    private String getAudioDriverInfo() {
    StringBuilder info = new StringBuilder();
    try {
        if (audioManager != null) {
            String[] parameters = {
                "ro.hardware.audio",
                "ro.hardware.audio.primary",
                "ro.mtk.audio.platform",
                "audio.driver.status"
            };
            
            for (String param : parameters) {
                try {
                    String value = audioManager.getParameters(param);
                    if (value != null && !value.isEmpty()) {
                        info.append(param).append("=").append(value).append("\n");
                    }
                } catch (Exception e) {
                    Log.w(TAG, "Error getting parameter " + param + ": " + e.getMessage());
                }
            }
        }

        info.append("Sample rates supported:\n");
        for (int rate : new int[]{8000, 11025, 16000, 22050, 32000, 44100, 48000, 96000}) {
            int bufferSize = AudioTrack.getMinBufferSize(
                rate,
                AudioFormat.CHANNEL_OUT_STEREO,
                AudioFormat.ENCODING_PCM_16BIT
            );
            if (bufferSize > 0) {
                info.append(rate).append(" Hz\n");
            }
        }

        if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.JELLY_BEAN_MR1) {
            PackageManager pm = context.getPackageManager();
            boolean hasLowLatencyFeature = pm.hasSystemFeature(PackageManager.FEATURE_AUDIO_LOW_LATENCY);
            boolean hasProFeature = pm.hasSystemFeature(PackageManager.FEATURE_AUDIO_PRO);
            info.append("Low Latency support: ").append(hasLowLatencyFeature).append("\n");
            info.append("Pro Audio support: ").append(hasProFeature).append("\n");
        }

    } catch (Exception e) {
        Log.e(TAG, "Error getting audio driver info: " + e.getMessage());
    }
    
    return info.toString();
}

private boolean isMtkAudioDriver() {
    try {
        String hardware = Build.HARDWARE.toLowerCase();
        return hardware.contains("mt") || hardware.contains("mediatek");
    } catch (Exception e) {
        return false;
    }
}

    public void startPlayback() {
        if (audioTrack != null && !isPlaying) {
            audioTrack.play();
            isPlaying = true;
            processAudioStream();
        }
    }

    public void stopPlayback() {
        if (audioTrack != null && isPlaying) {
            isPlaying = false;
            audioTrack.stop();
            audioTrack.flush();
        }
    }

    private void processAudioStream() {
        new Thread(() -> {
            float[] tempBuffer = new float[1024];
            
            while (isPlaying) {
                try {
                    webInputBuffer.clear();
                    int samplesRead = Math.min(tempBuffer.length, webInputBuffer.remaining());
                    
                    if (samplesRead > 0) {
                        webInputBuffer.get(tempBuffer, 0, samplesRead);
                        
                        // Применяем матрицу каналов
                        float[] processedBuffer = applyChannelMatrix(tempBuffer, samplesRead);
                        
                        // Воспроизводим
                        audioTrack.write(processedBuffer, 0, processedBuffer.length, AudioTrack.WRITE_NON_BLOCKING);
                    }
                    
                    Thread.sleep(10);
                } catch (Exception e) {
                    Log.e(TAG, "Error in audio processing: " + e.getMessage());
                    break;
                }
            }
        }).start();
    }
    
    private enum AudioDriverType {
    MTK,
    QUALCOMM,
    SAMSUNG,
    GENERIC
}
private AudioDriverType driverType = AudioDriverType.GENERIC; // Значение по умолчанию

    // Добавьте обработчик регулировок с дебаунсингом
private final Handler volumeHandler = new Handler(Looper.getMainLooper());
private static final long VOLUME_UPDATE_DELAY = 50; // миллисекунды

@Override
public void setChannelVolume(int channel, float volume) {
    if (channel >= 0 && channel < channelVolumes.length) {
        volumeHandler.removeCallbacksAndMessages(null);
        volumeHandler.postDelayed(() -> {
            synchronized (processLock) {
                channelVolumes[channel] = Math.max(0.0f, Math.min(1.0f, volume));
                
                // Применяем изменения немедленно
                audioInitExecutor.execute(() -> {
                    try {
                        if (audioTrack != null && audioTrack.getState() == AudioTrack.STATE_INITIALIZED) {
                            float[] processedBuffer = processAudioData(lastBuffer, lastBuffer.length);
                            audioTrack.write(processedBuffer, 0, processedBuffer.length, 
                                AudioTrack.WRITE_NON_BLOCKING);
                        }
                    } catch (Exception e) {
                        Log.e(TAG, "Error updating volume: " + e.getMessage());
                    }
                });

                // Обновляем UI
                if (channelUpdateListener != null) {
                    float volumeDb = 20 * (float) Math.log10(Math.max(0.0001f, volume));
                    channelUpdateListener.onVolumeTextUpdated(channel, 
                        String.format(Locale.US, "%.1f dB", volumeDb));
                }
            }
        }, VOLUME_UPDATE_DELAY);
    }
}

// Аналогично для баса
@Override
public void setChannelBass(int channel, float bass) {
    if (channel >= 0 && channel < channelBass.length) {
        volumeHandler.removeCallbacksAndMessages(null);
        volumeHandler.postDelayed(() -> {
            synchronized (processLock) {
                channelBass[channel] = Math.max(0.0f, Math.min(1.0f, bass));
                
                // Применяем изменения немедленно
                audioInitExecutor.execute(() -> {
                    try {
                        if (audioTrack != null && audioTrack.getState() == AudioTrack.STATE_INITIALIZED) {
                            float[] processedBuffer = processAudioData(lastBuffer, lastBuffer.length);
                            audioTrack.write(processedBuffer, 0, processedBuffer.length, 
                                AudioTrack.WRITE_NON_BLOCKING);
                        }
                    } catch (Exception e) {
                        Log.e(TAG, "Error updating bass: " + e.getMessage());
                    }
                });

                if (channelUpdateListener != null) {
                    float bassDb = 20 * (float) Math.log10(Math.max(0.0001f, bass + 1.0f));
                    channelUpdateListener.onBassTextUpdated(channel, 
                        String.format(Locale.US, "%.1f dB", bassDb));
                }
            }
        }, VOLUME_UPDATE_DELAY);
    }
}

    
// Добавьте буфер для последних данных
private float[] lastBuffer = new float[0];

// Модифицируйте processAudioData
public float[] processAudioData(float[] input, int length) {
    if (!isProcessingEnabled.get() || input == null || length <= 0) {
        return input;
    }

    synchronized (processLock) {
        try {
            float[] output = new float[length];
            float[][] virtualChannels = new float[5][length/2];
            
            // Разделение на виртуальные каналы с учетом акустики салона
            for (int i = 0, j = 0; i < length; i += 2, j++) {
                float left = input[i];
                float right = input[i+1];
                
                // Фронтальные каналы с компенсацией расстояния
                virtualChannels[0][j] = left * 1.1f;  // Front Left (небольшое усиление)
                virtualChannels[1][j] = right * 1.1f; // Front Right
                
                // Тыловые каналы с задержкой и ослаблением высоких
                virtualChannels[2][j] = (left * 0.9f - right * 0.2f);  // Rear Left
                virtualChannels[3][j] = (right * 0.9f - left * 0.2f);  // Rear Right
                
                // Сабвуфер с учетом резонанса салона
                virtualChannels[4][j] = (left + right) * 0.7f;  // Sub (ослаблен для контроля)
            }

            // Обработка каждого канала с учетом акустических особенностей
            for (int ch = 0; ch < 5; ch++) {
                // Применяем фильтры с оптимизированными частотами
                if (channelLPF[ch]) {
                    for (int i = 0; i < virtualChannels[ch].length; i++) {
                        virtualChannels[ch][i] = lowPassFilters[ch].process(virtualChannels[ch][i]);
                    }
                }
                
                // Bass enhancement с учетом резонансов салона
                if (channelBass[ch] > 0) {
                    float bassAmount = channelBass[ch];
                    for (int i = 0; i < virtualChannels[ch].length; i++) {
                        float lowFreq = lowPassFilters[ch].process(virtualChannels[ch][i]);
                        // Прогрессивное усиление с ограничением
                        virtualChannels[ch][i] += lowFreq * bassAmount * 
                            (1.0f - Math.abs(virtualChannels[ch][i]) * 0.3f);
                    }
                }
                
                // Применяем громкость с компенсацией акустики
                float volume = channelVolumes[ch];
                if (ch < 4) { // Для основных каналов
                    volume *= (1.0f + Math.abs(virtualChannels[ch][0]) * 0.2f); // Динамическая компенсация
                }
                for (int i = 0; i < virtualChannels[ch].length; i++) {
                    virtualChannels[ch][i] *= volume;
                }
            }

            // Матричное микширование с учетом позиции слушателя
            for (int i = 0, j = 0; i < length; i += 2, j++) {
                float frontLeft = 0, frontRight = 0;
                float rearLeft = 0, rearRight = 0;
                
                for (int ch = 0; ch < 5; ch++) {
                    float sample = virtualChannels[ch][j];
                    frontLeft += sample * CHANNEL_MATRIX[ch][0];
                    frontRight += sample * CHANNEL_MATRIX[ch][1];
                    rearLeft += sample * CHANNEL_MATRIX[ch][2];
                    rearRight += sample * CHANNEL_MATRIX[ch][3];
                }
                
                // Финальное микширование с мягким клиппингом
                output[i] = softClip((frontLeft + rearLeft * 0.7f) * 0.7f);
                output[i + 1] = softClip((frontRight + rearRight * 0.7f) * 0.7f);
            }
            
            // Обновляем индикаторы уровня
            updateLevels(output);
            
            return output;
            
        } catch (Exception e) {
            Log.e(TAG, "Error processing car audio: " + e.getMessage());
            return input;
        }
    }
}
   
   private void setupAudioIsolation() {
    synchronized (processLock) {
        try {
            // Отключаем все системные аудиопотоки кроме нашего
            audioManager.setParameters("SET_FORCE_ROUTE=1");
            audioManager.setParameters("SET_AUDIO_PATH=processor");
            audioManager.setParameters("MTK_STREAM_TYPE=AUDIO_STREAM_PROC");
            audioManager.setParameters("SET_AUDIO_TRACK_DIRECT=1");
            
            // Блокируем другие источники звука
            audioManager.setParameters("SET_AUDIO_SOURCE_EXCLUSIVE=1");
            audioManager.setParameters("SET_AUDIO_OUTPUT_EXCLUSIVE=1");
            audioManager.setParameters("SET_AUDIO_FOCUS_EXCLUSIVE=1");
            
            // Отключаем все эффекты HyperOS
            audioManager.setParameters("SET_EFFECT_ENABLED=0");
            audioManager.setParameters("SET_SOUND_EFFECT=0");
            audioManager.setParameters("SET_AUDIO_EFFECT=0");
            audioManager.setParameters("MTK_AUDIO_TUNING_TOOL=1");
            
            // Настраиваем веб-аудио
            audioManager.setParameters("SET_WEBAUDIO_ENABLE=1");
            audioManager.setParameters("WebAudio_Stream_Control=1");
            audioManager.setParameters("MTK_WEB_AUDIO_PATH=1");
            
            // Принудительно отключаем все другие аудиопотоки
            for (int stream : new int[]{
                AudioManager.STREAM_ALARM,
                AudioManager.STREAM_DTMF,
                AudioManager.STREAM_NOTIFICATION,
                AudioManager.STREAM_RING,
                AudioManager.STREAM_SYSTEM,
                AudioManager.STREAM_VOICE_CALL
            }) {
                audioManager.setStreamMute(stream, true);
            }
            
        } catch (Exception e) {
            Log.e(TAG, "Error in setupAudioIsolation: " + e.getMessage());
        }
    }
}
     
    private void updateLevels(float[] buffer) {
    if (buffer == null || buffer.length == 0) return;
    
    try {
        // Расчет RMS для каждого канала
        float[] rms = new float[5];
        int samplesPerChannel = buffer.length / 2;
        
        // Фронтальные каналы
        for (int i = 0; i < buffer.length; i += 2) {
            rms[0] += buffer[i] * buffer[i];         // Front Left
            rms[1] += buffer[i + 1] * buffer[i + 1]; // Front Right
        }
        
        // Тыловые каналы и сабвуфер
        for (int i = 0; i < buffer.length; i += 2) {
            float left = buffer[i];
            float right = buffer[i + 1];
            
            float rearLeft = (left - right) * 0.7f;
            float rearRight = (right - left) * 0.7f;
            float sub = (left + right) * 0.5f;
            
            rms[2] += rearLeft * rearLeft;   // Rear Left
            rms[3] += rearRight * rearRight; // Rear Right
            rms[4] += sub * sub;             // Subwoofer
        }
        
        // Преобразуем в дБ
        for (int i = 0; i < 5; i++) {
            rms[i] = (float) Math.sqrt(rms[i] / samplesPerChannel);
            float db = 20 * (float) Math.log10(Math.max(rms[i], 1e-6f));
            channelLevels[i] = Math.max(MIN_DB, Math.min(MAX_DB, db));
        }
        
        // Обновляем UI через слушателя
        if (channelUpdateListener != null) {
            for (int i = 0; i < 5; i++) {
                channelUpdateListener.onChannelLevelChanged(i, channelLevels[i]);
            }
        }
        
    } catch (Exception e) {
        Log.e(TAG, "Error updating levels: " + e.getMessage());
    }
    
    private float[] processMatrixChannels(float[] input) {
    if (input == null || input.length == 0) return new float[0];
    
    try {
        float[] output = new float[input.length];
        float[][] virtualChannels = new float[5][input.length/2];
        
        // Разделение на виртуальные каналы с точным позиционированием
        for (int i = 0, j = 0; i < input.length; i += 2, j++) {
            float left = input[i];
            float right = input[i+1];
            
            // Фронтальные каналы с точным разделением
            virtualChannels[0][j] = left;  // Front Left
            virtualChannels[1][j] = right; // Front Right
            
            // Тыловые каналы с фазовым сдвигом и позиционированием
            virtualChannels[2][j] = (left - right * 0.3f) * 0.7f;  // Rear Left
            virtualChannels[3][j] = (right - left * 0.3f) * 0.7f;  // Rear Right
            
            // Сабвуфер с выделением низких частот
            virtualChannels[4][j] = (left + right) * 0.5f;  // Sub
        }

        // Обработка каждого канала с точным контролем
        for (int ch = 0; ch < 5; ch++) {
            // LPF с контролем резонанса
            if (channelLPF[ch] && lowPassFilters[ch] != null) {
                lowPassFilters[ch].setResonance(1.2f); // Легкий резонанс для лучшей слышимости
                for (int i = 0; i < virtualChannels[ch].length; i++) {
                    virtualChannels[ch][i] = lowPassFilters[ch].process(virtualChannels[ch][i]);
                }
            }
            
            // Bass enhancement с прогрессивной характеристикой
            if (channelBass[ch] > 0) {
                float bassAmount = channelBass[ch];
                for (int i = 0; i < virtualChannels[ch].length; i++) {
                    float lowFreq = lowPassFilters[ch].process(virtualChannels[ch][i]);
                    // Прогрессивное усиление баса
                    float bassGain = 1.0f + (bassAmount * (1.0f + Math.abs(lowFreq)));
                    virtualChannels[ch][i] = virtualChannels[ch][i] + (lowFreq * bassGain);
                }
            }
            
            // Точное управление громкостью с плавной характеристикой
            float volume = (float) Math.pow(channelVolumes[ch], 1.5); // Нелинейная характеристика
            for (int i = 0; i < virtualChannels[ch].length; i++) {
                virtualChannels[ch][i] *= volume;
            }
            
            // Обновляем уровни для UI
            float rms = calculateRMS(virtualChannels[ch]);
            channelLevels[ch] = convertToDb(rms);
        }

        // Матричное микширование с психоакустической коррекцией
        for (int i = 0, j = 0; i < input.length; i += 2, j++) {
            float leftOut = 0;
            float rightOut = 0;
            
            for (int ch = 0; ch < 5; ch++) {
                float sample = virtualChannels[ch][j];
                
                // Применяем матрицу с психоакустической коррекцией
                leftOut += sample * CHANNEL_MATRIX[ch][0];
                rightOut += sample * CHANNEL_MATRIX[ch][1];
            }
            
            // Финальное ограничение для предотвращения клиппинга
            output[i] = softClip(leftOut);
            output[i + 1] = softClip(rightOut);
        }
        
        return output;
        
    } catch (Exception e) {
        Log.e(TAG, "Error in processMatrixChannels: " + e.getMessage());
        return input;
    }
}

private float softClip(float sample) {
    if (sample > 1.0f) {
        return 1.0f - (1.0f / (sample + 1.0f));
    } else if (sample < -1.0f) {
        return -1.0f + (1.0f / (-sample + 1.0f));
    }
    return sample;
}
    
private void configureAudioInput() {
    try {
        // Отключаем микрофонный вход
        if (audioRecord != null) {
            audioRecord.stop();
            audioRecord.release();
            audioRecord = null;
        }
        
        // Отключаем микрофонную петлю
        if (audioManager != null) {
            audioManager.setParameters("agc_enable=0");
            audioManager.setParameters("aec_enable=0");
            audioManager.setParameters("ns_enable=0");
            audioManager.setParameters("mic_loopback=0");
            
            switch (driverType) {
                case MTK:
                    audioManager.setParameters("MTK_AUDIO_MIC_MUTE=1");
                    audioManager.setParameters("MTK_AUDIO_LOOPBACK=0");
                    break;
                case QUALCOMM:
                    audioManager.setParameters("audio_mic_disable=1");
                    audioManager.setParameters("audio_loopback_disable=1");
                    break;
                case SAMSUNG:
                    audioManager.setParameters("mic_mute=1");
                    audioManager.setParameters("loopback_mode=0");
                    break;
            }
        }
    } catch (Exception e) {
        Log.e(TAG, "Error configuring audio input: " + e.getMessage());
    }
}
    
    // Метод для обновления данных в буфере
    public void updateBuffer(float[] data) {
        webInputBuffer.clear();
        webInputBuffer.put(data, 0, Math.min(data.length, webInputBuffer.capacity()));
        webInputBuffer.flip();
    
};
    public void initialize() {
    audioInitExecutor.execute(() -> {
        try {
            // Определяем тип драйвера в фоновом потоке
            AudioDriverType detectedDriver = detectDriverType();
            
            // Переключаемся на главный поток для критических операций
            mainHandler.post(() -> {
                synchronized (processLock) {
                    try {
                        driverType = detectedDriver;
                        
                        // Отключаем микрофонный вход
                        configureAudioInput();
                        
                        // Инициализируем аудио с учетом драйвера
                        initializeAudioOutput();
                        
                        isProcessingEnabled.set(true);
                        startProcessingThreads();
                        
                        isInitialized.set(true);
                        Log.d(TAG, "AudioProcessor initialized successfully with " + driverType);
                        
                    } catch (Exception e) {
                        Log.e(TAG, "Error in initialize: " + e.getMessage());
                        isInitialized.set(false);
                    }
                }
            });
            
        } catch (Exception e) {
            Log.e(TAG, "Error in background initialization: " + e.getMessage());
            isInitialized.set(false);
        }
    });
}
        
private MediaCodec mediaCodec;

private void initializeAudioOutput() {
    synchronized (processLock) {
        try {
            releaseResources(); // Освобождаем ресурсы

            int sampleRate = getSampleRateForDriver(); // Получаем частоту
            int bufferSize = AudioTrack.getMinBufferSize(
                sampleRate,
                AudioFormat.CHANNEL_OUT_STEREO,
                AudioFormat.ENCODING_PCM_FLOAT
            );

            if (bufferSize == AudioTrack.ERROR || bufferSize == AudioTrack.ERROR_BAD_VALUE) {
                throw new IllegalArgumentException("Invalid buffer size");
            }

            AudioAttributes attributes = new AudioAttributes.Builder()
                .setUsage(AudioAttributes.USAGE_MEDIA)
                .setContentType(AudioAttributes.CONTENT_TYPE_MUSIC)
                .setFlags(AudioAttributes.FLAG_LOW_LATENCY)
                .build();

            AudioFormat format = new AudioFormat.Builder()
                .setEncoding(AudioFormat.ENCODING_PCM_FLOAT)
                .setSampleRate(sampleRate)
                .setChannelMask(AudioFormat.CHANNEL_OUT_STEREO)
                .build();

            audioTrack = new AudioTrack.Builder()
                .setAudioAttributes(attributes)
                .setAudioFormat(format)
                .setBufferSizeInBytes(bufferSize * 2) // Увеличиваем размер буфера
                .setTransferMode(AudioTrack.MODE_STREAM)
                .setPerformanceMode(AudioTrack.PERFORMANCE_MODE_LOW_LATENCY)
                .build();

            if (audioTrack.getState() == AudioTrack.STATE_INITIALIZED) {
                audioTrack.play();
            } else {
                Log.e(TAG, "AudioTrack not initialized");
            }

        } catch (Exception e) {
            Log.e(TAG, "Error initializing audio output: " + e.getMessage());
        }
    }
}

private int getPerformanceMode() {
    if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.N) {
        PackageManager pm = context.getPackageManager();
        if (pm.hasSystemFeature(PackageManager.FEATURE_AUDIO_PRO)) {
            return AudioTrack.PERFORMANCE_MODE_LOW_LATENCY;
        }
    }
    return AudioTrack.PERFORMANCE_MODE_NONE;
}

    private int getDefaultSampleRate() {
    return 44100;
}
    
private void releaseResources() {
    try {
        // Освобождаем AudioTrack
        if (audioTrack != null) {
            if (audioTrack.getPlayState() == AudioTrack.PLAYSTATE_PLAYING) {
                audioTrack.stop();
            }
            audioTrack.flush();
            audioTrack.release();
            audioTrack = null;
        }
        
        // Освобождаем MediaCodec
        if (mediaCodec != null) {
            try {
                mediaCodec.stop();
                mediaCodec.release();
            } catch (Exception e) {
                Log.e(TAG, "Error releasing MediaCodec: " + e.getMessage());
            }
            mediaCodec = null;
        }
        
    } catch (Exception e) {
        Log.e(TAG, "Error releasing resources: " + e.getMessage());
    }
}
    
    private float[] applyChannelMatrix(float[] buffer, int length) {
    float[] output = new float[length];
    
    for (int i = 0; i < length; i += 2) {
        float leftInput = buffer[i];
        float rightInput = (i + 1 < length) ? buffer[i + 1] : 0f;
        
        // Применяем матрицу микширования
        for (int ch = 0; ch < CHANNEL_MATRIX.length; ch++) {
            float left = leftInput * CHANNEL_MATRIX[ch][0];
            float right = rightInput * CHANNEL_MATRIX[ch][1];
            output[i + ch] = left + right;
        }
    }
    
    return output;
}

private int getSampleRateForDriver() {
    if (driverType == null) {
        driverType = AudioDriverType.GENERIC;
    }
        
        if (driverType == null) {
    return getDefaultSampleRate(); // или значение по умолчанию
}
    
    try {
        switch (driverType) {
            case MTK:
                return 48000; // Оптимально для MTK
            case QUALCOMM:
                return 48000; // Qualcomm лучше работает на 48kHz
            case SAMSUNG:
                return 44100; // Samsung предпочитает 44.1kHz
            case GENERIC:
            default:
                // Пробуем определить оптимальную частоту
                for (int rate : new int[]{48000, 44100, 16000}) {
                    int bufferSize = AudioTrack.getMinBufferSize(
                        rate,
                        AudioFormat.CHANNEL_OUT_STEREO,
                        AudioFormat.ENCODING_PCM_FLOAT
                    );
                    if (bufferSize > 0) {
                        return rate;
                    }
                }
                return 44100; // Безопасное значение по умолчанию
        }
    } catch (Exception e) {
        Log.e(TAG, "Error getting sample rate: " + e.getMessage());
        return 44100; // Безопасное значение при ошибке
    }
}

private int getOptimalBufferSize() {
    if (driverType == null) {
        driverType = AudioDriverType.GENERIC;
    }
    
    try {
        int sampleRate = getSampleRateForDriver();
        int minBuffer = AudioTrack.getMinBufferSize(
            sampleRate,
            AudioFormat.CHANNEL_OUT_STEREO,
            AudioFormat.ENCODING_PCM_FLOAT
        );
        
        switch (driverType) {
            case MTK:
                // MTK работает лучше с меньшими буферами
                return Math.max(1024, minBuffer);
                
            case QUALCOMM:
                // Qualcomm требует большего буфера для стабильности
                return Math.max(2048, minBuffer * 2);
                
            case SAMSUNG:
                // Samsung оптимален со средним размером
                return Math.max(1536, minBuffer);
                
            case GENERIC:
            default:
                // Для остальных увеличиваем минимальный буфер
                return Math.max(minBuffer * 2, 2048);
        }
    } catch (Exception e) {
        Log.e(TAG, "Error getting buffer size: " + e.getMessage());
        // Возвращаем безопасное значение при ошибке
        return 4096;
    }
}

private void initializeFallbackAudio() {
    try {
        releaseResources();
        
        // Самая базовая конфигурация
        int minBuffer = AudioTrack.getMinBufferSize(
            48000, // Используем 48000 Hz
            AudioFormat.CHANNEL_OUT_STEREO,
            AudioFormat.ENCODING_PCM_16BIT
        );

        audioTrack = new AudioTrack(
            AudioManager.STREAM_MUSIC,
            48000,
            AudioFormat.CHANNEL_OUT_STEREO,
            AudioFormat.ENCODING_PCM_16BIT,
            minBuffer * 4, // Увеличиваем буфер
            AudioTrack.MODE_STREAM
        );

        if (audioTrack != null && audioTrack.getState() == AudioTrack.STATE_INITIALIZED) {
            audioTrack.play();
        }
    } catch (Exception e) {
        Log.e(TAG, "Error in fallback audio initialization: " + e.getMessage());
        throw new RuntimeException("Could not initialize audio", e);
    }
}


    
    private void initializeAudioSystem() {
    synchronized (processLock) {
        try {
            // Инициализация аудио компонентов
            initializeAudioOutput();
            initializeWebAudioEngine(); // Используем существующий метод
            setupMtkOptimizations();
            
            // Запуск обработчиков
            startProcessingThreads();
            startUIUpdates();
            
            isInitialized.set(true); // Используем AtomicBoolean
            Log.d(TAG, "Audio system initialized successfully");
            
        } catch (Exception e) {
            Log.e(TAG, "Error initializing audio system: " + e.getMessage());
            reinitializeAudioOutput();
        }
    }
}
    
    private void reinitializeAudioTrack() {
    synchronized (processingLock) {
        try {
            if (audioTrack != null) {
                audioTrack.stop();
                audioTrack.flush();
                audioTrack.release();
            }

            int minBuffer = AudioTrack.getMinBufferSize(
                SAMPLE_RATE,
                AudioFormat.CHANNEL_OUT_STEREO,
                AudioFormat.ENCODING_PCM_FLOAT
            );

            AudioAttributes attributes = new AudioAttributes.Builder()
                .setUsage(AudioAttributes.USAGE_MEDIA)
                .setContentType(AudioAttributes.CONTENT_TYPE_MUSIC)
                .setFlags(AudioAttributes.FLAG_LOW_LATENCY)
                .build();

            AudioFormat format = new AudioFormat.Builder()
                .setEncoding(AudioFormat.ENCODING_PCM_FLOAT)
                .setSampleRate(SAMPLE_RATE)
                .setChannelMask(AudioFormat.CHANNEL_OUT_STEREO)
                .build();

            audioTrack = new AudioTrack.Builder()
                .setAudioAttributes(attributes)
                .setAudioFormat(format)
                .setBufferSizeInBytes(minBuffer * 2)
                .setTransferMode(AudioTrack.MODE_STREAM)
                .setPerformanceMode(AudioTrack.PERFORMANCE_MODE_LOW_LATENCY)
                .setSessionId(audioManager.generateAudioSessionId())
                .build();

            if (audioTrack.getState() == AudioTrack.STATE_INITIALIZED) {
                audioTrack.play();
            }
        } catch (Exception e) {
            Log.e(TAG, "Error in reinitializeAudioTrack: " + e.getMessage());
        }
    }
}

public void reinitializeAudioOutput() {
    synchronized (processLock) {
        try {
            if (audioTrack != null) {
                audioTrack.stop();
                audioTrack.flush();
                audioTrack.release();
            }

            setupMtkAudioRouting();

            // Восстановление состояния обработки
            if (isProcessingEnabled.get()) {
                if (audioTrack != null && audioTrack.getState() == AudioTrack.STATE_INITIALIZED) {
                    audioTrack.play();
                }
            }
        } catch (Exception e) {
            Log.e(TAG, "Error reinitializing audio output: " + e.getMessage());
        }
    }
}

    private void setupHyperOSAudio() {
    try {
        // Настройки для HyperOS
        audioManager.setParameters("SET_DIRECT_OUTPUT_PATH=1");
        audioManager.setParameters("SET_OFFLOAD_PLAYBACK=0");
        audioManager.setParameters("SET_AUDIO_TRACK_DIRECT=1");
        
        // Отключаем системные эффекты
        audioManager.setParameters("SET_EFFECT_ENABLED=0");
        audioManager.setParameters("SET_SOUND_EFFECT=0");
        audioManager.setParameters("SET_AUDIO_EFFECT=0");
        
        // Оптимизация буферов
        int bufferSize = Math.max(4096, AudioTrack.getMinBufferSize(
            SAMPLE_RATE,
            AudioFormat.CHANNEL_OUT_STEREO,
            AudioFormat.ENCODING_PCM_FLOAT
        ));
        
        audioManager.setParameters("SET_BUFFER_SIZE=" + bufferSize);
        audioManager.setParameters("SET_AUDIO_BUFFER_SIZE=" + bufferSize);
        
    } catch (Exception e) {
        Log.e(TAG, "Error in setupHyperOSAudio: " + e.getMessage());
    }
}
    
private void setupMtkOptimizations() {
    if (audioManager != null) {
        try {
            audioManager.setParameters("MTK_AUDIO_PATH=processor");
audioManager.setParameters("SET_FORCE_ROUTE=1"); 
audioManager.setParameters("MTK_STREAM_TYPE=AUDIO_STREAM_PROC");
audioManager.setParameters("SET_WEBAUDIO_ENABLE=1");
audioManager.setParameters("WebAudio_Stream_Control=1");
            
            // Оптимизация буферов
            int bufferSize = Math.max(4096, AudioTrack.getMinBufferSize(
                SAMPLE_RATE,
                AudioFormat.CHANNEL_OUT_STEREO,
                AudioFormat.ENCODING_PCM_FLOAT
            ));
            
            audioManager.setParameters("MTK_AUDIO_BUFFER_SIZE=" + bufferSize);
        } catch (Exception e) {
            Log.e(TAG, "Error setting MTK parameters: " + e.getMessage());
        }
    }
}
    
    private void initializeHyperOSAudio() {
    synchronized (processLock) {
        try {
            // Настройка оптимального пути аудио для HyperOS
            audioManager.setParameters("SET_AUDIO_HAL_DIRECT=1");
            audioManager.setParameters("SET_AUDIO_TRACK_DIRECT=1");
            audioManager.setParameters("SET_AUDIO_PATH_DIRECT=1");
            audioManager.setParameters("SET_AUDIO_OFFLOAD=0");
            audioManager.setParameters("SET_AUDIO_LOW_LATENCY=1");
            audioManager.setParameters("SET_AUDIO_DEEP_BUFFER=0");
            
            // Отключаем системные эффекты HyperOS
            audioManager.setParameters("SET_EFFECT_ENABLED=0");
            audioManager.setParameters("SET_SOUND_EFFECT=0");
            audioManager.setParameters("SET_AUDIO_EFFECT=0");
            audioManager.setParameters("SET_AUDIO_PROCESSING=1");
            
            // Настройка MediaTek параметров
            audioManager.setParameters("MTK_AUDIO_TUNING_TOOL=1");
            audioManager.setParameters("MTK_AUDIO_32BIT=1");
            audioManager.setParameters("MTK_AUDIO_PATCH=DIRECT");
            audioManager.setParameters("MTK_AUDIO_RAW_DATA_MODE=1");
            audioManager.setParameters("MTK_AUDIO_DEEP_BUFFER=0");
            audioManager.setParameters("MTK_WEB_AUDIO_PATH=1");
            audioManager.setParameters("SET_WEBAUDIO_ENABLE=1");
            audioManager.setParameters("WebAudio_Stream_Control=1");

            // Оптимальный размер буфера
            int bufferSize = 12300; // Оптимальное значение для MediaTek
            
            AudioAttributes attributes = new AudioAttributes.Builder()
                .setUsage(AudioAttributes.USAGE_MEDIA)
                .setContentType(AudioAttributes.CONTENT_TYPE_MUSIC)
                .setFlags(AudioAttributes.FLAG_LOW_LATENCY)
                .build();

            AudioFormat format = new AudioFormat.Builder()
                .setEncoding(AudioFormat.ENCODING_PCM_FLOAT)
                .setSampleRate(48000)
                .setChannelMask(AudioFormat.CHANNEL_OUT_STEREO)
                .build();

            audioTrack = new AudioTrack.Builder()
                .setAudioAttributes(attributes)
                .setAudioFormat(format)
                .setBufferSizeInBytes(bufferSize)
                .setTransferMode(AudioTrack.MODE_STREAM)
                .setPerformanceMode(AudioTrack.PERFORMANCE_MODE_LOW_LATENCY)
                .setSessionId(currentAudioSessionId)
                .build();

            if (audioTrack.getState() == AudioTrack.STATE_INITIALIZED) {
                audioTrack.play();
                isInitialized.set(true);
                
                // Проверяем и устанавливаем громкость
                if (audioManager.getStreamVolume(AudioManager.STREAM_MUSIC) > 0) {
                    audioManager.setStreamVolume(AudioManager.STREAM_MUSIC, 0, 0);
                }
                
                Log.d(TAG, "HyperOS audio initialized successfully");
            }

        } catch (Exception e) {
            Log.e(TAG, "Error initializing HyperOS audio: " + e.getMessage());
            initializeFallbackAudio();
        }
    }
}

private void startProcessingThreads() {
    audioProcessingExecutor.execute(() -> {
        while (isProcessingEnabled.get()) {
            try {
                FloatBuffer buffer = processingQueue.take();
                if (buffer != null) {
                    processAudioData(buffer.array(), buffer.remaining());
                }
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
                break;
            } catch (Exception e) {
                Log.e(TAG, "Error in processing thread: " + e.getMessage());
            }
        }
    });

    webProcessingExecutor.execute(() -> {
        while (isWebProcessingEnabled.get()) {
            try {
                FloatBuffer buffer = webProcessingQueue.take();
                if (buffer != null) {
                    processWebAudio(buffer.array(), buffer.remaining());
                }
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
                break;
            } catch (Exception e) {
                Log.e(TAG, "Error in web processing thread: " + e.getMessage());
            }
        }
    });
}

    public void processWebAudio(float[] buffer, int length) {
    if (!isProcessingEnabled.get() || buffer == null || length == 0) return;

    synchronized (processLock) {
        try {
            // Обработка через матричный процессор
            float[] processedData = processAudioData(buffer, length);
            
            // Отправляем напрямую в аудио выход
            if (audioTrack != null && audioTrack.getPlayState() == AudioTrack.PLAYSTATE_PLAYING) {
                int written = audioTrack.write(processedData, 0, processedData.length, 
                    AudioTrack.WRITE_NON_BLOCKING);
                    
                if (written < 0) {
                    Log.e(TAG, "Error writing to AudioTrack: " + written);
                    reinitializeAudioOutput();
                }
            }
        } catch (Exception e) {
            Log.e(TAG, "Error in processWebAudio: " + e.getMessage());
            handleProcessingError();
        }
    }
}
    
private void handleProcessingError() {
    if (errorCount.incrementAndGet() > MAX_ERRORS) {
        reinitializeAudioOutput();
        errorCount.set(0);
    }
}

private void handleWebProcessingError() {
    if (webErrorCount.incrementAndGet() > MAX_ERRORS) {
        reinitializeWebAudio();
        webErrorCount.set(0);
    }
}
    private void reinitializeWebAudio() {
    synchronized (processLock) {
        try {
            // Очищаем очереди
            webProcessingQueue.clear();
            
            // Перезапускаем веб-аудио компоненты
            if (webEngine != null) {
                webEngine.stopProcessing();
                webEngine.release();
                webEngine = null;
            }
            
            initializeWebAudioEngine();
            
            // Перезапускаем обработку если была активна
            if (isWebProcessingEnabled.get()) {
                startWebAudioProcessing();
            }
            
        } catch (Exception e) {
            Log.e(TAG, "Error reinitializing web audio: " + e.getMessage());
        }
    }
}

private void startWebAudioProcessing() {
    if (webEngine != null) {
        webEngine.startProcessing();
        setWebAudioEnabled(true);
    }
}


private float[] processVirtualChannels(float[] input) {
    if (input == null || input.length == 0) return new float[0];
    
    try {
        float[] output = new float[input.length];
        float[][] channels = new float[5][input.length/2];
        
        // Разделение на виртуальные каналы
        for (int i = 0, j = 0; i < input.length; i += 2, j++) {
            float left = input[i];
            float right = input[i + 1];
            
            channels[0][j] = left;  // FL
            channels[1][j] = right; // FR
            channels[2][j] = (left - right) * 0.7f;  // RL
            channels[3][j] = (right - left) * 0.7f;  // RR
            channels[4][j] = (left + right) * 0.5f;  // SUB
        }

        // Обработка каждого канала
        for (int ch = 0; ch < 5; ch++) {
            // LPF фильтрация
            if (channelLPF[ch] && lowPassFilters[ch] != null) {
                for (int i = 0; i < channels[ch].length; i++) {
                    channels[ch][i] = lowPassFilters[ch].process(channels[ch][i]);
                }
            }
            
            // Bass Boost
            if (channelBass[ch] > 0) {
                float bassAmount = channelBass[ch];
                for (int i = 0; i < channels[ch].length; i++) {
                    float lowFreq = lowPassFilters[ch].process(channels[ch][i]);
                    channels[ch][i] = channels[ch][i] + (lowFreq * bassAmount);
                }
            }
            
            // Применяем громкость
            float volume = channelVolumes[ch];
            for (int i = 0; i < channels[ch].length; i++) {
                channels[ch][i] *= volume;
            }
        }

        // Микширование в стерео
        for (int i = 0, j = 0; i < input.length; i += 2, j++) {
            float leftOut = 0;
            float rightOut = 0;
            
            for (int ch = 0; ch < 5; ch++) {
                leftOut += channels[ch][j] * CHANNEL_MATRIX[ch][0];
                rightOut += channels[ch][j] * CHANNEL_MATRIX[ch][1];
            }
            
            output[i] = leftOut;
            output[i + 1] = rightOut;
        }

        // Обновляем уровни для UI
        updateLevels(output);
        
        return output;
        
    } catch (Exception e) {
        Log.e(TAG, "Error in processVirtualChannels: " + e.getMessage());
        return input;
    }
}
    
    
    private static class LowPassFilter {
        private float cutoff;
        private float resonance;
        private float[] buf = new float[4];
        private MediaCodec mediaCodec;
        
        public LowPassFilter() {
            this.cutoff = 0.99f;
            this.resonance = 0.0f;
        }
        
        public void setCutoff(float cutoff) {
            this.cutoff = Math.max(0.0f, Math.min(0.99f, cutoff));
        }
        
        public float getCutoff() {
            return cutoff;
        }
        
        public void setResonance(float resonance) {
            this.resonance = Math.max(0.0f, Math.min(4.0f, resonance));
        }
        
        public float process(float input) {
            float f = cutoff * 1.16f;
            float fb = resonance * (1.0f - 0.15f * f * f);
            
            buf[0] = buf[0] + f * (input - buf[0] + fb * (buf[0] - buf[1]));
            buf[1] = buf[1] + f * (buf[0] - buf[1]);
            buf[2] = buf[2] + f * (buf[1] - buf[2]);
            buf[3] = buf[3] + f * (buf[2] - buf[3]);
            
            return buf[3];
        }
    }
    
    private float processSpatial(float sample, int channel) {
    // Создаем буфер для одного сэмпла
    float[] input = new float[1];
    input[0] = sample;
    
    // Задержка для тыловых каналов
    int delay = (channel == 2) ? 441 : 882; // 10мс и 20мс при 44.1кГц
    
    // Применяем HRTF фильтрацию
    float[] processed = hrtfProcessor.process(
        input,
        (channel == 2) ? -30.0f : 30.0f, // Угол для левого/правого тыла
        0.0f  // Добавляем третий параметр - высоту
    );
    
    // Добавляем реверберацию для пространственности
    float spatialSample = spatialProcessors[channel].process(
        processed[0], 
        (channel == 2) ? -0.7f : 0.7f
    );
    
    return spatialSample;
}

private float processFilters(float sample, int channel) {
    // Применяем фильтры если включены
    if (channelLPF[channel]) {
        sample = lowPassFilters[channel].process(sample);
    }
    
    // Применяем усиление баса
    if (channelBass[channel] > 0) {
        float bassAmount = channelBass[channel];
        float lowFreq = lowPassFilters[channel].process(sample);
        sample = sample + (lowFreq * bassAmount);
    }
    
    // Применяем громкость канала
    return sample * channelVolumes[channel];
}
    
    // Добавляем переменную для хранения системной громкости
    private float systemVolume = 1.0f;
    
   


@Override
public void setChannelLPF(int channel, boolean enabled) {
    if (channel >= 0 && channel < channelLPF.length) {
        synchronized (processLock) {
            channelLPF[channel] = enabled;
            if (lowPassFilters[channel] != null) {
                lowPassFilters[channel].setEnabled(enabled);
            }
            if (channelUpdateListener != null) {
                channelUpdateListener.onLPFStateUpdated(channel, enabled);
            }
        }
    }
}

@Override
public float getChannelLevel(int channel) {
    if (channel >= 0 && channel < channelLevels.length) {
        synchronized (uiUpdateLock) {
            return channelLevels[channel];
        }
    }
    return MIN_DB;
}

@Override
public float getChannelVolume(int channel) {
    if (channel >= 0 && channel < channelVolumes.length) {
        synchronized (processLock) {
            return channelVolumes[channel];
        }
    }
    return 1.0f;
}

@Override
public float getChannelBass(int channel) {
    if (channel >= 0 && channel < channelBass.length) {
        synchronized (processLock) {
            return channelBass[channel];
        }
    }
    return 0.0f;
}

@Override
public boolean getChannelLPF(int channel) {
    if (channel >= 0 && channel < channelLPF.length) {
        synchronized (processLock) {
            return channelLPF[channel];
        }
    }
    return false;
}

@Override
public float[] getChannelVolumes() {
    synchronized (processLock) {
        return channelVolumes.clone();
    }
}

@Override
public float[] getChannelBassLevels() {
    synchronized (processLock) {
        return channelBass.clone();
    }
}

@Override
public boolean[] getChannelLPFStates() {
    synchronized (processLock) {
        return channelLPF.clone();
    }
}

@Override
public void attachToSession(int sessionId) {
    synchronized (processLock) {
        if (currentAudioSessionId != sessionId) {
            currentAudioSessionId = sessionId;
            
            if (audioTrack != null) {
                audioTrack.release();
            }
            
            initializeAudioOutput();
            
        }
    }
}

@Override
public void setProcessingEnabled(boolean enabled) {
    boolean wasEnabled = isProcessingEnabled.get();
    isProcessingEnabled.set(enabled);
    
    if (enabled && !wasEnabled) {
        if (audioTrack != null && audioTrack.getPlayState() != AudioTrack.PLAYSTATE_PLAYING) {
            audioTrack.play();
        }
        startUIUpdates();
    } else if (!enabled && wasEnabled) {
        if (audioTrack != null) {
            audioTrack.pause();
            audioTrack.flush();
        }
        mainHandler.removeCallbacks(uiUpdateRunnable);
    }
}

@Override
public void saveProcessingState() {
    synchronized (processLock) {
        SharedPreferences.Editor editor = preferences.edit();
        
        for (int i = 0; i < 5; i++) {
            editor.putFloat("volume_" + i, channelVolumes[i]);
            editor.putFloat("bass_" + i, channelBass[i]);
            editor.putBoolean("lpf_" + i, channelLPF[i]);
        }
        
        editor.putBoolean("processing_enabled", isProcessingEnabled.get());
        editor.putBoolean("web_audio_enabled", isWebAudioEnabled.get());
        
        editor.apply();
    }
}

@Override
public void restoreProcessingState() {
    synchronized (processLock) {
        for (int i = 0; i < 5; i++) {
            channelVolumes[i] = preferences.getFloat("volume_" + i, 1.0f);
            channelBass[i] = preferences.getFloat("bass_" + i, 0.0f);
            channelLPF[i] = preferences.getBoolean("lpf_" + i, false);
            
            if (lowPassFilters[i] != null) {
                lowPassFilters[i].setEnabled(channelLPF[i]);
            }
        }
        
        setProcessingEnabled(preferences.getBoolean("processing_enabled", true));
        setWebAudioEnabled(preferences.getBoolean("web_audio_enabled", false));
        
        updateEffects();
    }
}

@Override
public void updateEffects() {
    synchronized (processLock) {
        for (int i = 0; i < 5; i++) {
            if (lowPassFilters[i] != null) {
                lowPassFilters[i].update();
            }
            if (highPassFilters[i] != null) {
                highPassFilters[i].update();
            }
            if (spatialProcessors[i] != null) {
                spatialProcessors[i].update();
            }
        }
    }
}
    
    // Константы для обработки звука
    private static final int BUFFER_SIZE = AudioProcessorInterface.BUFFER_SIZE;
    private static final float CROSSOVER_FREQUENCY = AudioProcessorInterface.CROSSOVER_FREQUENCY;
    private static final float MIN_DB = AudioProcessorInterface.MIN_DB;
    private static final float MAX_DB = AudioProcessorInterface.MAX_DB;
    private static final int PROCESSING_QUEUE_SIZE = 4;
    private static final int VIRTUAL_CHANNEL_INDEX = 5;
private static final int CHANNEL_CONFIG = AudioFormat.CHANNEL_OUT_STEREO;
private static final int AUDIO_FORMAT = AudioFormat.ENCODING_PCM_FLOAT;
private final LruCache<Integer, ByteBuffer> bufferPool;
    private static final int SAMPLE_RATE = 48000;
private static final int OPTIMAL_BUFFER_SIZE = 12300;
    
    // Константы для веб-аудио
    private static final int WEB_BUFFER_SIZE = 4096;
    private static final int WEB_CHANNELS = 2;
    private static final float WEB_SCALE = 0.8f;
    
    // Константы для пространственной обработки
    private static final float HRTF_ANGLE = 30.0f;
    private static final float ROOM_SIZE = 0.7f;
    private static final float REFLECTION_AMOUNT = 0.3f;
    private static final float STEREO_WIDTH = 1.2f;
    private static final float AIR_AMOUNT = 0.1f;
    private static final int MAX_ERRORS = 5;
private final AtomicInteger errorCount = new AtomicInteger(0);
private final AtomicInteger webErrorCount = new AtomicInteger(0);
    private final Object processingLock = new Object();

    // Улучшенные матрицы микширования с психоакустической коррекцией
    private static final float[][] FRONT_MATRIX = {
        {0.95f, 0.05f, 0.15f, -0.15f},  // FL -> L+R с улучшенной фазой
        {0.05f, 0.95f, -0.15f, 0.15f}   // FR -> L+R с улучшенной фазой
    };
    
    private static final float[][] REAR_MATRIX = {
        {0.7f, -0.3f, 0.8f, -0.4f},    // RL -> L+R с усиленным объемом
        {-0.3f, 0.7f, -0.4f, 0.8f}     // RR -> L+R с усиленным объемом
    };
    
    private static final float[][] SUB_MATRIX = {
        {0.6f, 0.6f, 0.4f, 0.4f}       // SUB -> L+R с оптимизированным НЧ
    };
    
    private synchronized float processChannel(float sample, int channel) {
    // Применяем громкость
    sample *= channelVolumes[channel];
    
    // Применяем фильтры
    if (channelLPF[channel]) {
        sample = lowPassFilters[channel].process(sample);
    }
    
    // Применяем бас
    if (channelBass[channel] > 0) {
        float bassAmount = channelBass[channel];
        sample = sample * (1.0f + bassAmount);
    }
    
    return sample;
}

    // Компоненты веб-движка
    private CustomWebEngine webEngine;
    private WebView attachedWebView;
    private final AtomicBoolean isWebAudioEnabled = new AtomicBoolean(false);
    private final FloatBuffer webInputBuffer;
    private final FloatBuffer webOutputBuffer;
    private final FloatBuffer[] webChannelBuffers;
    private final Object webAudioLock = new Object();
    private final Object filterLock = new Object();
private float currentCutoff = 0.0f;

    // Системные сервисы и контекст
    private final Context context;
    private final AudioManager audioManager;
    private final SharedPreferences preferences;
    private final Handler mainHandler;
    private final ExecutorService audioProcessingExecutor;
    private final ExecutorService webProcessingExecutor;
    private final LinkedBlockingQueue<FloatBuffer> processingQueue;
    private final LinkedBlockingQueue<FloatBuffer> webProcessingQueue;

    // Аудио компоненты
    private AudioTrack audioTrack;
    private WebAudioCapturer webAudioCapturer;
    private MediaProjection mediaProjection;
    private HRTFProcessor hrtfProcessor;
private Thread processingThread;
private AudioRecord audioRecord;
private AudioTrack outputTrack;
private boolean isProcessing;
    private LowPassFilter lowPassFilter;

    // Буферы для обработки
    private final FloatBuffer inputBuffer;
    private final FloatBuffer processBuffer;
    private final FloatBuffer[] virtualChannels;
    private final FloatBuffer outputBuffer;
    private final FloatBuffer tempBuffer;
    private final FloatBuffer spatialBuffer;
    private final FloatBuffer mixBuffer;
    private final FloatBuffer originalSignalBuffer;
    private final FloatBuffer processedSignalBuffer;

    // Массивы параметров каналов
    private final float[] channelVolumes;
    private final float[] channelBass;
    private final boolean[] channelLPF;
    private final float[] channelLevels;
    private final float[] peakLevels;
    private final float[] spatialPositions;
    private final float[] webChannelLevels;
    private final float[] webPeakLevels;

    // Процессоры эффектов
    private final CrossoverFilter[] lowPassFilters;
    private final CrossoverFilter[] highPassFilters;
    private final CrossoverFilter[] webLowPassFilters;
    private final CrossoverFilter[] webHighPassFilters;
    private final RmsCalculator[] rmsCalculators;
    private final RmsCalculator[] webRmsCalculators;
    private final SpatialProcessor[] spatialProcessors;
    private final SpatialProcessor[] webSpatialProcessors;

    // Слушатель обновлений
    private OnChannelUpdateListener channelUpdateListener;

    // Состояние
    private int currentAudioSessionId = -1;
    private final AtomicBoolean isProcessingEnabled = new AtomicBoolean(true);
    private final AtomicBoolean isInitialized = new AtomicBoolean(false);
    private final AtomicBoolean isCapturing = new AtomicBoolean(false);
    private final AtomicBoolean isUIUpdateEnabled = new AtomicBoolean(true);
    private final AtomicBoolean isWebProcessingEnabled = new AtomicBoolean(false);
    private final AtomicBoolean isVirtualChannelActive = new AtomicBoolean(false);

    // Синхронизация
    private final Object processLock = new Object();
    private final Object bufferLock = new Object();
    private final Object uiUpdateLock = new Object();
    
    
    private void updateWebUIValues() {
    if (!isInitialized.get() || !isUIUpdateEnabled.get()) return;

    try {
        for (int ch = 0; ch < 5; ch++) {
            if (channelUpdateListener != null) {
                channelUpdateListener.onChannelLevelChanged(ch, webChannelLevels[ch]);
                channelUpdateListener.onChannelPeakChanged(ch, webPeakLevels[ch]);
            }
        }
    } catch (Exception e) {
        Log.e(TAG, "Error updating web UI values: " + e.getMessage());
    }
}
    
    private void applyMatrixProcessing(float[] buffer) {
    if (buffer == null || buffer.length == 0) return;
    
    // Применяем матричную обработку
    for (int i = 0; i < buffer.length; i += 2) {
        float left = buffer[i];
        float right = buffer[i + 1];
        
        // Применяем матричные коэффициенты
        buffer[i] = left * matrix[0][0] + right * matrix[0][1];
        buffer[i + 1] = left * matrix[1][0] + right * matrix[1][1];
    }
}

private void applyLowPassFilter(float[] buffer) {
    if (buffer == null || buffer.length == 0 || lowPassFilter == null) return;
    
    synchronized(filterLock) {
        for (int i = 0; i < buffer.length; i++) {
            buffer[i] = lowPassFilter.process(buffer[i]);
        }
    }
}

private void applyBassBoost(float[] buffer) {
    if (buffer == null || buffer.length == 0 || !bassBoostEnabled) return;
    
    // Применяем усиление баса
    for (int i = 0; i < buffer.length; i++) {
        // Простое усиление низких частот
        buffer[i] *= (1.0f + bassBoostLevel);
        
        // Ограничиваем амплитуду
        if (buffer[i] > 1.0f) buffer[i] = 1.0f;
        if (buffer[i] < -1.0f) buffer[i] = -1.0f;
    }
}
    
    private void saveSystemVolume() {
        if (audioManager != null) {
            systemVolume = audioManager.getStreamVolume(AudioManager.STREAM_MUSIC);
        }
    }

    private void restoreSystemVolume() {
        if (audioManager != null) {
            audioManager.setStreamMute(AudioManager.STREAM_MUSIC, false);
            audioManager.setStreamVolume(AudioManager.STREAM_MUSIC, (int)systemVolume, 0);
        }
    }
    

    private boolean bassBoostEnabled = false;
private float bassBoostLevel = 0.0f;
private float[][] matrix = new float[][] {
    {1.0f, 0.0f},
    {0.0f, 1.0f}
};
    private void initializeAudioInput() {
    try {
        // MTK специфичные параметры
        audioManager.setParameters("MTK_AUDIO_PATH=direct");
        audioManager.setParameters("MTK_AUDIO_TRACK_DIRECT=1");
        
        int minBufferSize = AudioRecord.getMinBufferSize(
            SAMPLE_RATE,
            AudioFormat.CHANNEL_IN_STEREO,
            AudioFormat.ENCODING_PCM_FLOAT
        );

        audioRecord = new AudioRecord.Builder()
            .setAudioSource(MediaRecorder.AudioSource.VOICE_RECOGNITION)
            .setAudioFormat(new AudioFormat.Builder()
                .setEncoding(AudioFormat.ENCODING_PCM_FLOAT)
                .setSampleRate(SAMPLE_RATE)
                .setChannelMask(AudioFormat.CHANNEL_IN_STEREO)
                .build())
            .setBufferSizeInBytes(minBufferSize * 2)
            .build();
            
        audioRecord.startRecording();
    } catch (Exception e) {
        Log.e(TAG, "Error initializing audio input: " + e.getMessage());
    }
}
    
    
    
    private void fadeInAudio() {
    if (audioTrack != null) {
        new Thread(() -> {
            float volume = 0f;
            while (volume < 1.0f) {
                audioTrack.setVolume(volume);
                volume += 0.1f;
                try {
                    Thread.sleep(50);
                } catch (InterruptedException e) {
                    break;
                }
            }
            audioTrack.setVolume(1.0f);
            // Восстанавливаем системную громкость
            if (audioManager != null) {
                audioManager.setStreamVolume(AudioManager.STREAM_MUSIC, 
                    audioManager.getStreamMaxVolume(AudioManager.STREAM_MUSIC), 0);
            }
        }).start();
    }
}
    

private void fadeOutAudio() {
    if (audioTrack != null) {
        float volume = 1.0f;
        while (volume > 0) {
            audioTrack.setVolume(volume);
            volume -= 0.1f;
            try {
                Thread.sleep(50);
            } catch (InterruptedException e) {
                break;
            }
        }
        audioTrack.setVolume(0);
    }
}

private void normalizeAudio(float[] buffer) {
    float maxAmplitude = 0.0f;
    
    // Находим максимальную амплитуду
    for (float sample : buffer) {
        maxAmplitude = Math.max(maxAmplitude, Math.abs(sample));
    }
    
    // Нормализуем, если нужно
    if (maxAmplitude > 1.0f) {
        float normalizationFactor = 1.0f / maxAmplitude;
        for (int i = 0; i < buffer.length; i++) {
            buffer[i] *= normalizationFactor;
        }
    }
}
    
    
    public void setWebAudioEnabled(boolean enabled) {
    if (isWebAudioEnabled.compareAndSet(!enabled, enabled)) {
        try {
            if (enabled) {
                if (webEngine != null) {
                    saveSystemVolume();
                    if (audioManager != null) {
                        audioManager.setParameters("MTK_WEB_AUDIO_PATH=1");
                        audioManager.setParameters("SET_WEBAUDIO_ENABLE=1");
                        audioManager.setStreamMute(AudioManager.STREAM_MUSIC, true);
                    }
                    webEngine.startProcessing();
                    Log.d(TAG, "Web audio processing started");
                }
            } else {
                if (webEngine != null) {
                    webEngine.stopProcessing();
                    restoreSystemVolume();
                    Log.d(TAG, "Web audio processing stopped");
                }
            }
        } catch (Exception e) {
            Log.e(TAG, "Ошибка переключения WebAudio: " + e.getMessage());
            isWebAudioEnabled.set(false);
        }
    }
}

    private void processMtkAudio(float[] buffer) {
    // Отключаем системный звук
    audioManager.setStreamMute(AudioManager.STREAM_MUSIC, true);
    
    try {
        // Применяем эффекты
        float[] processedBuffer = new float[buffer.length];
        for (int i = 0; i < buffer.length; i += 2) {
            // Левый канал
            processedBuffer[i] = processChannel(buffer[i], 0);
            // Правый канал
            processedBuffer[i + 1] = processChannel(buffer[i + 1], 1);
        }
        
        // Записываем в AudioTrack
        if (audioTrack != null && audioTrack.getPlayState() == AudioTrack.PLAYSTATE_PLAYING) {
            audioTrack.write(processedBuffer, 0, processedBuffer.length, 
                AudioTrack.WRITE_NON_BLOCKING);
        }
    } catch (Exception e) {
        Log.e(TAG, "Error processing MTK audio: " + e.getMessage());
    }
}
    
private float applyPsychoacousticProcessing(float sample, int channel) {
    // Применяем психоакустическую обработку в зависимости от канала
    if (channel >= 2 && channel < 4) { // Тыловые каналы
        // Усиление пространственного эффекта
        float spatialGain = 1.2f;
        float phaseShift = (float) Math.sin(2.0 * Math.PI * sample);
        sample = sample * spatialGain + phaseShift * 0.2f;
        
        // Добавление задержки для эффекта объема
        if (spatialProcessors[channel] != null) {
            sample = spatialProcessors[channel].process(sample, spatialPositions[channel]);
        }
    }
    
    // Применяем частотную коррекцию
    if (lowPassFilters[channel] != null && highPassFilters[channel] != null) {
        float lowFreq = lowPassFilters[channel].process(sample);
        float highFreq = highPassFilters[channel].process(sample);
        
        // Микширование с учетом психоакустических особенностей
        sample = highFreq + lowFreq * (1.0f + channelBass[channel] * 0.5f);
    }
    
    return sample;
}

    // UI обновление
    private final Runnable uiUpdateRunnable = new Runnable() {
        @Override
        public void run() {
            if (isUIUpdateEnabled.get() && isInitialized.get()) {
                updateUIValues();
                updateWebUIValues();
                mainHandler.postDelayed(this, 50);
            }
        }
    };
    
    private void initializeProcessors() {
    try {
        hrtfProcessor = new HRTFProcessor(SAMPLE_RATE);
        
        for (int i = 0; i < 5; i++) {
            lowPassFilters[i] = new CrossoverFilter(
                CrossoverFilter.TYPE_LOWPASS,
                CROSSOVER_FREQUENCY,
                SAMPLE_RATE
            );
            lowPassFilters[i].setQ(0.707f);

            highPassFilters[i] = new CrossoverFilter(
                CrossoverFilter.TYPE_HIGHPASS,
                CROSSOVER_FREQUENCY,
                SAMPLE_RATE
            );
            highPassFilters[i].setQ(0.707f);

            rmsCalculators[i] = new RmsCalculator(SAMPLE_RATE / 10);
            spatialProcessors[i] = new SpatialProcessor(SAMPLE_RATE, ROOM_SIZE);
            spatialProcessors[i].setReflectionAmount(REFLECTION_AMOUNT);
        }
    } catch (Exception e) {
        Log.e(TAG, "Error initializing processors: " + e.getMessage());
        isInitialized.set(false);
    }
}

private void initializeWebProcessors() {
    try {
        for (int i = 0; i < 5; i++) {
            webLowPassFilters[i] = new CrossoverFilter(
                CrossoverFilter.TYPE_LOWPASS,
                CROSSOVER_FREQUENCY,
                SAMPLE_RATE
            );
            webLowPassFilters[i].setQ(0.707f);

            webHighPassFilters[i] = new CrossoverFilter(
                CrossoverFilter.TYPE_HIGHPASS,
                CROSSOVER_FREQUENCY,
                SAMPLE_RATE
            );
            webHighPassFilters[i].setQ(0.707f);

            webRmsCalculators[i] = new RmsCalculator(SAMPLE_RATE / 10);
            webSpatialProcessors[i] = new SpatialProcessor(SAMPLE_RATE, ROOM_SIZE);
            webSpatialProcessors[i].setReflectionAmount(REFLECTION_AMOUNT);
        }
    } catch (Exception e) {
        Log.e(TAG, "Error initializing web processors: " + e.getMessage());
    }
}

private void initializeDefaultValues() {
    synchronized (processLock) {
        for (int i = 0; i < 5; i++) {
            channelVolumes[i] = 1.0f;
            channelBass[i] = 0.0f;
            channelLPF[i] = false;
            spatialPositions[i] = 0.0f;
        }
        restoreProcessingState();
    }
}
    
private void initializeWebAudioEngine() {
    try {
        webEngine = new CustomWebEngine(context, this);
        webEngine.setAudioProcessor(this);
    } catch (Exception e) {
        Log.e(TAG, "Error initializing web audio engine: " + e.getMessage());
    }
}

private void initializeWebAudioCapturer() {
    try {
        webAudioCapturer = new WebAudioCapturer(context, SAMPLE_RATE, WEB_BUFFER_SIZE);
        webAudioCapturer.setCallback((data, len) -> onAudioDataCaptured(data, len));
    } catch (Exception e) {
        Log.e(TAG, "Error initializing web audio capturer: " + e.getMessage());
    }
}
    
    private ByteBuffer getBuffer(int size) {
    ByteBuffer buffer = bufferPool.get(size);
    if (buffer == null) {
        buffer = ByteBuffer.allocateDirect(size);
        bufferPool.put(size, buffer);
    }
    buffer.clear();
    return buffer;
}

    public AudioProcessor(Context context) {
    bufferPool = new LruCache<>(5); // Размер пула буферов
    this.context = context;
    this.audioManager = (AudioManager) context.getSystemService(Context.AUDIO_SERVICE);
    this.preferences = context.getSharedPreferences(PREFS_NAME, Context.MODE_PRIVATE);
    this.mainHandler = new Handler(Looper.getMainLooper());
    this.audioProcessingExecutor = Executors.newSingleThreadExecutor();
    this.webProcessingExecutor = Executors.newSingleThreadExecutor();
    this.processingQueue = new LinkedBlockingQueue<>(PROCESSING_QUEUE_SIZE);
    this.webProcessingQueue = new LinkedBlockingQueue<>(PROCESSING_QUEUE_SIZE);
    
        
    // Инициализация массивов параметров
    channelVolumes = new float[5];
    channelBass = new float[5];
    channelLPF = new boolean[5];
    channelLevels = new float[5];
    peakLevels = new float[5];
    spatialPositions = new float[5];
    webChannelLevels = new float[5];
    webPeakLevels = new float[5];

    // Инициализация буферов
    inputBuffer = FloatBuffer.allocate(BUFFER_SIZE);
    processBuffer = FloatBuffer.allocate(BUFFER_SIZE);
    spatialBuffer = FloatBuffer.allocate(BUFFER_SIZE);
    mixBuffer = FloatBuffer.allocate(BUFFER_SIZE);
    webInputBuffer = FloatBuffer.allocate(WEB_BUFFER_SIZE);
    webOutputBuffer = FloatBuffer.allocate(WEB_BUFFER_SIZE);
    originalSignalBuffer = FloatBuffer.allocate(BUFFER_SIZE);
    processedSignalBuffer = FloatBuffer.allocate(BUFFER_SIZE);
    
    // Инициализация виртуальных каналов
    virtualChannels = new FloatBuffer[6]; // 5 основных + 1 виртуальный
    webChannelBuffers = new FloatBuffer[6];
    for (int i = 0; i < 6; i++) {
        virtualChannels[i] = FloatBuffer.allocate(BUFFER_SIZE);
        webChannelBuffers[i] = FloatBuffer.allocate(WEB_BUFFER_SIZE);
    }
    outputBuffer = FloatBuffer.allocate(BUFFER_SIZE);
    tempBuffer = FloatBuffer.allocate(BUFFER_SIZE);

    // Инициализация процессоров эффектов
    lowPassFilters = new CrossoverFilter[5];
    highPassFilters = new CrossoverFilter[5];
    webLowPassFilters = new CrossoverFilter[5];
    webHighPassFilters = new CrossoverFilter[5];
    rmsCalculators = new RmsCalculator[5];
    webRmsCalculators = new RmsCalculator[5];
    spatialProcessors = new SpatialProcessor[5];
    webSpatialProcessors = new SpatialProcessor[5];
    
    // Настройка аудио маршрутизации для MediaTek
    setupAudioRouting();
    
    initializeProcessors();
    initializeWebProcessors();
    initializeDefaultValues();
    initializeAudioOutput();
    initializeWebAudioEngine();
    initializeWebAudioCapturer();
    startUIUpdates();
    
    startProcessingThreads();
}

    
    private void startAudioProcessing() {
    isProcessing = true;
    new Thread(new Runnable() {
        @Override
        public void run() {
            android.os.Process.setThreadPriority(android.os.Process.THREAD_PRIORITY_URGENT_AUDIO);
            
            float[] buffer = new float[4096];
            
            try {
                audioRecord.startRecording();
                
                while (isProcessing) {
                    int read = audioRecord.read(buffer, 0, buffer.length, AudioRecord.READ_BLOCKING);
                    if (read > 0) {
                        // Обработка аудио через интерфейсный метод
                        float[] processedBuffer = processAudioData(buffer, read);
                        // Отправляем обработанный звук на выход
                        outputTrack.write(processedBuffer, 0, read, AudioTrack.WRITE_BLOCKING);
                    }
                }
            } catch (Exception e) {
                Log.e(TAG, "Error in audio processing thread: " + e.getMessage());
            } finally {
                stopAudioProcessing();
            }
        }
    }, "AudioProcessingThread").start();
}
    private void stopAudioProcessing() {
    isProcessing = false;
        if (audioRecord != null) {
        try {
            audioRecord.stop();
        } catch (Exception e) {
            Log.e(TAG, "Error stopping audio record: " + e.getMessage());
        }
        }
    if (outputTrack != null) {
        try {
            outputTrack.stop();
        } catch (Exception e) {
            Log.e(TAG, "Error stopping audio track: " + e.getMessage());
        }
    }
}
    
private void setupAudioRouting() {
        
        
    if (audioManager != null) {
        try {
            // Базовые настройки аудио
            audioManager.setMode(AudioManager.MODE_NORMAL);
            audioManager.setSpeakerphoneOn(true);
            
            // Настройка для перехвата аудио из WebView
            audioManager.setStreamVolume(AudioManager.STREAM_MUSIC, 
                audioManager.getStreamMaxVolume(AudioManager.STREAM_MUSIC), 0);
                
            // Специфичные настройки для WebView
            audioManager.setParameters("MTK_WEB_AUDIO_PATH=0");
            audioManager.setParameters("SET_WEBAUDIO_ENABLE=1");
            audioManager.setParameters("WebAudio_Stream_Control=1");

            int bufferSize = AudioTrack.getMinBufferSize(SAMPLE_RATE,
                AudioFormat.CHANNEL_OUT_STEREO,
                AudioFormat.ENCODING_PCM_FLOAT);

            // Настройка атрибутов аудио
            AudioAttributes playbackAttributes = new AudioAttributes.Builder()
                .setUsage(AudioAttributes.USAGE_MEDIA)
                .setContentType(AudioAttributes.CONTENT_TYPE_MUSIC)
                .setFlags(AudioAttributes.FLAG_LOW_LATENCY)
                .build();

            // Создаем аудио трек для вывода
            outputTrack = new AudioTrack.Builder()
                .setAudioAttributes(playbackAttributes)
                .setAudioFormat(new AudioFormat.Builder()
                    .setEncoding(AudioFormat.ENCODING_PCM_FLOAT)
                    .setSampleRate(SAMPLE_RATE)
                    .setChannelMask(AudioFormat.CHANNEL_OUT_STEREO)
                    .build())
                .setBufferSizeInBytes(bufferSize)
                .setTransferMode(AudioTrack.MODE_STREAM)
                .build();

            outputTrack.play();

            // Настройка аудио рекордера
            audioRecord = new AudioRecord.Builder()
                .setAudioSource(MediaRecorder.AudioSource.VOICE_RECOGNITION)
                .setAudioFormat(new AudioFormat.Builder()
                    .setEncoding(AudioFormat.ENCODING_PCM_FLOAT)
                    .setSampleRate(SAMPLE_RATE)
                    .setChannelMask(AudioFormat.CHANNEL_IN_STEREO)
                    .build())
                .setBufferSizeInBytes(bufferSize)
                .build();

            // Настройка аудио фокуса
            int result = audioManager.requestAudioFocus(new AudioManager.OnAudioFocusChangeListener() {
                @Override
                public void onAudioFocusChange(int focusChange) {
                    switch (focusChange) {
                        case AudioManager.AUDIOFOCUS_GAIN:
                            if (!isProcessing) {
                                startAudioProcessing();
                            }
                            break;
                        case AudioManager.AUDIOFOCUS_LOSS:
                            stopAudioProcessing();
                            break;
                    }
                }
            }, AudioManager.STREAM_MUSIC,
               AudioManager.AUDIOFOCUS_GAIN);

            // Запускаем обработку
            startAudioProcessing();
            
        } catch (Exception e) {
            Log.e(TAG, "Error setting up WebView audio routing: " + e.getMessage());
        }
    }
}

    private float calculateRMS(float[] buffer) {
    float sum = 0;
    for (float v : buffer) {
        sum += v * v;
    }
    return (float) Math.sqrt(sum / buffer.length);
}
    
    @Override
public void onAudioDataCaptured(float[] audioData, int length) {
    if (!isProcessingEnabled.get() || audioData == null || length <= 0) return;

    try {
        float[] processedData = processAudioData(audioData, length);

        for (int ch = 0; ch < 5; ch++) {
            channelLevels[ch] = calculateRMS(processedData);
        }

        if (audioTrack != null && audioTrack.getPlayState() == AudioTrack.PLAYSTATE_PLAYING) {
            audioTrack.write(processedData, 0, processedData.length, AudioTrack.WRITE_NON_BLOCKING);
        }

    } catch (Exception e) {
        Log.e(TAG, "Error in onAudioDataCaptured: " + e.getMessage());
    }
}

    private float[] processVirtualChannelData(float[] data, int length) {
        float[] processedData = new float[length];
        
        try {
            // Получаем данные из виртуального канала
            FloatBuffer virtualBuffer = virtualChannels[VIRTUAL_CHANNEL_INDEX].duplicate();
            virtualBuffer.clear();
            
            // Применяем матричное преобразование для каждого канала
            for (int ch = 0; ch < 5; ch++) {
                float[] matrix = getChannelMatrix(ch);
                
                for (int i = 0; i < length; i += 2) {
                    float left = data[i];
                    float right = data[i + 1];
                    
                    // Применяем матричные коэффициенты
                    float channelSample = left * matrix[0] + right * matrix[1];
                    
                    // Применяем психоакустическую обработку для тыловых каналов
                    if (ch >= 2 && ch < 4) {
                        channelSample = applyPsychoacousticProcessing(channelSample, ch);
                    }
                    
                    processedData[i + ch] = channelSample * channelVolumes[ch];
                }
            }
            
        } catch (Exception e) {
            Log.e(TAG, "Error processing virtual channel data: " + e.getMessage());
        }
        
        return processedData;
    }

    private float[] getChannelMatrix(int channel) {
        if (channel < 2) {
            return FRONT_MATRIX[channel];
        } else if (channel < 4) {
            return REAR_MATRIX[channel - 2];
        } else {
            return SUB_MATRIX[0];
        }
    }


    
    
    private float[] extractChannelData(float[] input, int channel, int length) {
        float[] channelData = new float[length / 2];
        int j = 0;
        for (int i = channel; i < length; i += 2) {
            channelData[j++] = input[i];
        }
        return channelData;
    }
    
    private float[] processChannel(float[] channelData, int channel) {
        float[] processed = channelData.clone();
        
        // Применяем громкость
        float volume = channelVolumes[channel];
        for (int i = 0; i < processed.length; i++) {
            processed[i] *= volume;
        }
        
        // Применяем бас
        if (channelBass[channel] > 0 && lowPassFilters[channel] != null) {
            float bassAmount = channelBass[channel];
            float[] bassData = new float[processed.length];
            
            for (int i = 0; i < processed.length; i++) {
                float sample = processed[i];
                float lowFreq = lowPassFilters[channel].process(sample);
                float highFreq = highPassFilters[channel].process(sample);
                float harmonics = generateHarmonics(lowFreq);
                
                processed[i] = highFreq + (lowFreq + harmonics * 0.3f) * (1.0f + bassAmount);
            }
        }
        
        // Применяем LPF
        if (channelLPF[channel] && lowPassFilters[channel] != null) {
            for (int i = 0; i < processed.length; i++) {
                processed[i] = lowPassFilters[channel].process(processed[i]);
            }
        }
        
        // Применяем пространственную обработку
        if (spatialProcessors[channel] != null) {
            for (int i = 0; i < processed.length; i++) {
                processed[i] = spatialProcessors[channel].process(processed[i], spatialPositions[channel]);
            }
        }
        
        return processed;
    }
    
    public void processAudio(float[] buffer) {
    if (!isProcessingEnabled.get() || buffer == null || buffer.length == 0) {
        return;
    }

    try {
        ByteBuffer processBuffer = getBuffer(buffer.length * 4);
        processBuffer.asFloatBuffer().put(buffer);
        float[] processedBuffer = processAudioData(buffer, buffer.length);
        
        if (audioTrack != null && audioTrack.getPlayState() == AudioTrack.PLAYSTATE_PLAYING) {
            int written = audioTrack.write(processedBuffer, 0, processedBuffer.length, 
                AudioTrack.WRITE_NON_BLOCKING);
                
            if (written < 0) {
                Log.e(TAG, "Error writing to AudioTrack: " + written);
                reinitializeAudioOutput();
            }
        }
    } catch (Exception e) {
        Log.e(TAG, "Error in processAudio: " + e.getMessage());
        handleProcessingError();
    }
}
    

    private void mixChannelToOutput(float[] channelData, int channel) {
    float[] matrix = getChannelMatrix(channel);
    
    for (int i = 0; i < channelData.length; i++) {
        float sample = channelData[i];
        
        // Применяем матричное микширование
        outputBuffer.put(i * 2, outputBuffer.get(i * 2) + sample * matrix[0]);     // Left
        outputBuffer.put(i * 2 + 1, outputBuffer.get(i * 2 + 1) + sample * matrix[1]); // Right
    }
}

    private float[] createFinalOutput() {
        float[] output = new float[outputBuffer.capacity()];
        outputBuffer.get(output);
        
        // Применяем стерео расширение
        for (int i = 0; i < output.length - 1; i += 2) {
            float left = output[i];
            float right = output[i + 1];
            
            float mid = (left + right) * 0.5f;
            float side = (left - right) * 0.5f;
            
            // Расширяем стерео базу
            side *= STEREO_WIDTH;
            
            output[i] = mid + side;
            output[i + 1] = mid - side;
        }
        
        return output;
    }

    private float generateHarmonics(float input) {
        float harmonic2 = input * input * (input >= 0 ? 1 : -1) * 0.5f;
        float harmonic3 = input * input * input * 0.3f;
        return harmonic2 + harmonic3;
    }

    private void applyFinalPsychoacousticProcessing(float[] audio) {
        for (int i = 0; i < audio.length - 1; i += 2) {
            float left = audio[i];
            float right = audio[i + 1];

            // Усиление стереообраза
            float mid = (left + right) * 0.5f;
            float side = (left - right) * 0.5f;
            side *= 1.2f;

            // Применяем воздушность
            if (i > 0 && i < audio.length - 2) {
                float airLeft = (audio[i - 1] - audio[i + 1]) * AIR_AMOUNT;
                float airRight = (audio[i] - audio[i + 2]) * AIR_AMOUNT;
                
                left += airLeft;
                right += airRight;
            }

            audio[i] = mid + side;
            audio[i + 1] = mid - side;
        }
    }


    private float[][] createWebVirtualChannels(float[] input) {
        float[][] channels = new float[5][input.length / 2];
        
        for (int ch = 0; ch < 5; ch++) {
            float[] matrix = getChannelMatrix(ch);
            
            for (int i = 0, j = 0; i < input.length - 1; i += 2, j++) {
                float left = input[i];
                float right = input[i + 1];
                
                // Применяем матричное преобразование
                channels[ch][j] = left * matrix[0] + right * matrix[1];
                
                // Применяем психоакустическую обработку для тыловых каналов
                if (ch >= 2 && ch < 4) {
                    channels[ch][j] = applyPsychoacousticProcessing(channels[ch][j], ch);
                }
            }
        }
        
        return channels;
    }

    private float[] processWebChannel(float[] channelData, int channel) {
        float[] processed = channelData.clone();
        
        // Применяем HRTF обработку
        if (hrtfProcessor != null) {
            processed = hrtfProcessor.process(processed, spatialPositions[channel], HRTF_ANGLE);
        }

        // Применяем фильтры и эффекты
        for (int i = 0; i < processed.length; i++) {
            float sample = processed[i];

            // LPF
            if (channelLPF[channel]) {
                sample = webLowPassFilters[channel].process(sample);
            }

            // Bass enhancement
            if (channelBass[channel] > 0) {
                float lowFreq = webLowPassFilters[channel].process(sample);
                float highFreq = webHighPassFilters[channel].process(sample);
                float harmonics = generateHarmonics(lowFreq);
                sample = highFreq + (lowFreq + harmonics * 0.3f) * (1.0f + channelBass[channel]);
            }

            // Пространственная обработка
            sample = webSpatialProcessors[channel].process(sample, spatialPositions[channel]);
            
            // Применяем громкость
            sample *= channelVolumes[channel];
            
            processed[i] = sample;
        }

        return processed;
    }

    private void applyWebSpatialProcessing(float[][] channels) {
        for (int ch = 0; ch < 5; ch++) {
            if (webSpatialProcessors[ch] != null) {
                for (int i = 0; i < channels[ch].length; i++) {
                    channels[ch][i] = webSpatialProcessors[ch].process(
                        channels[ch][i], 
                        spatialPositions[ch]
                    );
                }
            }
        }
    }

    private float[] mixWebToStereo(float[][] channels) {
        int outputLength = channels[0].length * 2;
        float[] stereoOutput = new float[outputLength];
        
        for (int i = 0, j = 0; i < channels[0].length; i++, j += 2) {
            float left = 0;
            float right = 0;
            
            // Микшируем все каналы согласно матрицам
            for (int ch = 0; ch < 5; ch++) {
                float[] matrix = getChannelMatrix(ch);
                float sample = channels[ch][i];
                
                left += sample * matrix[0];
                right += sample * matrix[1];
            }
            
            // Применяем стерео расширение
            float mid = (left + right) * 0.5f;
            float side = (left - right) * 0.5f * STEREO_WIDTH;
            
            stereoOutput[j] = mid + side;
            stereoOutput[j + 1] = mid - side;
        }
        
        return stereoOutput;
    }

    private void writeWebAudioOutput(float[] outputData) {
        if (!isInitialized.get() || audioTrack == null || 
            audioTrack.getPlayState() != AudioTrack.PLAYSTATE_PLAYING) return;

        try {
            // Нормализация
            float maxAmp = 0.0f;
            for (float sample : outputData) {
                maxAmp = Math.max(maxAmp, Math.abs(sample));
            }
            
            if (maxAmp > 1.0f) {
                float gain = 1.0f / maxAmp;
                for (int i = 0; i < outputData.length; i++) {
                    outputData[i] *= gain;
                }
            }

            // Отправляем на воспроизведение
            int written = audioTrack.write(
                outputData, 
                0, 
                outputData.length, 
                AudioTrack.WRITE_NON_BLOCKING
            );

            if (written < 0) {
                Log.e(TAG, "Error writing web audio to AudioTrack: " + written);
            }
        } catch (Exception e) {
            Log.e(TAG, "Error writing web audio output: " + e.getMessage());
        }
    }

    private void updateChannelLevels(float[] data, int length) {
    float leftRms = 0;
    float rightRms = 0;
    float leftPeak = 0;
    float rightPeak = 0;

    // Вычисляем RMS и пиковые значения
    for (int i = 0; i < length; i += 2) {
        float leftAbs = Math.abs(data[i]);
        float rightAbs = Math.abs(data[i + 1]);
        
        leftRms += data[i] * data[i];
        rightRms += data[i + 1] * data[i + 1];
        
        leftPeak = Math.max(leftPeak, leftAbs);
        rightPeak = Math.max(rightPeak, rightAbs);
    }

    int samplesPerChannel = length / 2;
    leftRms = (float) Math.sqrt(leftRms / samplesPerChannel);
    rightRms = (float) Math.sqrt(rightRms / samplesPerChannel);

    // Обновляем значения уровней
    channelLevels[0] = convertToDb(leftRms);
    channelLevels[1] = convertToDb(rightRms);
    peakLevels[0] = convertToDb(leftPeak);
    peakLevels[1] = convertToDb(rightPeak);
}
    
    private void initializeMtkAudio() {
    try {
        // Настройка MediaTek Audio HAL
        audioManager.setParameters("MTK_AUDIO_TUNING_TOOL=1");
        
        // Включаем поддержку 32-bit аудио
        audioManager.setParameters("MTK_AUDIO_32BIT=1");
        
        // Настройка аудио патча для прямой передачи
        audioManager.setParameters("MTK_AUDIO_PATCH=DIRECT");
        
    } catch (Exception e) {
        Log.e(TAG, "Error initializing MTK audio: " + e.getMessage());
    }
}
    
    private void setupMtkAudioRouting() {
    if (audioManager != null) {
        try {
            // Отключаем системный звук
            audioManager.setStreamVolume(AudioManager.STREAM_MUSIC, 0, 0);
            audioManager.setStreamMute(AudioManager.STREAM_MUSIC, true);
            
            // Настройки для MediaTek
            audioManager.setParameters("MTK_AUDIO_PATH=direct");
            audioManager.setParameters("MTK_AUDIO_TRACK_DIRECT=1");
            audioManager.setParameters("MTK_AUDIO_TRACK_LOW_LATENCY=1");
            audioManager.setParameters("MTK_LOW_LATENCY=1");
            audioManager.setParameters("MTK_AUDIO_TUNING_TOOL=1");
            audioManager.setParameters("MTK_HIFI_AUDIO=1");
            audioManager.setParameters("MTK_AUDIO_32BIT=1");
            audioManager.setParameters("MTK_AUDIO_PATCH=DIRECT");
            audioManager.setParameters("MTK_AUDIO_PROCESSING=1");
            audioManager.setParameters("MTK_AUDIO_RAW_DATA_MODE=1");
            audioManager.setParameters("MTK_AUDIO_DEEP_BUFFER=0");
            audioManager.setParameters("SET_WEBAUDIO_ENABLE=1");
            audioManager.setParameters("WebAudio_Stream_Control=1");

            // Оптимальные настройки буфера для MediaTek
            int minBuffer = AudioTrack.getMinBufferSize(
                SAMPLE_RATE,
                AudioFormat.CHANNEL_OUT_STEREO,
                AudioFormat.ENCODING_PCM_FLOAT
            );
            int optimizedBuffer = Math.max(minBuffer * 2, 4096);

            AudioAttributes attributes = new AudioAttributes.Builder()
                .setUsage(AudioAttributes.USAGE_MEDIA)
                .setContentType(AudioAttributes.CONTENT_TYPE_MUSIC)
                .setFlags(AudioAttributes.FLAG_LOW_LATENCY)
                .build();

            AudioFormat format = new AudioFormat.Builder()
                .setEncoding(AudioFormat.ENCODING_PCM_FLOAT)
                .setSampleRate(SAMPLE_RATE)
                .setChannelMask(AudioFormat.CHANNEL_OUT_STEREO)
                .build();

            if (audioTrack != null) {
                audioTrack.release();
            }

            audioTrack = new AudioTrack.Builder()
                .setAudioAttributes(attributes)
                .setAudioFormat(format)
                .setBufferSizeInBytes(optimizedBuffer)
                .setTransferMode(AudioTrack.MODE_STREAM)
                .setPerformanceMode(AudioTrack.PERFORMANCE_MODE_LOW_LATENCY)
                .build();

            // Настройка микшера
            audioManager.setParameters("MTK_AUDIO_MIC_MUTE=1");
            audioManager.setParameters("MTK_AUDIO_LOOPBACK=0");
            audioManager.setParameters("agc_enable=0");
            audioManager.setParameters("aec_enable=0");
            audioManager.setParameters("ns_enable=0");
            audioManager.setParameters("mic_loopback=0");

            // Запуск воспроизведения
            if (audioTrack.getState() == AudioTrack.STATE_INITIALIZED) {
                audioTrack.play();
            }

        } catch (Exception e) {
            Log.e(TAG, "Error in setupMtkAudioRouting: " + e.getMessage());
            reinitializeAudioOutput();
        }
    }
}

private void initializeAudio() {
    try {
        // Сначала инициализируем AudioTrack
        initializeAudioOutput();
        
        // Только после успешной инициализации AudioTrack пробуем добавить эффекты
        if (audioTrack != null && audioTrack.getState() == AudioTrack.STATE_INITIALIZED) {
            int sessionId = audioTrack.getAudioSessionId();
            
            }
        
        
        isInitialized.set(true);
    } catch (Exception e) {
        Log.e(TAG, "Error initializing audio: " + e.getMessage());
        releaseResources();
    }
}
    
    private void updateWebChannelLevels(int channel, FloatBuffer buffer) {
        if (!isInitialized.get() || buffer == null) return;

        try {
            float rms = 0;
            float peak = 0;
            
            buffer.clear();
            while (buffer.hasRemaining()) {
                float sample = buffer.get();
                float abs = Math.abs(sample);
                rms += sample * sample;
                peak = Math.max(peak, abs);
            }
            
            rms = (float) Math.sqrt(rms / buffer.capacity());
            webRmsCalculators[channel].addValue(rms);
            
            synchronized (uiUpdateLock) {
                webChannelLevels[channel] = convertToDb(webRmsCalculators[channel].getCurrentValue());
                webPeakLevels[channel] = convertToDb(peak);
            }
        } catch (Exception e) {
            Log.e(TAG, "Error updating web channel levels: " + e.getMessage());
        }
    }

    private void updateUIValues() {
        if (!isInitialized.get() || !isUIUpdateEnabled.get()) return;

        try {
            for (int ch = 0; ch < 5; ch++) {
                if (channelUpdateListener != null) {
                    channelUpdateListener.onChannelLevelChanged(ch, channelLevels[ch]);
                    channelUpdateListener.onChannelPeakChanged(ch, peakLevels[ch]);
                    
                    float volumeDb = 20 * (float) Math.log10(Math.max(0.0001f, channelVolumes[ch]));
                    float bassDb = 20 * (float) Math.log10(Math.max(0.0001f, channelBass[ch] + 1.0f));
                    
                    channelUpdateListener.onVolumeTextUpdated(ch, String.format("%.1f dB", volumeDb));
                    channelUpdateListener.onBassTextUpdated(ch, String.format("%.1f dB", bassDb));
                    channelUpdateListener.onLPFStateUpdated(ch, channelLPF[ch]);
                }
            }

            // Обновляем анализ в реальном времени
            if (channelUpdateListener != null) {
                String analysis = String.format(Locale.US,
                    "LF:%.1fdB  RF:%.1fdB\n" +
                    "LR:%.1fdB  RR:%.1fdB  SUB:%.1fdB",
                    channelLevels[0], channelLevels[1],
                    channelLevels[2], channelLevels[3],
                    channelLevels[4]);
                
                channelUpdateListener.onAnalysisTextUpdated(analysis);
            }
        } catch (Exception e) {
            Log.e(TAG, "Error updating UI values: " + e.getMessage());
        }
    }

    private float convertToDb(float value) {
        if (value < 1e-6f) return MIN_DB;
        return Math.max(MIN_DB,
               Math.min(MAX_DB,
               20 * (float) Math.log10(value)));
    }

    private void startUIUpdates() {
        mainHandler.post(uiUpdateRunnable);
    }

    public void release() {
        try {
            isProcessingEnabled.set(false);
            isWebAudioEnabled.set(false);
            isInitialized.set(false);
            
            saveProcessingState();
            
            audioProcessingExecutor.shutdown();
            webProcessingExecutor.shutdown();
            
            if (audioTrack != null) {
                audioTrack.stop();
                audioTrack.release();
                audioTrack = null;
            }
            
            if (webEngine != null) {
                webEngine.release();
                webEngine = null;
            }
            
            for (int i = 0; i < 5; i++) {
                if (lowPassFilters[i] != null) lowPassFilters[i].release();
                if (highPassFilters[i] != null) highPassFilters[i].release();
                if (webLowPassFilters[i] != null) webLowPassFilters[i].release();
                if (webHighPassFilters[i] != null) webHighPassFilters[i].release();
                if (spatialProcessors[i] != null) spatialProcessors[i].release();
                if (webSpatialProcessors[i] != null) webSpatialProcessors[i].release();
            }
            
            if (hrtfProcessor != null) {
                hrtfProcessor.release();
            }
            
            processingQueue.clear();
            webProcessingQueue.clear();
            
            mainHandler.removeCallbacks(uiUpdateRunnable);
            
        } catch (Exception e) {
            Log.e(TAG, "Error releasing resources: " + e.getMessage());
        }
    }

    public void setChannelUpdateListener(AudioProcessorInterface.OnChannelUpdateListener listener) {
        this.channelUpdateListener = listener;
    }

    public void attachWebView(WebView webView) {
        this.attachedWebView = webView;
        if (webEngine != null) {
            webEngine.attachWebView(webView);
        }
    }

    public void detachWebView() {
    if (webEngine != null) {
        webEngine.stopProcessing(); // Сначала останавливаем обработку
        webEngine.attachWebView(null); // Используем существующий метод с null
    }
    this.attachedWebView = null;
}

public boolean isWebViewAttached() {
    return attachedWebView != null && webEngine != null && 
           webEngine.isProcessing(); // Проверяем активность обработки
}

    public int getAudioSessionId() {
        return currentAudioSessionId;
    }

    public boolean isInitialized() {
        return isInitialized.get();
    }

    public boolean isProcessing() {
        return isProcessingEnabled.get();
    }

    public void setWebProcessingEnabled(boolean enabled) {
        isWebProcessingEnabled.set(enabled);
        if (webEngine != null) {
            if (enabled) {
                webEngine.startProcessing();
            } else {
                webEngine.stopProcessing();
            }
        }
    }
    
public void stop() {
    if (audioManager != null) {
        audioManager.setStreamMute(AudioManager.STREAM_MUSIC, false);
    }
    
    if (audioTrack != null) {
        fadeOutAudio();
        audioTrack.stop();
        audioTrack.flush();
    }
    
    isProcessing = false;
    if (processingThread != null) {
        processingThread.interrupt();
        processingThread = null;
    }
}

    @Override
    protected void finalize() throws Throwable {
        try {
            release();
        } finally {
            super.finalize();
        }
    }
    private void logProcessingState() {
    Log.d(TAG, String.format("AudioProcessor state: " +
        "Processing enabled=%b, Volumes=%s, " +
        "LPF states=%s, Bass levels=%s, " +
        "Audio track state=%d, Web audio enabled=%b",
        isProcessingEnabled.get(),
        Arrays.toString(channelVolumes),
        Arrays.toString(channelLPF),
        Arrays.toString(channelBass),
        audioTrack != null ? audioTrack.getPlayState() : -1,
        isWebAudioEnabled.get()));
}
}

И

package com.vlq.audioprocessor;

public interface AudioProcessorInterface {
    // Константы каналов
    int FRONT_LEFT = 0;
    int FRONT_RIGHT = 1;
    int REAR_LEFT = 2;
    int REAR_RIGHT = 3;
    int SUBWOOFER = 4;
    
    // Константы для обработки звука
    float MIN_DB = -60.0f;
    float MAX_DB = 0.0f;
    float MIN_FREQUENCY = 20.0f;
    float MAX_FREQUENCY = 20000.0f;
    int SAMPLE_RATE = 44100;
    int BUFFER_SIZE = 4096;
    float CROSSOVER_FREQUENCY = 200.0f;
    
    // Основные методы управления каналами
    void setChannelVolume(int channel, float volume);
    void setChannelBass(int channel, float bass);
    void setChannelLPF(int channel, boolean enabled);
    float getChannelLevel(int channel);
    float getChannelVolume(int channel);
    float getChannelBass(int channel);
    boolean getChannelLPF(int channel);

    // Методы управления состоянием
    void setProcessingEnabled(boolean enabled);
    boolean isInitialized();
    void release();
    
    // Методы для работы с аудио сессией
    int getAudioSessionId();
    void attachToSession(int audioSessionId);
    
    // Методы для работы с буферами
    void onAudioDataCaptured(float[] audioData, int length);
    float[] processAudioData(float[] data, int length);  // Изменено возвращаемое значение с void на float[]
    
    // Методы для сохранения/восстановления состояния
    void saveProcessingState();
    void restoreProcessingState();
    
    // Методы для работы с эффектами
    void updateEffects();
    
    // Интерфейс для обновления уровней каналов
    interface OnChannelUpdateListener {
        void onChannelLevelChanged(int channel, float level);
        void onChannelPeakChanged(int channel, float peak);
        void onVolumeTextUpdated(int channel, String text);
        void onBassTextUpdated(int channel, String text); 
        void onLevelTextUpdated(int channel, String text);
        void onLPFStateUpdated(int channel, boolean enabled);
        void onAnalysisTextUpdated(String text);
    }
    
    // Методы для работы с listener'ами
    void setChannelUpdateListener(OnChannelUpdateListener listener);
    
    // Методы для получения массивов настроек
    float[] getChannelVolumes();
    float[] getChannelBassLevels();
    boolean[] getChannelLPFStates();
}

И

package com.vlq.audioprocessor;

import android.util.Log;
import java.nio.FloatBuffer;
import java.util.concurrent.atomic.AtomicInteger;

public class AudioRenderingEngine {
    private static final String TAG = "AudioRenderingEngine";

    private final int sampleRate;
    private final int bufferSize;
    private final FloatBuffer mixBuffer;
    private final RingBuffer audioBuffer;
    private final Object lock = new Object();

    public AudioRenderingEngine(int sampleRate, int bufferSize) {
        this.sampleRate = sampleRate;
        this.bufferSize = bufferSize;
        this.mixBuffer = FloatBuffer.allocate(bufferSize);
        this.audioBuffer = new RingBuffer(bufferSize * 4);
    }

    public void processAudio(float[] input, int length) {
        synchronized (lock) {
            try {
                // Нормализация входного сигнала
                float maxAmplitude = 0.0f;
                for (int i = 0; i < length; i++) {
                    maxAmplitude = Math.max(maxAmplitude, Math.abs(input[i]));
                }

                if (maxAmplitude > 1.0f) {
                    float gain = 1.0f / maxAmplitude;
                    for (int i = 0; i < length; i++) {
                        input[i] *= gain;
                    }
                }

                // Подготовка буфера перед записью
                mixBuffer.rewind();
                mixBuffer.put(input, 0, length);

                // Запись в кольцевой буфер
                audioBuffer.write(input, 0, length);

            } catch (Exception e) {
                Log.e(TAG, "Error processing audio: " + e.getMessage());
            }
        }
    }

    public int readAudio(float[] output, int offset, int length) {
        synchronized (lock) {
            if (audioBuffer.getAvailable() == 0) {
                try {
                    Thread.sleep(1); // МедиаТек плохо обрабатывает пустые буферы
                } catch (InterruptedException e) {
                    Thread.currentThread().interrupt();
                }
                return 0;
            }
            return audioBuffer.read(output, offset, length);
        }
    }

    public void clear() {
        synchronized (lock) {
            audioBuffer.clear();
        }
    }

    private static class RingBuffer {
        private final float[] buffer;
        private int writePosition;
        private int readPosition;
        private final AtomicInteger available;

        public RingBuffer(int capacity) {
            this.buffer = new float[capacity];
            this.writePosition = 0;
            this.readPosition = 0;
            this.available = new AtomicInteger(0);
        }

        public void write(float[] data, int offset, int length) {
            int remaining = length;
            while (remaining > 0) {
                int count = Math.min(remaining, buffer.length - writePosition);
                System.arraycopy(data, offset + length - remaining, buffer, writePosition, count);
                writePosition = (writePosition + count) % buffer.length;
                remaining -= count;
                available.addAndGet(count);
            }
        }

        public int read(float[] data, int offset, int length) {
            int count = Math.min(length, available.get());
            if (count == 0) return 0;

            int remaining = count;
            while (remaining > 0) {
                int chunk = Math.min(remaining, buffer.length - readPosition);
                System.arraycopy(buffer, readPosition, data, offset + count - remaining, chunk);
                readPosition = (readPosition + chunk) % buffer.length;
                remaining -= chunk;
            }

            available.addAndGet(-count);
            return count;
        }

        public void clear() {
            writePosition = 0;
            readPosition = 0;
            available.set(0);
        }

        public int getAvailable() {
            return available.get();
        }
    }
}

И

package com.vlq.audioprocessor;

import android.app.Service;
import android.content.Intent;
import android.os.IBinder;
import android.util.Log;

public class AudioService extends Service {
    private static final String TAG = "AudioService";
    private AudioProcessor audioProcessor;

    @Override
    public void onCreate() {
        super.onCreate();
        audioProcessor = new AudioProcessor(this);
    }

    @Override
    public int onStartCommand(Intent intent, int flags, int startId) {
        if (intent != null && "com.visualdsp.UPDATE".equals(intent.getAction())) {
            int channel = intent.getIntExtra("channel", -1);
            float volume = intent.getFloatExtra("volume", -1);
            float bass = intent.getFloatExtra("bass", -1);
            boolean lpf = intent.getBooleanExtra("lpf", false);
            
            if (channel != -1) {
                updateChannel(channel, volume, bass, lpf);
            }
        }
        return START_STICKY;
    }

    private void updateChannel(int channel, float volume, float bass, boolean lpf) {
        if (audioProcessor != null) {
            if (volume >= 0) audioProcessor.setChannelVolume(channel, volume);
            if (bass >= 0) audioProcessor.setChannelBass(channel, bass);
            audioProcessor.setChannelLPF(channel, lpf);
        }
    }

    @Override
    public IBinder onBind(Intent intent) {
        return null;
    }

    @Override
    public void onDestroy() {
        if (audioProcessor != null) {
            audioProcessor.release();
            audioProcessor = null;
        }
        super.onDestroy();
    }
}

И

package com.vlq.audioprocessor;

import android.media.AudioManager;
import android.content.Context;

public class AudioSessionManager {
    private static AudioSessionManager instance;
    private AudioManager audioManager;
    private int globalAudioSessionId = -1;

    private AudioSessionManager(Context context) {
        audioManager = (AudioManager) context.getSystemService(Context.AUDIO_SERVICE);
        globalAudioSessionId = audioManager.generateAudioSessionId();
    }

    public static synchronized AudioSessionManager getInstance(Context context) {
        if (instance == null) {
            instance = new AudioSessionManager(context.getApplicationContext());
        }
        return instance;
    }

    public int getAudioSessionId() {
        return globalAudioSessionId;
    }

    public void releaseAudioSession() {
        globalAudioSessionId = -1;
    }
}

И

package com.vlq.audioprocessor;

import android.content.Context;
import android.content.SharedPreferences;

public class AudioSettings {
    private static final String PREFS_NAME = "AudioProcessorSettings";
    private static final String PREFIX_VOLUME = "volume_";
    private static final String PREFIX_BASS = "bass_";
    private static final String PREFIX_LPF = "lpf_";
    
    private final SharedPreferences preferences;
    
    public AudioSettings(Context context) {
        preferences = context.getSharedPreferences(PREFS_NAME, Context.MODE_PRIVATE);
    }
    
    public void saveChannelVolume(int channel, float volume) {
        preferences.edit().putFloat(PREFIX_VOLUME + channel, volume).apply();
    }
    
    public float getChannelVolume(int channel, float defaultValue) {
        return preferences.getFloat(PREFIX_VOLUME + channel, defaultValue);
    }
    
    public void saveChannelBass(int channel, float bass) {
        preferences.edit().putFloat(PREFIX_BASS + channel, bass).apply();
    }
    
    public float getChannelBass(int channel, float defaultValue) {
        return preferences.getFloat(PREFIX_BASS + channel, defaultValue);
    }
    
    public void saveChannelLPF(int channel, boolean enabled) {
        preferences.edit().putBoolean(PREFIX_LPF + channel, enabled).apply();
    }
    
    public boolean getChannelLPF(int channel, boolean defaultValue) {
        return preferences.getBoolean(PREFIX_LPF + channel, defaultValue);
    }
    
    public void saveAllSettings(float[] volumes, float[] bass, boolean[] lpf) {
        SharedPreferences.Editor editor = preferences.edit();
        
        for (int i = 0; i < volumes.length; i++) {
            editor.putFloat(PREFIX_VOLUME + i, volumes[i]);
            editor.putFloat(PREFIX_BASS + i, bass[i]);
            editor.putBoolean(PREFIX_LPF + i, lpf[i]);
        }
        
        editor.apply();
    }
    
    public void loadAllSettings(float[] volumes, float[] bass, boolean[] lpf) {
        for (int i = 0; i < volumes.length; i++) {
            volumes[i] = getChannelVolume(i, volumes[i]);
            bass[i] = getChannelBass(i, bass[i]);
            lpf[i] = getChannelLPF(i, lpf[i]);
        }
    }
    
    public void clearAllSettings() {
        preferences.edit().clear().apply();
    }
}

И

package com.vlq.audioprocessor;

import android.webkit.JavascriptInterface;
import android.widget.Toast;
import android.content.Context;
import android.graphics.Bitmap;
import android.os.Bundle;
import android.util.Log;
import android.view.LayoutInflater;
import android.view.View;
import android.view.ViewGroup;
import android.webkit.PermissionRequest;
import android.webkit.WebChromeClient;
import android.webkit.WebResourceRequest;
import android.webkit.WebSettings;
import android.webkit.WebView;
import android.webkit.WebViewClient;
import android.widget.EditText;
import android.widget.ImageButton;
import android.widget.ProgressBar;
import androidx.annotation.NonNull;
import androidx.annotation.Nullable;
import androidx.fragment.app.Fragment;
import android.view.inputmethod.EditorInfo;
import android.view.inputmethod.InputMethodManager;

import com.vlq.audioprocessor.R;

public class BrowserFragment extends Fragment {
    private static final String TAG = "BrowserFragment";
    
    private WebView webView;
    private EditText editTextUrl;
    private ImageButton buttonBack;
    private ImageButton buttonForward;
    private ImageButton buttonRefresh;
    private ProgressBar progressBar;
    
    private CustomWebEngine webEngine;
    private MainActivity mainActivity;
    private AudioProcessor audioProcessor;
    private boolean isProcessingEnabled = false;

    @Override
    public void onAttach(@NonNull Context context) {
        super.onAttach(context);
        if (context instanceof MainActivity) {
            mainActivity = (MainActivity) context;
            if (mainActivity.isAudioProcessorReady()) {
                audioProcessor = mainActivity.getAudioProcessor();
            }
        } else {
            throw new RuntimeException("Must be attached to MainActivity");
        }
    }

    @Nullable
    @Override
    public View onCreateView(@NonNull LayoutInflater inflater, @Nullable ViewGroup container, 
                            @Nullable Bundle savedInstanceState) {
        View view = inflater.inflate(R.layout.fragment_browser, container, false);
        initializeViews(view);
        setupWebEngine();
        setupWebView();
        setupControls();
        return view;
    }

    private void initializeViews(View view) {
        webView = view.findViewById(R.id.webView);
        editTextUrl = view.findViewById(R.id.editTextUrl);
        buttonBack = view.findViewById(R.id.buttonBack);
        buttonForward = view.findViewById(R.id.buttonForward);
        buttonRefresh = view.findViewById(R.id.buttonRefresh);
        progressBar = view.findViewById(R.id.progressBar);

        progressBar.setVisibility(View.GONE);
        buttonBack.setEnabled(false);
        buttonForward.setEnabled(false);
    }

    private void setupWebEngine() {
        if (audioProcessor != null) {
            webEngine = new CustomWebEngine(requireContext(), audioProcessor);
            webEngine.setAudioProcessor(audioProcessor);
            isProcessingEnabled = true;
        }
    }

    private void setupWebView() {
    if (webView != null) {
        WebSettings settings = webView.getSettings();
        settings.setJavaScriptEnabled(true);
        settings.setMediaPlaybackRequiresUserGesture(false);
        settings.setDomStorageEnabled(true);
        settings.setLoadWithOverviewMode(true);
        settings.setUseWideViewPort(true);
        settings.setCacheMode(WebSettings.LOAD_DEFAULT);
        settings.setAllowFileAccess(true);
        settings.setAllowContentAccess(true);
        settings.setDatabaseEnabled(true);
        settings.setLoadsImagesAutomatically(true);
        settings.setMixedContentMode(WebSettings.MIXED_CONTENT_ALWAYS_ALLOW);

        webView.addJavascriptInterface(new AudioBridge(), "AudioBridge");
        webView.setWebViewClient(new CustomWebViewClient());
        webView.setWebChromeClient(new CustomWebChromeClient());

        if (webEngine != null) {
            webEngine.attachWebView(webView);
            if (mainActivity != null) {
                mainActivity.attachWebViewToAudioCapture(webView);
            }
        }
    }
}
    
private class AudioBridge {
    private long lastToastTime = 0;
    private final long TOAST_INTERVAL = 1000; // 1 секунда между сообщениями

    private void logAudioProcessing(float[] audioData) {
        if (audioData != null) {
            float maxAmplitude = 0;
            for (float sample : audioData) {
                maxAmplitude = Math.max(maxAmplitude, Math.abs(sample));
            }
            Log.d(TAG, String.format("Audio bridge: buffer size=%d, max amplitude=%.4f, processor ready=%b",
                audioData.length,
                maxAmplitude,
                audioProcessor != null));
        }
    }

    @android.webkit.JavascriptInterface
    public void processAudio(float[] audioData) {
        if (audioProcessor != null) {
            try {
                // Обработка аудио
                audioProcessor.processAudio(audioData);
                
                // Показываем Toast не чаще чем раз в секунду
                long currentTime = System.currentTimeMillis();
                if (currentTime - lastToastTime > TOAST_INTERVAL) {
                    lastToastTime = currentTime;
                    
                    // Получаем уровни каналов
                    final float[] volumes = audioProcessor.getChannelVolumes();
                    
                    // Создаем сообщение для Toast
                    final String message = String.format(
                        "Audio processing: Buffer=%d, L=%.2f, R=%.2f",
                        audioData.length,
                        volumes[0],
                        volumes[1]
                    );
                    
                    // Показываем Toast в UI потоке
                    if (mainActivity != null) {
                        mainActivity.runOnUiThread(new Runnable() {
                            @Override
                            public void run() {
                                Toast.makeText(mainActivity, message, Toast.LENGTH_SHORT).show();
                            }
                        });
                    }
                }
                
            } catch (Exception e) {
                final String errorMsg = "Error: " + e.getMessage();
                if (mainActivity != null) {
                    mainActivity.runOnUiThread(new Runnable() {
                        @Override
                        public void run() {
                            Toast.makeText(mainActivity, errorMsg, Toast.LENGTH_LONG).show();
                        }
                    });
                }
            }
        } else {
            if (mainActivity != null) {
                mainActivity.runOnUiThread(new Runnable() {
                    @Override
                    public void run() {
                        Toast.makeText(mainActivity, "AudioProcessor is null!", Toast.LENGTH_LONG).show();
                    }
                });
            }
        }
    }
}

    private void setupControls() {
        editTextUrl.setOnEditorActionListener((v, actionId, event) -> {
            if (actionId == EditorInfo.IME_ACTION_GO) {
                loadUrl(editTextUrl.getText().toString());
                hideKeyboard();
                return true;
            }
            return false;
        });

        buttonBack.setOnClickListener(v -> {
            if (webView != null && webView.canGoBack()) {
                webView.goBack();
            }
        });

        buttonForward.setOnClickListener(v -> {
            if (webView != null && webView.canGoForward()) {
                webView.goForward();
            }
        });

        buttonRefresh.setOnClickListener(v -> {
            if (webView != null) {
                webView.reload();
            }
        });
    }

    
    private class CustomWebViewClient extends WebViewClient {
        @Override
        public void onPageStarted(WebView view, String url, Bitmap favicon) {
            progressBar.setVisibility(View.VISIBLE);
            editTextUrl.setText(url);
            updateNavigationButtons();
        }

        @Override
        public void onPageFinished(WebView view, String url) {
            progressBar.setVisibility(View.GONE);
            updateNavigationButtons();
            
            if (webEngine != null && !webEngine.isProcessing() && isProcessingEnabled) {
                webEngine.startProcessing();
                if (audioProcessor != null) {
                    audioProcessor.setWebAudioEnabled(true);
                }
            }
        }

        @Override
        public boolean shouldOverrideUrlLoading(WebView view, WebResourceRequest request) {
            view.loadUrl(request.getUrl().toString());
            return true;
        }
    }

    private class CustomWebChromeClient extends WebChromeClient {
        @Override
        public void onProgressChanged(WebView view, int newProgress) {
            if (progressBar != null) {
                progressBar.setProgress(newProgress);
            }
        }

        @Override
        public void onPermissionRequest(PermissionRequest request) {
            if (getActivity() != null) {
                getActivity().runOnUiThread(() -> {
                    String[] resources = request.getResources();
                    request.grant(resources);
                });
            }
        }
    }

    private void loadUrl(String url) {
        if (webView != null) {
            if (!url.startsWith("http://") && !url.startsWith("https://")) {
                url = "https://" + url;
            }
            webView.loadUrl(url);
        }
    }

    private void hideKeyboard() {
        if (getActivity() != null && editTextUrl != null) {
            InputMethodManager imm = (InputMethodManager) getActivity()
                    .getSystemService(Context.INPUT_METHOD_SERVICE);
            if (imm != null) {
                imm.hideSoftInputFromWindow(editTextUrl.getWindowToken(), 0);
            }
        }
    }

    private void updateNavigationButtons() {
        if (webView != null) {
            buttonBack.setEnabled(webView.canGoBack());
            buttonForward.setEnabled(webView.canGoForward());
        }
    }

    public void startAudioProcessing() {
        if (webEngine != null && !webEngine.isProcessing() && isProcessingEnabled) {
            webEngine.startProcessing();
            if (audioProcessor != null) {
                audioProcessor.setWebAudioEnabled(true);
            }
        }
    }

    public void stopAudioProcessing() {
        if (webEngine != null) {
            webEngine.stopProcessing();
            if (audioProcessor != null) {
                audioProcessor.setWebAudioEnabled(false);
            }
        }
    }

    @Override
    public void onResume() {
        super.onResume();
        if (webView != null) {
            webView.onResume();
        }
        startAudioProcessing();
    }

    @Override
    public void onPause() {
        if (webView != null) {
            webView.onPause();
        }
        stopAudioProcessing();
        super.onPause();
    }

    @Override
    public void onDestroy() {
        stopAudioProcessing();
        
        if (webEngine != null) {
            webEngine.release();
            webEngine = null;
        }
        
        if (webView != null) {
            webView.destroy();
            webView = null;
        }
        
        audioProcessor = null;
        super.onDestroy();
    }

    public boolean canGoBack() {
        return webView != null && webView.canGoBack();
    }

    public void goBack() {
        if (canGoBack()) {
            webView.goBack();
        }
    }
}

И

package com.vlq.audioprocessor;

public class CrossoverFilter {
    public static final int TYPE_LOWPASS = 0;
    public static final int TYPE_HIGHPASS = 1;
    public static final int TYPE_BANDPASS = 2;
    public static final int TYPE_PEAK = 3;
    public static final int TYPE_NOTCH = 4;
    
    private static final float STABILITY_THRESHOLD = 0.999f;
    private static final float MIN_Q = 0.1f;
    private static final float MAX_Q = 20.0f;
    private float resonance = 0.707f;
    
    private final float[] b = new float[3];
    private final float[] a = new float[3];
    private final float[] x = new float[3];
    private final float[] y = new float[3];
    
    private float frequency;
    private float sampleRate;
    private float Q;
    private float gain;
    private int type;
    private boolean enabled;
    private final Object processLock = new Object();

    public CrossoverFilter(int type, float frequency, float sampleRate) {
        this.type = type;
        this.frequency = Math.max(AudioProcessorInterface.MIN_FREQUENCY,
                                Math.min(AudioProcessorInterface.MAX_FREQUENCY, frequency));
        this.sampleRate = sampleRate;
        this.Q = 0.707f; // Butterworth по умолчанию
        this.gain = 1.0f;
        this.enabled = true;
        calculateCoefficients();
    }

    public void setResonance(float newResonance) {
        synchronized (processLock) {
            this.resonance = Math.max(MIN_Q, Math.min(MAX_Q, newResonance));
            calculateCoefficients();
        }
    }

    public float getResonance() {
        return resonance;
    }

    private void calculateCoefficients() {
        float omega = 2.0f * (float)Math.PI * frequency / sampleRate;
        float sn = (float)Math.sin(omega);
        float cs = (float)Math.cos(omega);
        float alpha = sn / (2.0f * Q);
        float A = (float)Math.pow(10.0, gain / 40.0);

        // Нормализующий коэффициент
        float a0;

        switch (type) {
            case TYPE_LOWPASS:
                a0 = 1.0f + alpha;
                b[0] = ((1.0f - cs) / 2.0f) / a0;
                b[1] = (1.0f - cs) / a0;
                b[2] = ((1.0f - cs) / 2.0f) / a0;
                a[1] = (-2.0f * cs) / a0;
                a[2] = (1.0f - alpha) / a0;
                break;

            case TYPE_HIGHPASS:
                a0 = 1.0f + alpha;
                b[0] = ((1.0f + cs) / 2.0f) / a0;
                b[1] = -(1.0f + cs) / a0;
                b[2] = ((1.0f + cs) / 2.0f) / a0;
                a[1] = (-2.0f * cs) / a0;
                a[2] = (1.0f - alpha) / a0;
                break;

            case TYPE_BANDPASS:
                a0 = 1.0f + alpha;
                b[0] = alpha / a0;
                b[1] = 0;
                b[2] = -alpha / a0;
                a[1] = (-2.0f * cs) / a0;
                a[2] = (1.0f - alpha) / a0;
                break;

            case TYPE_PEAK:
                a0 = 1.0f + alpha/A;
                b[0] = (1.0f + alpha*A) / a0;
                b[1] = (-2.0f * cs) / a0;
                b[2] = (1.0f - alpha*A) / a0;
                a[1] = (-2.0f * cs) / a0;
                a[2] = (1.0f - alpha/A) / a0;
                break;

            case TYPE_NOTCH:
                a0 = 1.0f + alpha;
                b[0] = 1.0f / a0;
                b[1] = (-2.0f * cs) / a0;
                b[2] = 1.0f / a0;
                a[1] = (-2.0f * cs) / a0;
                a[2] = (1.0f - alpha) / a0;
                break;
        }

        // Проверка стабильности
        stabilizeCoefficients();
    }

    private void stabilizeCoefficients() {
        // Предотвращение нестабильности фильтра
        float sum = Math.abs(a[1]) + Math.abs(a[2]);
        if (sum >= STABILITY_THRESHOLD) {
            float scale = STABILITY_THRESHOLD / sum;
            a[1] *= scale;
            a[2] *= scale;
        }
    }

    public float process(float input) {
        if (!enabled) return input;

        synchronized (processLock) {
            // Сдвиг буферов
            x[2] = x[1];
            x[1] = x[0];
            x[0] = input;

            y[2] = y[1];
            y[1] = y[0];

            // Применение фильтра с проверкой переполнения
            float output = b[0] * x[0] + b[1] * x[1] + b[2] * x[2]
                    - a[1] * y[1] - a[2] * y[2];

            // Обработка ошибок и клиппинга
            if (Float.isNaN(output) || Float.isInfinite(output)) {
                reset();
                return input;
            }

            // Мягкое ограничение
            output = softClip(output);
            y[0] = output;

            return output;
        }
    }

    private float softClip(float input) {
        // Мягкое ограничение для предотвращения искажений
        if (input > 1.0f) {
            return 1.0f - (1.0f / (input + 1.0f));
        } else if (input < -1.0f) {
            return -1.0f + (1.0f / (-input + 1.0f));
        }
        return input;
    }

    
    
    public void setFrequency(float freq) {
        synchronized (processLock) {
            freq = Math.max(AudioProcessorInterface.MIN_FREQUENCY,
                          Math.min(AudioProcessorInterface.MAX_FREQUENCY, freq));
            if (this.frequency != freq) {
                this.frequency = freq;
                calculateCoefficients();
            }
        }
    }

    public void setSampleRate(float rate) {
        synchronized (processLock) {
            if (rate > 0 && this.sampleRate != rate) {
                this.sampleRate = rate;
                calculateCoefficients();
            }
        }
    }

    public void setQ(float Q) {
        synchronized (processLock) {
            Q = Math.max(MIN_Q, Math.min(MAX_Q, Q));
            if (this.Q != Q) {
                this.Q = Q;
                calculateCoefficients();
            }
        }
    }

    public void setGain(float gainDB) {
        synchronized (processLock) {
            if (this.gain != gainDB) {
                this.gain = gainDB;
                calculateCoefficients();
            }
        }
    }

    public void setType(int type) {
        synchronized (processLock) {
            if (this.type != type && isValidType(type)) {
                this.type = type;
                calculateCoefficients();
            }
        }
    }

    private boolean isValidType(int type) {
        return type >= TYPE_LOWPASS && type <= TYPE_NOTCH;
    }

    public void setEnabled(boolean enabled) {
        synchronized (processLock) {
            if (this.enabled != enabled) {
                this.enabled = enabled;
                if (enabled) {
                    calculateCoefficients();
                } else {
                    reset();
                }
            }
        }
    }

    public void reset() {
        synchronized (processLock) {
            for (int i = 0; i < 3; i++) {
                x[i] = 0;
                y[i] = 0;
            }
        }
    }

    // Геттеры
    public float getFrequency() { return frequency; }
    public float getSampleRate() { return sampleRate; }
    public float getQ() { return Q; }
    public float getGain() { return gain; }
    public int getType() { return type; }
    public boolean isEnabled() { return enabled; }

    public void release() {
        setEnabled(false);
        reset();
    }

    public void update() {
        if (enabled) {
            calculateCoefficients();
        }
    }
}

И

package com.vlq.audioprocessor;

import android.content.Context;
import android.media.AudioAttributes;
import android.media.AudioFormat;
import android.media.AudioManager;
import android.media.AudioTrack;
import android.media.MediaCodec;
import android.media.MediaExtractor;
import android.media.MediaFormat;
import android.os.Build;
import android.util.Log;
import android.webkit.WebView;
import java.nio.FloatBuffer;
import java.util.concurrent.ArrayBlockingQueue;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.Queue;
import java.util.concurrent.LinkedBlockingQueue;
import java.util.concurrent.atomic.AtomicLong;
import java.util.concurrent.atomic.AtomicInteger;
import android.os.Handler;
import android.os.Looper;
import android.webkit.JavascriptInterface;
import android.webkit.WebSettings;
import android.app.Activity;

public class CustomWebEngine {
    private static final String TAG = "CustomWebEngine";
    private static final String ENGINE_NAME = "VLQWebEngine";
    private static final int SAMPLE_RATE = 48000;
    private static final int BUFFER_SIZE = AudioTrack.getMinBufferSize(
            SAMPLE_RATE,
            AudioFormat.CHANNEL_OUT_STEREO,
            AudioFormat.ENCODING_PCM_FLOAT) * 2;
    private static final float PROCESSING_GAIN = 1.0f;
    private static final float SMOOTHING_FACTOR = 0.15f;

    private final Context context;
    private AudioProcessor audioProcessor;
    private final AudioManager audioManager;
    private final ExecutorService audioExecutor;
    private final ArrayBlockingQueue<FloatBuffer> audioQueue;
    private final AtomicBoolean isProcessing;
    private final Object lock = new Object();
    private final FloatBuffer tempBuffer;
    private final Activity mainActivity;
    private float[] previousBuffer = null;
    private final AtomicInteger errorCount = new AtomicInteger(0);
private static final int MAX_ERRORS = 5;
private final Object processingLock = new Object();

    // Добавленные поля для аудио системы
    private AudioAttributes audioAttributes;
    private AudioFormat audioFormat;
    private int audioSessionId;
    
    private AudioRenderingEngine audioEngine;
    private MediaCodec audioDecoder;
    private MediaExtractor extractor;
    private AudioTrack audioTrack;
    private WebView attachedWebView;
    private int sessionId = -1;
    private boolean isWebViewAttached = false;
    private float systemVolume = 0f;
    

    public interface AudioCallback {
        void onAudioData(float[] audioData, int length);
    }

    private AudioCallback audioCallback;

    public CustomWebEngine(Context context, AudioProcessor processor) {
    this.context = context;
    this.mainActivity = (Activity) context;
        this.audioProcessor = processor;
        this.audioManager = (AudioManager) context.getSystemService(Context.AUDIO_SERVICE);
        this.audioExecutor = Executors.newSingleThreadExecutor();
        this.audioQueue = new ArrayBlockingQueue<>(16); // Увеличен размер очереди
        this.isProcessing = new AtomicBoolean(false);
        this.tempBuffer = FloatBuffer.allocate(BUFFER_SIZE);
        
        // Принудительная маршрутизация через процессор
        if (audioManager != null) {
            audioManager.setParameters("MTK_AUDIO_PATH=processor");
            audioManager.setParameters("MTK_STREAM_TYPE=AUDIO_STREAM_PROC");
            audioManager.setParameters("SET_FORCE_ROUTE=1");
            // Сохраняем текущую громкость системы
            systemVolume = audioManager.getStreamVolume(AudioManager.STREAM_MUSIC);
        }
        
        Log.d(TAG, "CustomWebEngine initialized with buffer size: " + BUFFER_SIZE);
        
        initializeAudioEngine();
        setupMediaCodecs();
    }

    private void initializeAudioEngine() {
        try {
            if (audioManager != null) {
                // Настройка процессора MediaTek
                audioManager.setParameters("MTK_AUDIO_PATH=processor");
                audioManager.setParameters("MTK_AUDIO_TRACK_DIRECT=0");
                audioManager.setParameters("SET_FORCE_ROUTE=1");
                audioManager.setParameters("MTK_AUDIO_TRACK_LOW_LATENCY=1");
                audioManager.setParameters("MTK_LOW_LATENCY=1");
                audioManager.setParameters("SET_WEBAUDIO_ENABLE=1");
                audioManager.setParameters("WebAudio_Stream_Control=1");
                
                // Настройка режима аудио
                audioManager.setMode(AudioManager.MODE_NORMAL);
                audioManager.setSpeakerphoneOn(true);
                audioManager.setStreamVolume(AudioManager.STREAM_MUSIC, 0, 0);
                audioManager.setStreamMute(AudioManager.STREAM_MUSIC, true);
            }

            // Настройка аудио формата
            AudioAttributes playbackAttributes = new AudioAttributes.Builder()
                .setUsage(AudioAttributes.USAGE_MEDIA)
                .setContentType(AudioAttributes.CONTENT_TYPE_MUSIC)
             
                .build();

            AudioFormat audioFormat = new AudioFormat.Builder()
                .setEncoding(AudioFormat.ENCODING_PCM_FLOAT)
                .setSampleRate(SAMPLE_RATE)
                .setChannelMask(AudioFormat.CHANNEL_OUT_STEREO)
                .build();

            int bufferSize = AudioTrack.getMinBufferSize(
                SAMPLE_RATE,
                AudioFormat.CHANNEL_OUT_STEREO,
                AudioFormat.ENCODING_PCM_FLOAT
            );

            // Создание аудио трека
            audioTrack = new AudioTrack.Builder()
                .setAudioAttributes(playbackAttributes)
                .setAudioFormat(audioFormat)
                .setBufferSizeInBytes(bufferSize * 2) // Увеличенный буфер для стабильности
                .setTransferMode(AudioTrack.MODE_STREAM)
                .setPerformanceMode(AudioTrack.PERFORMANCE_MODE_LOW_LATENCY)
                .build();

            audioTrack.play();

        } catch (Exception e) {
            Log.e(TAG, "Error initializing audio engine: " + e.getMessage());
        }
    }
    
    private void setupMediaCodecs() {
        try {
            audioDecoder = MediaCodec.createDecoderByType(MediaFormat.MIMETYPE_AUDIO_AAC);
            MediaFormat format = new MediaFormat();
            format.setString(MediaFormat.KEY_MIME, MediaFormat.MIMETYPE_AUDIO_AAC);
            format.setInteger(MediaFormat.KEY_SAMPLE_RATE, SAMPLE_RATE);
            format.setInteger(MediaFormat.KEY_CHANNEL_COUNT, 2);
            audioDecoder.configure(format, null, null, 0);
            audioDecoder.start();
        } catch (Exception e) {
            Log.e(TAG, "Error setting up media codecs: " + e.getMessage());
        }
    }

    public void attachWebView(WebView webView) {
        synchronized (lock) {
            if (this.attachedWebView != null) {
                detachWebView();
            }
            this.attachedWebView = attachedWebView;
            if (attachedWebView != null) {
                setupWebView();
                isWebViewAttached = true;
            }
        }
    }

    public void detachWebView() {
        synchronized (lock) {
            if (attachedWebView != null) {
                stopProcessing();
                attachedWebView.post(() -> {
                    attachedWebView.evaluateJavascript(
                        "if(window.audioContext) {" +
                        "    window.masterGain.disconnect();" +
                        "    window.audioContext.close();" +
                        "    console.log('Audio context closed');" +
                        "}", null
                    );
                });
                attachedWebView.removeJavascriptInterface("AudioBridge");
                attachedWebView = null;
                isWebViewAttached = false;
            }
        }
    }

    public boolean isWebViewAttached() {
        synchronized (lock) {
            return isWebViewAttached && attachedWebView != null &&
                   attachedWebView.getSettings().getJavaScriptEnabled();
        }
    }
    
    private void setupWebAudioIsolation() {
    if (attachedWebView != null) {
        String script = 
            "javascript:(function() {" +
            // Перехватываем все аудиопотоки
            "    const origCreateElement = document.createElement.bind(document);" +
            "    document.createElement = function(tag) {" +
            "        const el = origCreateElement(tag);" +
            "        if (tag.toLowerCase() === 'audio' || tag.toLowerCase() === 'video') {" +
            "            Object.defineProperties(el, {" +
            "                volume: {" +
            "                    value: 0," +
            "                    writable: false," +
            "                    configurable: false" +
            "                }," +
            "                muted: {" +
            "                    value: true," +
            "                    writable: false," +
            "                    configurable: false" +
            "                }," +
            "                defaultMuted: {" +
            "                    value: true," +
            "                    writable: false," +
            "                    configurable: false" +
            "                }" +
            "            });" +
            
            "            const ctx = new (window.AudioContext || window.webkitAudioContext)({" +
            "                sampleRate: 48000," +
            "                latencyHint: 'interactive'" +
            "            });" +
            
            "            const source = ctx.createMediaElementSource(el);" +
            "            const processor = ctx.createScriptProcessor(4096, 2, 2);" +
            
            "            processor.onaudioprocess = function(e) {" +
            "                const inputL = e.inputBuffer.getChannelData(0);" +
            "                const inputR = e.inputBuffer.getChannelData(1);" +
            "                const buffer = new Float32Array(inputL.length * 2);" +
            
            "                for(let i = 0; i < inputL.length; i++) {" +
            "                    buffer[i * 2] = inputL[i];" +
            "                    buffer[i * 2 + 1] = inputR[i];" +
            "                }" +
            
            "                AudioBridge.processAudio(buffer);" +
            
            "                const outputL = e.outputBuffer.getChannelData(0);" +
            "                const outputR = e.outputBuffer.getChannelData(1);" +
            "                outputL.fill(0);" +
            "                outputR.fill(0);" +
            "            };" +
            
            "            source.connect(processor);" +
            "            processor.connect(ctx.destination);" +
            "        }" +
            "        return el;" +
            "    };" +
            
            // Блокируем все попытки воспроизведения звука напрямую
            "    const audioAPI = ['setVolume', 'play', 'unmute'];" +
            "    audioAPI.forEach(method => {" +
            "        window[method] = function() { return false; };" +
            "    });" +
            
            // Наблюдатель за DOM
            "    new MutationObserver((mutations) => {" +
            "        mutations.forEach(mutation => {" +
            "            mutation.addedNodes.forEach(node => {" +
            "                if (node instanceof HTMLMediaElement) {" +
            "                    node.volume = 0;" +
            "                    node.muted = true;" +
            "                }" +
            "            });" +
            "        });" +
            "    }).observe(document, {" +
            "        childList: true," +
            "        subtree: true" +
            "    });" +
            "})();";

        attachedWebView.evaluateJavascript(script, null);
    }
}
    
    private void handleProcessingError() {
    if (errorCount.incrementAndGet() > MAX_ERRORS) {
        try {
            reinitializeAudioTrack();
        } catch (Exception e) {
            Log.e(TAG, "Error reinitializing audio track: " + e.getMessage());
        }
        errorCount.set(0);
    }
}
    
    private void setupWebViewAudioBridge(WebView webView) {
    webView.evaluateJavascript(
        "if(window.audioContext) window.audioContext.close();" +
        "window.audioContext = new (window.AudioContext || window.webkitAudioContext)({" +
        "    sampleRate: " + SAMPLE_RATE + "," +
        "    latencyHint: 'interactive'" +
        "});" +
        "window.audioContext.destination.channelCount = 2;" + 
        "window.audioContext.destination.channelCountMode = 'explicit';" +
        "window.audioContext.destination.channelInterpretation = 'speakers';" +
        "document.querySelectorAll('audio,video').forEach(el => {" +
        "    el.volume = 0;" +
        "    el.muted = true;" +
        "    if(el.audioContext) el.audioContext.close();" +
        "    el.audioContext = window.audioContext;" +
        "});",
        null
    );
}

private void setupWebView() {
    if (attachedWebView != null) {
        WebSettings settings = attachedWebView.getSettings();
        settings.setJavaScriptEnabled(true);
        settings.setMediaPlaybackRequiresUserGesture(false);
        
        String script = 
            "javascript:(function() {" +
            "    const origAudioContext = window.AudioContext || window.webkitAudioContext;" +
            "    class CustomAudioContext extends origAudioContext {" +
            "        constructor() {" +
            "            super({" +
            "                sampleRate: 48000," +
            "                latencyHint: 'interactive'" +
            "            });" +
            
            "            const processor = this.createScriptProcessor(4096, 2, 2);" +
            "            const destination = super.destination;" +
            
            "            processor.onaudioprocess = (e) => {" +
            "                try {" +
            "                    const inputL = e.inputBuffer.getChannelData(0);" +
            "                    const inputR = e.inputBuffer.getChannelData(1);" +
            "                    const buffer = new Float32Array(inputL.length * 2);" +
            
            "                    for(let i = 0; i < inputL.length; i++) {" +
            "                        buffer[i * 2] = inputL[i];" +
            "                        buffer[i * 2 + 1] = inputR[i];" +
            "                    }" +
            
            "                    AudioBridge.processAudio(buffer);" +
            
            "                    const outputL = e.outputBuffer.getChannelData(0);" +
            "                    const outputR = e.outputBuffer.getChannelData(1);" +
            "                    outputL.fill(0);" +
            "                    outputR.fill(0);" +
            "                } catch(err) {" +
            "                    console.error('Audio processing error:', err);" +
            "                }" +
            "            };" +

            // Перенаправляем весь звук через наш процессор
            "            Object.defineProperty(this, 'destination', {" +
            "                get: () => processor" +
            "            });" +
            "        }" +
            "    }" +

            "    window.AudioContext = CustomAudioContext;" +
            "    window.webkitAudioContext = CustomAudioContext;" +

            // Перехват создания медиа элементов
            "    const origCreateElement = document.createElement.bind(document);" +
            "    document.createElement = function(tag) {" +
            "        const el = origCreateElement(tag);" +
            "        if (tag.toLowerCase() === 'audio' || tag.toLowerCase() === 'video') {" +
            "            const ctx = new CustomAudioContext();" +
            "            const source = ctx.createMediaElementSource(el);" +
            "            source.connect(ctx.destination);" +
            "        }" +
            "        return el;" +
            "    };" +

            // Наблюдатель за DOM
            "    new MutationObserver((mutations) => {" +
            "        mutations.forEach(mutation => {" +
            "            mutation.addedNodes.forEach(node => {" +
            "                if (node instanceof HTMLMediaElement && !node.processed) {" +
            "                    node.processed = true;" +
            "                    const ctx = new CustomAudioContext();" +
            "                    const source = ctx.createMediaElementSource(node);" +
            "                    source.connect(ctx.destination);" +
            "                }" +
            "            });" +
            "        });" +
            "    }).observe(document, {" +
            "        childList: true," +
            "        subtree: true" +
            "    });" +

            "})();";

        attachedWebView.evaluateJavascript(script, null);
    }
}
    
    @JavascriptInterface
public void processAudio(float[] audioData) {
    if (!isProcessing.get() || audioProcessor == null) return;

    try {
        // Нормализация входного сигнала
        float maxAmplitude = 0;
        for (float sample : audioData) {
            maxAmplitude = Math.max(maxAmplitude, Math.abs(sample));
        }

        if (maxAmplitude > 1.0f) {
            float gain = 1.0f / maxAmplitude;
            for (int i = 0; i < audioData.length; i++) {
                audioData[i] *= gain;
            }
        }

        // Отправляем на обработку через матричный процессор
        audioProcessor.processWebAudio(audioData, audioData.length);

    } catch (Exception e) {
        Log.e(TAG, "Error in processAudio: " + e.getMessage());
        handleProcessingError();
    }
}
    
        private class AudioBridge {
    private static final int MIN_BUFFER_SIZE = 8192; // Увеличенный буфер для MIUI/MediaTek
    private final float[] tempBuffer = new float[MIN_BUFFER_SIZE];
    private long lastProcessTime = 0;
    private static final long MIN_PROCESS_INTERVAL = 5000000; // 5ms в наносекундах
    private final Object processLock = new Object();
    private int errorCount = 0;
    private static final int MAX_ERRORS = 5;
    private final BufferQueue bufferQueue = new BufferQueue(4);

    @JavascriptInterface
    public void processAudio(float[] audioData) {
        if (audioProcessor == null || audioData == null || audioData.length == 0) {
            return;
        }

        long currentTime = System.nanoTime();
        if (currentTime - lastProcessTime < MIN_PROCESS_INTERVAL) {
            bufferQueue.offer(audioData); // Буферизуем данные если интервал слишком мал
            return;
        }

        synchronized (processLock) {
            try {
                lastProcessTime = currentTime;

                // Отключаем системный звук
                if (mainActivity != null) {
                    mainActivity.runOnUiThread(() -> {
                        AudioManager audioManager = (AudioManager) mainActivity
                            .getSystemService(Context.AUDIO_SERVICE);
                        if (audioManager != null) {
                            audioManager.setStreamVolume(AudioManager.STREAM_MUSIC, 0, 0);
                            audioManager.setStreamMute(AudioManager.STREAM_MUSIC, true);
                        }
                    });
                }

                // Нормализация входных данных
                float maxAmplitude = 0.0f;
                for (float sample : audioData) {
                    maxAmplitude = Math.max(maxAmplitude, Math.abs(sample));
                }

                if (maxAmplitude > 1.0f) {
                    float gain = 1.0f / maxAmplitude;
                    for (int i = 0; i < audioData.length; i++) {
                        audioData[i] *= gain;
                    }
                }

                // Обработка текущих данных
                audioProcessor.processWebAudio(audioData, audioData.length);

                // Обработка накопленных данных из очереди
                while (!bufferQueue.isEmpty()) {
                    float[] queuedData = bufferQueue.poll();
                    if (queuedData != null) {
                        audioProcessor.processWebAudio(queuedData, queuedData.length);
                    }
                }

                errorCount = 0;

            } catch (Exception e) {
                Log.e(TAG, "Error processing web audio: " + e.getMessage());
                errorCount++;
                
                if (errorCount >= MAX_ERRORS) {
                    // Восстановление аудио системы
                    try {
                        if (audioProcessor != null) {
                            audioProcessor.reinitializeAudioOutput();
                        }
                        if (attachedWebView != null) {
                            attachedWebView.post(() -> {
                                attachedWebView.evaluateJavascript(
                                    "if(window.audioContext) {" +
                                    "    audioContext.close();" +
                                    "    window.audioContext = new (window.AudioContext || window.webkitAudioContext)();" +
                                    "}", null
                                );
                            });
                        }
                    } catch (Exception recoverError) {
                        Log.e(TAG, "Error recovering audio system: " + recoverError.getMessage());
                    }
                    errorCount = 0;
                }
            }
        }
    }

    // Вспомогательный класс для буферизации
    private class BufferQueue {
        private final Queue<float[]> queue;
        private final int capacity;
        private final Object queueLock = new Object();

        BufferQueue(int capacity) {
            this.capacity = capacity;
            this.queue = new LinkedBlockingQueue<>(capacity);
        }

        void offer(float[] data) {
            synchronized (queueLock) {
                if (queue.size() >= capacity) {
                    queue.poll(); // Удаляем старые данные если очередь полна
                }
                queue.offer(data.clone());
            }
        }

        float[] poll() {
            synchronized (queueLock) {
                return queue.poll();
            }
        }

        boolean isEmpty() {
            synchronized (queueLock) {
                return queue.isEmpty();
            }
        }

        void clear() {
            synchronized (queueLock) {
                queue.clear();
            }
        }
    }
}
    
    public void reinitializeAudioOutput() {
        synchronized (processingLock) {
            try {
                if (audioTrack != null) {
                    audioTrack.stop();
                    audioTrack.flush();
                    audioTrack.release();
                }

                int minBuffer = AudioTrack.getMinBufferSize(
                    SAMPLE_RATE,
                    AudioFormat.CHANNEL_OUT_STEREO,
                    AudioFormat.ENCODING_PCM_FLOAT
                );

                AudioAttributes attributes = new AudioAttributes.Builder()
                    .setUsage(AudioAttributes.USAGE_MEDIA)
                    .setContentType(AudioAttributes.CONTENT_TYPE_MUSIC)
                    .setFlags(AudioAttributes.FLAG_LOW_LATENCY)
                    .build();

                AudioFormat format = new AudioFormat.Builder()
                    .setEncoding(AudioFormat.ENCODING_PCM_FLOAT)
                    .setSampleRate(SAMPLE_RATE)
                    .setChannelMask(AudioFormat.CHANNEL_OUT_STEREO)
                    .build();

                audioTrack = new AudioTrack.Builder()
                    .setAudioAttributes(attributes)
                    .setAudioFormat(format)
                    .setBufferSizeInBytes(minBuffer * 2)
                    .setTransferMode(AudioTrack.MODE_STREAM)
                    .setPerformanceMode(AudioTrack.PERFORMANCE_MODE_LOW_LATENCY)
                    .build();

                if (audioTrack.getState() == AudioTrack.STATE_INITIALIZED) {
                    audioTrack.play();
                }
            } catch (Exception e) {
                Log.e(TAG, "Error in reinitializeAudioTrack: " + e.getMessage());
            }
        }
    }

    private void handleError() {
        if (errorCount.incrementAndGet() > MAX_ERRORS) {
            try {
                reinitializeAudioTrack();
            } catch (Exception e) {
                Log.e(TAG, "Error reinitializing AudioTrack: " + e.getMessage());
                restartAudioProcessing();
            }
            errorCount.set(0);
        }
    }

    
    private class BufferQueue {
        private final Queue<float[]> queue;
        private final int capacity;
        private final Object queueLock = new Object();

        BufferQueue(int capacity) {
            this.capacity = capacity;
            this.queue = new LinkedBlockingQueue<>(capacity);
        }

        void offer(float[] data) {
            synchronized (queueLock) {
                if (queue.size() >= capacity) {
                    queue.poll();
                }
                float[] copy = data.clone();
                queue.offer(copy);
            }
        }

        float[] poll() {
            synchronized (queueLock) {
                return queue.poll();
            }
        }

        boolean isEmpty() {
            synchronized (queueLock) {
                return queue.isEmpty();
            }
        }

        void clear() {
            synchronized (queueLock) {
                queue.clear();
            }
        }
    }

    
    private float[] smoothTransition(float[] buffer) {
        if (previousBuffer == null) {
            previousBuffer = new float[buffer.length];
            return buffer;
        }
        
        float[] smoothed = new float[buffer.length];
        for (int i = 0; i < buffer.length; i++) {
            smoothed[i] = buffer[i] * (1 - SMOOTHING_FACTOR) + 
                         previousBuffer[i] * SMOOTHING_FACTOR;
        }
        return smoothed;
    }
    
    private boolean isMediaTek() {
        String processor = Build.HARDWARE.toLowerCase();
        return processor.contains("mt") || processor.contains("mediatek");
    }
    
    private void resetAudioTrack() {
        try {
            if (audioTrack != null) {
                audioTrack.release();
            }
            
            AudioAttributes attributes = new AudioAttributes.Builder()
                .setUsage(AudioAttributes.USAGE_MEDIA)
                .setContentType(AudioAttributes.CONTENT_TYPE_MUSIC)
                .build();
                
            AudioFormat format = new AudioFormat.Builder()
                .setSampleRate(48000)
                .setEncoding(AudioFormat.ENCODING_PCM_FLOAT)
                .setChannelMask(AudioFormat.CHANNEL_OUT_STEREO)
                .build();
                
            int minBufferSize = AudioTrack.getMinBufferSize(
                48000,
                AudioFormat.CHANNEL_OUT_STEREO,
                AudioFormat.ENCODING_PCM_FLOAT
            );
            
            audioTrack = new AudioTrack.Builder()
                .setAudioAttributes(attributes)
                .setAudioFormat(format)
                .setBufferSizeInBytes(minBufferSize * 2)
                .setTransferMode(AudioTrack.MODE_STREAM)
                .setPerformanceMode(AudioTrack.PERFORMANCE_MODE_LOW_LATENCY)
                .build();
                
            audioTrack.play();
        } catch (Exception e) {
            Log.e(TAG, "Error resetting AudioTrack: " + e.getMessage());
        }
    }

    public void muteWebViewAudio() {
    if (attachedWebView!= null) {
        attachedWebView.evaluateJavascript(
            "document.querySelectorAll('audio,video').forEach(el => {" +
            "    el.volume = 0;" +
            "    el.muted = true;" +
            "});" +
            "if(window.audioContext) {" +
            "    window.audioContext.destination.channelCount = 0;" +
            "}",
            null
        );
    }
}

private void initializeAudioCapture() {
    if (attachedWebView != null) {
        setupWebViewAudioBridge(attachedWebView);
    }
}
    
    private void restartAudioProcessing() {
    synchronized (lock) {
        try {
            // Останавливаем текущую обработку
            if (audioTrack != null) {
                audioTrack.stop();
                audioTrack.flush();
            }
            
            // Очищаем буферы
            audioQueue.clear();
            
            // Реинициализируем аудио выход
            reinitializeAudioTrack();
            
            // Перезапускаем обработку
            if (isProcessing.get() && audioTrack != null) {
                audioTrack.play();
            }
            
        } catch (Exception e) {
            Log.e(TAG, "Error restarting audio processing: " + e.getMessage());
            // Повторная попытка через 100мс
            new Handler(Looper.getMainLooper()).postDelayed(
                this::restartAudioProcessing, 
                100
            );
        }
    }
}
    
    private void processAudioData() {
    while (!audioQueue.isEmpty() && isProcessing.get()) {
        try {
            FloatBuffer buffer = audioQueue.poll();
            if (buffer != null) {
                int length = buffer.remaining();
                
                // Создаем массив для входных данных
                float[] inputData = new float[length];
                buffer.get(inputData);
                
                // Очищаем временный буфер и копируем данные
                float[] processedBuffer = new float[inputData.length];
System.arraycopy(inputData, 0, processedBuffer, 0, inputData.length);

                // Обработка через процессор
                float[] processedData = audioProcessor.processAudioData(inputData, length);
                
                // Проверка на null и длину
                if (processedData != null && processedData.length > 0) {
                    // Применяем усиление
                    for (int i = 0; i < processedData.length; i++) {
                        processedData[i] = Math.max(-1.0f, 
                            Math.min(1.0f, processedData[i] * PROCESSING_GAIN));
                    }

                    // Проверяем состояние AudioTrack перед записью
                    if (audioTrack != null) {
                        if (audioTrack.getPlayState() != AudioTrack.PLAYSTATE_PLAYING) {
                            audioTrack.play();
                        }
                        
                        int written = audioTrack.write(processedData, 0, processedData.length, 
                            AudioTrack.WRITE_NON_BLOCKING);
                            
                        if (written < 0) {
                            Log.e(TAG, "Error writing to AudioTrack: " + written);
                            // Попытка восстановления
                            reinitializeAudioTrack();
                        } else if (written < processedData.length) {
                            Log.w(TAG, "Incomplete write to AudioTrack: " + written + 
                                " of " + processedData.length);
                        }
                    }

                    // Отправляем данные в callback если он установлен
                    if (audioCallback != null) {
                        try {
                            audioCallback.onAudioData(processedData, processedData.length);
                        } catch (Exception callbackEx) {
                            Log.e(TAG, "Error in audio callback: " + callbackEx.getMessage());
                        }
                    }
                }
            }
        } catch (Exception e) {
            Log.e(TAG, "Error processing audio data: " + e.getMessage());
            e.printStackTrace();
        }
    }
}

    private void setupAudioRouting() {
    if (audioManager != null) {
        // Отключаем системный звук
        audioManager.setStreamVolume(AudioManager.STREAM_MUSIC, 0, 0);
        audioManager.setStreamMute(AudioManager.STREAM_MUSIC, true);
        
        // Принудительная маршрутизация через процессор
        audioManager.setParameters("MTK_AUDIO_PATH=processor");
        audioManager.setParameters("MTK_STREAM_TYPE=AUDIO_STREAM_PROC");
        audioManager.setParameters("SET_FORCE_ROUTE=1");
    }
}

// Вспомогательный метод для реинициализации AudioTrack
private void reinitializeAudioTrack() {
    final Object initLock = new Object();
    
    synchronized (initLock) {
        try {
            if (audioTrack != null) {
                try {
                    audioTrack.stop();
                    audioTrack.flush();
                    audioTrack.release();
                } catch (Exception e) {
                    Log.e(TAG, "Error releasing AudioTrack: " + e.getMessage());
                }
                audioTrack = null;
            }

            int minBuffer = AudioTrack.getMinBufferSize(
                SAMPLE_RATE,
                AudioFormat.CHANNEL_OUT_STEREO,
                AudioFormat.ENCODING_PCM_FLOAT
            );

            // Увеличиваем размер буфера для большей стабильности
            int bufferSize = Math.max(minBuffer * 2, 4096);

            AudioAttributes attributes = new AudioAttributes.Builder()
                .setUsage(AudioAttributes.USAGE_MEDIA)
                .setContentType(AudioAttributes.CONTENT_TYPE_MUSIC)
                .setFlags(AudioAttributes.FLAG_LOW_LATENCY)
                .build();

            AudioFormat format = new AudioFormat.Builder()
                .setEncoding(AudioFormat.ENCODING_PCM_FLOAT)
                .setSampleRate(SAMPLE_RATE)
                .setChannelMask(AudioFormat.CHANNEL_OUT_STEREO)
                .build();

            audioTrack = new AudioTrack.Builder()
                .setAudioAttributes(attributes)
                .setAudioFormat(format)
                .setBufferSizeInBytes(bufferSize)
                .setTransferMode(AudioTrack.MODE_STREAM)
                .setPerformanceMode(AudioTrack.PERFORMANCE_MODE_LOW_LATENCY)
                .build();

            if (audioTrack.getState() == AudioTrack.STATE_INITIALIZED) {
                audioTrack.play();
            } else {
                throw new IllegalStateException("AudioTrack initialization failed");
            }

        } catch (Exception e) {
            Log.e(TAG, "Error reinitializing AudioTrack: " + e.getMessage());
            if (audioTrack != null) {
                audioTrack.release();
                audioTrack = null;
            }
            // Повторная попытка через 100мс
            new Handler(Looper.getMainLooper()).postDelayed(() -> {
                if (isProcessing.get()) {
                    reinitializeAudioTrack();
                }
            }, 100);
        }
    }
}
    public void setAudioCallback(AudioCallback callback) {
        this.audioCallback = callback;
    }

    public void startProcessing() {
        if (isProcessing.compareAndSet(false, true)) {
            Log.d(TAG, "Starting audio processing");
            audioExecutor.execute(this::processAudioLoop);
            
            if (isWebViewAttached()) {
                attachedWebView.post(() -> attachedWebView.evaluateJavascript(
                    "if(window.audioContext) {" +
                    "    audioContext.resume();" +
                    "    console.log('Audio context resumed');" +
                    "}", 
                    null
                ));
            }
            
            if (audioTrack != null && audioTrack.getPlayState() != AudioTrack.PLAYSTATE_PLAYING) {
                audioTrack.play();
            }
        }
    }

    private void processAudioLoop() {
        while (isProcessing.get()) {
            try {
                Thread.sleep(5); // Уменьшено время ожидания
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
                break;
            } catch (Exception e) {
                Log.e(TAG, "Error in process loop: " + e.getMessage());
            }
        }
    }

    public void stopProcessing() {
        Log.d(TAG, "Stopping audio processing");
        isProcessing.set(false);
        audioQueue.clear();
        
        if (isWebViewAttached()) {
            attachedWebView.post(() -> attachedWebView.evaluateJavascript(
                "if(window.audioContext) {" +
                "    window.masterGain.disconnect();" +
                "    audioContext.suspend();" +
                "    console.log('Audio context suspended');" +
                "}", 
                null
            ));
        }
        
        if (audioTrack != null) {
            audioTrack.pause();
            audioTrack.flush();
        }
        
        // Восстанавливаем системную громкость
        audioManager.setStreamMute(AudioManager.STREAM_MUSIC, false);
        audioManager.setStreamVolume(AudioManager.STREAM_MUSIC, (int)systemVolume, 0);
    }

    public void release() {
        stopProcessing();
        detachWebView();
        
        if (audioTrack != null) {
            try {
                audioTrack.stop();
                audioTrack.release();
            } catch (Exception e) {
                Log.e(TAG, "Error releasing AudioTrack: " + e.getMessage());
            }
            audioTrack = null;
        }
        
        if (audioDecoder != null) {
            try {
                audioDecoder.stop();
                audioDecoder.release();
            } catch (Exception e) {
                Log.e(TAG, "Error releasing MediaCodec: " + e.getMessage());
            }
            audioDecoder = null;
        }
        
        if (extractor != null) {
            extractor.release();
            extractor = null;
        }
        
        audioExecutor.shutdown();
    
        
        // Восстанавливаем системную громкость при выходе
        audioManager.setStreamMute(AudioManager.STREAM_MUSIC, false);
        audioManager.setStreamVolume(AudioManager.STREAM_MUSIC, (int)systemVolume, 0);
    }

    public void setAudioProcessor(AudioProcessor processor) {
        this.audioProcessor = processor;
    }

    public void initializeAudioContext(int sampleRate) {
        if (isWebViewAttached()) {
            attachedWebView.post(() -> attachedWebView.evaluateJavascript(
                "if(window.audioContext) {" +
                "    audioContext.sampleRate = " + sampleRate + ";" +
                "    console.log('Sample rate set to: " + sampleRate + "');" +
                "}", 
                null
            ));
        }
    }

    public void resumeAudioContext() {
        if (isWebViewAttached()) {
            attachedWebView.post(() -> attachedWebView.evaluateJavascript(
                "if(window.audioContext) audioContext.resume();", 
                null
            ));
        }
    }

    public void suspendAudioContext() {
        if (isWebViewAttached()) {
            attachedWebView.post(() -> attachedWebView.evaluateJavascript(
                "if(window.audioContext) audioContext.suspend();", 
                null
            ));
        }
    }

    public int getAudioSessionId() {
        return sessionId;
    }

    public boolean isProcessing() {
        return isProcessing.get();
    }
}

И

package com.vlq.audioprocessor;

import android.content.Context;
import android.os.Bundle;
import android.os.Handler;
import android.os.Looper;
import android.util.Log;
import android.view.LayoutInflater;
import android.view.View;
import android.view.ViewGroup;
import android.widget.CheckBox;
import android.widget.SeekBar;
import android.widget.TextView;
import androidx.annotation.NonNull;
import androidx.fragment.app.Fragment;
import java.util.Locale;

public class DSPFragment extends Fragment implements AudioProcessorInterface.OnChannelUpdateListener {
    private static final String TAG = "DSPFragment";
    private static final int UPDATE_INTERVAL_MS = 50;
    private static final float MIN_DB = AudioProcessorInterface.MIN_DB;
    private static final float MAX_DB = AudioProcessorInterface.MAX_DB;
    
    private MainActivity mainActivity;
    private AudioProcessor audioProcessor;
    private Handler updateHandler;
    private Runnable updateRunnable;
    private boolean isUpdating = false;
    private boolean isInitialized = false;
    private View rootView;

    // UI элементы
    private SeekBar[] volumeBars = new SeekBar[5];
    private SeekBar[] bassBars = new SeekBar[5];
    private CheckBox[] lpfBoxes = new CheckBox[5];
    private TextView[] levelTexts = new TextView[5];
    private TextView[] volumeTexts = new TextView[5];
    private TextView[] bassTexts = new TextView[5];
    private TextView textViewAnalysis;

    @Override
    public void onAttach(@NonNull Context context) {
        super.onAttach(context);
        if (context instanceof MainActivity) {
            mainActivity = (MainActivity) context;
            if (mainActivity.isAudioProcessorReady()) {
                audioProcessor = mainActivity.getAudioProcessor();
            }
        } else {
            throw new RuntimeException("Must be attached to MainActivity");
        }
    }

    @Override
    public View onCreateView(@NonNull LayoutInflater inflater, ViewGroup container, Bundle savedInstanceState) {
        rootView = inflater.inflate(R.layout.fragment_dsp, container, false);
        initializeViews(rootView);
        setupControlListeners();
        setupInitialValues();
        
        if (audioProcessor != null) {
            audioProcessor.setChannelUpdateListener(this);
            updateUIWithCurrentSettings();
            startLevelUpdates();
        }
        
        return rootView;
    }

    private void initializeViews(View view) {
        // Front Left Channel
        volumeBars[0] = view.findViewById(R.id.seekBarLeftFrontVolume);
        volumeTexts[0] = view.findViewById(R.id.textViewLeftFrontVolume);
        bassBars[0] = view.findViewById(R.id.seekBarLeftFrontBass);
        bassTexts[0] = view.findViewById(R.id.textViewLeftFrontBass);
        lpfBoxes[0] = view.findViewById(R.id.checkBoxLeftFrontLPF);
        levelTexts[0] = view.findViewById(R.id.textViewLeftFrontLevel);

        // Front Right Channel
        volumeBars[1] = view.findViewById(R.id.seekBarRightFrontVolume);
        volumeTexts[1] = view.findViewById(R.id.textViewRightFrontVolume);
        bassBars[1] = view.findViewById(R.id.seekBarRightFrontBass);
        bassTexts[1] = view.findViewById(R.id.textViewRightFrontBass);
        lpfBoxes[1] = view.findViewById(R.id.checkBoxRightFrontLPF);
        levelTexts[1] = view.findViewById(R.id.textViewRightFrontLevel);

        // Rear Left Channel
        volumeBars[2] = view.findViewById(R.id.seekBarLeftRearVolume);
        volumeTexts[2] = view.findViewById(R.id.textViewLeftRearVolume);
        bassBars[2] = view.findViewById(R.id.seekBarLeftRearBass);
        bassTexts[2] = view.findViewById(R.id.textViewLeftRearBass);
        lpfBoxes[2] = view.findViewById(R.id.checkBoxLeftRearLPF);
        levelTexts[2] = view.findViewById(R.id.textViewLeftRearLevel);

        // Rear Right Channel
        volumeBars[3] = view.findViewById(R.id.seekBarRightRearVolume);
        volumeTexts[3] = view.findViewById(R.id.textViewRightRearVolume);
        bassBars[3] = view.findViewById(R.id.seekBarRightRearBass);
        bassTexts[3] = view.findViewById(R.id.textViewRightRearBass);
        lpfBoxes[3] = view.findViewById(R.id.checkBoxRightRearLPF);
        levelTexts[3] = view.findViewById(R.id.textViewRightRearLevel);

        // Subwoofer Channel
        volumeBars[4] = view.findViewById(R.id.seekBarSubwooferVolume);
        volumeTexts[4] = view.findViewById(R.id.textViewSubwooferVolume);
        bassBars[4] = view.findViewById(R.id.seekBarSubwooferBass);
        bassTexts[4] = view.findViewById(R.id.textViewSubwooferBass);
        lpfBoxes[4] = view.findViewById(R.id.checkBoxSubwooferLPF);
        levelTexts[4] = view.findViewById(R.id.textViewSubwooferLevel);

        textViewAnalysis = view.findViewById(R.id.textViewAnalysis);
    }

    private void setupControlListeners() {
        for (int i = 0; i < 5; i++) {
            final int channel = i;
            
            // Volume Controls
            if (volumeBars[i] != null) {
                volumeBars[i].setMax(100);
                volumeBars[i].setOnSeekBarChangeListener(new SeekBar.OnSeekBarChangeListener() {
                    @Override
                    public void onProgressChanged(SeekBar seekBar, int progress, boolean fromUser) {
                        if (fromUser && audioProcessor != null) {
                            float volume = progress / 100.0f;
                            audioProcessor.setChannelVolume(channel, volume);
                            updateVolumeText(channel, volume);
                        }
                    }

                    @Override
                    public void onStartTrackingTouch(SeekBar seekBar) {}

                    @Override
                    public void onStopTrackingTouch(SeekBar seekBar) {
                        if (audioProcessor != null) {
                            audioProcessor.saveProcessingState();
                        }
                    }
                });
            }

            // Bass Controls
            if (bassBars[i] != null) {
                bassBars[i].setMax(100);
                bassBars[i].setOnSeekBarChangeListener(new SeekBar.OnSeekBarChangeListener() {
                    @Override
                    public void onProgressChanged(SeekBar seekBar, int progress, boolean fromUser) {
                        if (fromUser && audioProcessor != null) {
                            float bass = progress / 100.0f;
                            audioProcessor.setChannelBass(channel, bass);
                            updateBassText(channel, bass);
                        }
                    }

                    @Override
                    public void onStartTrackingTouch(SeekBar seekBar) {}

                    @Override
                    public void onStopTrackingTouch(SeekBar seekBar) {
                        if (audioProcessor != null) {
                            audioProcessor.saveProcessingState();
                        }
                    }
                });
            }

            // LPF Controls
            if (lpfBoxes[i] != null) {
                lpfBoxes[i].setOnCheckedChangeListener((buttonView, isChecked) -> {
                    if (audioProcessor != null) {
                        audioProcessor.setChannelLPF(channel, isChecked);
                        audioProcessor.saveProcessingState();
                    }
                });
            }
        }
    }

    private void setupInitialValues() {
        updateHandler = new Handler(Looper.getMainLooper());
        updateRunnable = () -> {
            if (isUpdating && audioProcessor != null) {
                updateAllLevels();
                updateHandler.postDelayed(updateRunnable, UPDATE_INTERVAL_MS);
            }
        };

        // Установка начальных значений для всех каналов
        for (int i = 0; i < 5; i++) {
            if (volumeBars[i] != null) {
                volumeBars[i].setProgress(100);
                updateVolumeText(i, 1.0f);
            }
            if (bassBars[i] != null) {
                bassBars[i].setProgress(0);
                updateBassText(i, 0.0f);
            }
            if (lpfBoxes[i] != null) {
                lpfBoxes[i].setChecked(false);
            }
            if (levelTexts[i] != null) {
                levelTexts[i].setText(String.format(Locale.US, "Level: %.1f dB", MIN_DB));
            }
        }
    }

    private void updateVolumeText(int channel, float volume) {
        if (channel >= 0 && channel < volumeTexts.length && volumeTexts[channel] != null) {
            float db = 20 * (float) Math.log10(Math.max(0.0001f, volume));
            volumeTexts[channel].setText(String.format(Locale.US, "%.1f dB", db));
        }
    }

    private void updateBassText(int channel, float bass) {
        if (channel >= 0 && channel < bassTexts.length && bassTexts[channel] != null) {
            float db = 20 * (float) Math.log10(Math.max(0.0001f, bass + 1.0f));
            bassTexts[channel].setText(String.format(Locale.US, "%.1f dB", db));
        }
    }

    private void updateLevelText(int channel, float levelDb) {
        if (channel >= 0 && channel < levelTexts.length && levelTexts[channel] != null) {
            levelTexts[channel].setText(String.format(Locale.US, "Level: %.1f dB", levelDb));
        }
    }

    private void updateAllLevels() {
        if (audioProcessor != null) {
            for (int i = 0; i < 5; i++) {
                float level = audioProcessor.getChannelLevel(i);
                updateLevelText(i, level);
            }
            updateAnalysisText();
        }
    }

    private void updateAnalysisText() {
        if (textViewAnalysis != null && audioProcessor != null) {
            StringBuilder analysis = new StringBuilder();
            analysis.append(String.format(Locale.US, "LF:%.1fdB  RF:%.1fdB\n",
                audioProcessor.getChannelLevel(0),
                audioProcessor.getChannelLevel(1)));
            analysis.append(String.format(Locale.US, "LR:%.1fdB  RR:%.1fdB  SUB:%.1fdB",
                audioProcessor.getChannelLevel(2),
                audioProcessor.getChannelLevel(3),
                audioProcessor.getChannelLevel(4)));
            
            textViewAnalysis.setText(analysis.toString());
        }
    }

    public void onAudioProcessorReady() {
        if (!isInitialized && mainActivity != null) {
            audioProcessor = mainActivity.getAudioProcessor();
            if (audioProcessor != null) {
                audioProcessor.setChannelUpdateListener(this);
                updateUIWithCurrentSettings();
                startLevelUpdates();
                isInitialized = true;
            }
        }
    }

    public void updateUIWithCurrentSettings() {
    if (audioProcessor != null) {
        float[] volumes = audioProcessor.getChannelVolumes();
        float[] bassLevels = audioProcessor.getChannelBassLevels();
        boolean[] lpfStates = audioProcessor.getChannelLPFStates();

        for (int i = 0; i < 5; i++) {
            if (volumeBars[i] != null) {
                volumeBars[i].setProgress((int)(volumes[i] * 100));
                updateVolumeText(i, volumes[i]);
            }
            if (bassBars[i] != null) {
                bassBars[i].setProgress((int)(bassLevels[i] * 100));
                updateBassText(i, bassLevels[i]);
            }
            if (lpfBoxes[i] != null) {
                lpfBoxes[i].setChecked(lpfStates[i]);
            }
        }
    }
}

    private void startLevelUpdates() {
        if (!isUpdating) {
            isUpdating = true;
            updateHandler.post(updateRunnable);
        }
    }

    private void stopLevelUpdates() {
        isUpdating = false;
        updateHandler.removeCallbacks(updateRunnable);
    }

    @Override
    public void onChannelLevelChanged(int channel, float level) {
        if (isAdded() && channel >= 0 && channel < levelTexts.length) {
            updateLevelText(channel, level);
        }
    }

    @Override
    public void onChannelPeakChanged(int channel, float peak) {
        if (isAdded() && channel >= 0 && channel < levelTexts.length) {
            String text = String.format(Locale.US, "Peak: %.1f dB", peak);
            levelTexts[channel].setText(text);
        }
    }

    @Override
    public void onVolumeTextUpdated(int channel, String text) {
        if (volumeTexts != null && channel >= 0 && channel < volumeTexts.length) {
            volumeTexts[channel].setText(text);
        }
    }

    @Override
    public void onBassTextUpdated(int channel, String text) {
        if (bassTexts != null && channel >= 0 && channel < bassTexts.length) {
            bassTexts[channel].setText(text);
        }
    }

    @Override
    public void onLevelTextUpdated(int channel, String text) {
        if (levelTexts != null && channel >= 0 && channel < levelTexts.length) {
            levelTexts[channel].setText(text);
        }
    }

    @Override
    public void onLPFStateUpdated(int channel, boolean enabled) {
        if (lpfBoxes != null && channel >= 0 && channel < lpfBoxes.length) {
            lpfBoxes[channel].setChecked(enabled);
        }
    }

    @Override
    public void onAnalysisTextUpdated(String text) {
        if (textViewAnalysis != null) {
            textViewAnalysis.setText(text);
        }
    }

    @Override
    public void onResume() {
        super.onResume();
        if (isInitialized) {
            startLevelUpdates();
            if (audioProcessor != null) {
                audioProcessor.setChannelUpdateListener(this);
                updateUIWithCurrentSettings();
            }
        }
    }

    @Override
    public void onPause() {
        super.onPause();
        stopLevelUpdates();
        if (audioProcessor != null) {
            audioProcessor.saveProcessingState();
        }
    }

    @Override
    public void onDestroyView() {
        super.onDestroyView();
        stopLevelUpdates();
        
        if (audioProcessor != null) {
            audioProcessor.setChannelUpdateListener(null);
        }
        
        updateHandler.removeCallbacksAndMessages(null);
        
        // Очистка ссылок на UI элементы
        volumeBars = null;
        bassBars = null;
        lpfBoxes = null;
        levelTexts = null;
        volumeTexts = null;
        bassTexts = null;
        textViewAnalysis = null;
        rootView = null;
    }

    @Override
    public void onDetach() {
        super.onDetach();
        mainActivity = null;
        audioProcessor = null;
        isInitialized = false;
    }

    public boolean isFragmentInitialized() {
        return isInitialized;
    }
    private void logControlState() {
    StringBuilder state = new StringBuilder();
    state.append("DSP Controls state:\n");
    
    for (int i = 0; i < 5; i++) {
        state.append(String.format(Locale.US,
            "Channel %d: Volume=%.2f, Bass=%.2f, LPF=%b, Level=%.1f dB\n",
            i,
            volumeBars[i] != null ? volumeBars[i].getProgress() / 100f : 0f,
            bassBars[i] != null ? bassBars[i].getProgress() / 100f : 0f,
            lpfBoxes[i] != null && lpfBoxes[i].isChecked(),
            audioProcessor != null ? audioProcessor.getChannelLevel(i) : -60f));
    }
    
    Log.d(TAG, state.toString());
}
}

И

package com.vlq.audioprocessor;

import android.util.Log;
import java.nio.FloatBuffer;

public class HRTFProcessor {
    private static final String TAG = "HRTFProcessor";
    
    private final int sampleRate;
    private final FloatBuffer leftBuffer;
    private final FloatBuffer rightBuffer;
    private final FloatBuffer tempBuffer;
    
    // HRTF коэффициенты для разных углов
    private static final float[][] HRTF_COEFFICIENTS = {
        // 0 градусов (фронт)
        {1.0f, 0.0f, 0.0f, 0.0f, 0.0f},
        // 30 градусов
        {0.9f, 0.6f, 0.3f, 0.1f, 0.05f},
        // 60 градусов
        {0.7f, 0.8f, 0.5f, 0.3f, 0.1f},
        // 90 градусов (сторона)
        {0.5f, 1.0f, 0.7f, 0.4f, 0.2f},
        // 120 градусов
        {0.3f, 0.8f, 0.9f, 0.6f, 0.3f},
        // 150 градусов
        {0.1f, 0.6f, 0.8f, 0.9f, 0.4f},
        // 180 градусов (тыл)
        {0.0f, 0.4f, 0.7f, 1.0f, 0.5f}
    };
    
    private final float[] delayLine;
    private int delayIndex = 0;
    private static final int MAX_DELAY = 48; // максимальная задержка в сэмплах
    
    public HRTFProcessor(int sampleRate) {
        this.sampleRate = sampleRate;
        this.leftBuffer = FloatBuffer.allocate(4096);
        this.rightBuffer = FloatBuffer.allocate(4096);
        this.tempBuffer = FloatBuffer.allocate(4096);
        this.delayLine = new float[MAX_DELAY];
    }
    
    public float[] process(float[] input, float position, float angle) {
        if (input == null || input.length == 0) return new float[0];
        
        // Нормализуем позицию и угол
        position = Math.max(-1.0f, Math.min(1.0f, position));
        angle = Math.max(0.0f, Math.min(180.0f, angle));
        
        // Получаем индексы и веса для интерполяции HRTF
        int index1 = (int)(angle / 30.0f);
        int index2 = Math.min(index1 + 1, HRTF_COEFFICIENTS.length - 1);
        float blend = (angle / 30.0f) - index1;
        
        float[] coeffs1 = HRTF_COEFFICIENTS[index1];
        float[] coeffs2 = HRTF_COEFFICIENTS[index2];
        
        // Создаем выходной массив
        float[] output = new float[input.length * 2];
        
        // Применяем HRTF обработку
        for (int i = 0; i < input.length; i++) {
            float sample = input[i];
            
            // Интерполируем коэффициенты
            float[] currentCoeffs = new float[5];
            for (int j = 0; j < 5; j++) {
                currentCoeffs[j] = coeffs1[j] * (1 - blend) + coeffs2[j] * blend;
            }
            
            // Вычисляем задержку на основе позиции
            int delay = (int)(position * MAX_DELAY / 2 + MAX_DELAY / 2);
            
            // Обновляем линию задержки
            delayLine[delayIndex] = sample;
            delayIndex = (delayIndex + 1) % MAX_DELAY;
            
            // Применяем HRTF фильтрацию
            float leftSample = 0;
            float rightSample = 0;
            
            for (int j = 0; j < 5; j++) {
                int index = (delayIndex - j + MAX_DELAY) % MAX_DELAY;
                float coeff = currentCoeffs[j];
                
                if (position <= 0) { // Левая сторона
                    leftSample += delayLine[index] * coeff;
                    rightSample += delayLine[index] * coeff * (1 + position);
                } else { // Правая сторона
                    leftSample += delayLine[index] * coeff * (1 - position);
                    rightSample += delayLine[index] * coeff;
                }
            }
            
            // Записываем результат
            output[i * 2] = leftSample;
            output[i * 2 + 1] = rightSample;
        }
        
        return output;
    }
    
    public void release() {
        // Освобождаем ресурсы
        leftBuffer.clear();
        rightBuffer.clear();
        tempBuffer.clear();
    }
}

И


package com.vlq.audioprocessor;

import android.content.ComponentName;
import android.content.Context;
import android.content.Intent;
import android.content.ServiceConnection;
import android.content.pm.PackageManager;
import android.content.pm.ApplicationInfo;
import android.media.AudioDeviceInfo;
import android.media.AudioManager;
import android.media.projection.MediaProjectionManager;
import android.media.projection.MediaProjection;
import android.os.Build;
import android.os.Bundle;
import android.os.IBinder;
import android.os.Handler;
import android.os.HandlerThread;
import android.os.Looper;
import android.util.Log;
import android.webkit.WebView;
import android.widget.Toast;
import androidx.annotation.NonNull;
import androidx.appcompat.app.AppCompatActivity;
import androidx.viewpager2.widget.ViewPager2;
import androidx.fragment.app.Fragment;
import androidx.fragment.app.FragmentActivity;
import androidx.viewpager2.adapter.FragmentStateAdapter;
import com.google.android.material.tabs.TabLayout;
import com.google.android.material.tabs.TabLayoutMediator;
import android.media.AudioTrack;
import android.media.AudioFormat;
import android.media.AudioAttributes;
import android.media.AudioDeviceCallback;
import android.media.AudioFocusRequest;
import java.util.List;
import java.util.ArrayList;
import android.app.AlertDialog;
import android.Manifest;
import java.util.concurrent.atomic.AtomicBoolean;
import android.view.KeyEvent;

public class MainActivity extends AppCompatActivity {
    private static final String TAG = "MainActivity";
    private boolean isServiceBound = false;
    private static final int BUFFER_SIZE = 2048; // Размер буфера, можно настроить
    
    private static final int PERMISSION_REQUEST_CODE = 123;
    private static final int REQUEST_CODE_MEDIA_PROJECTION = 456;
    private static final int SERVICE_RETRY_INTERVAL = 500;
    private static final int MAX_RETRY_ATTEMPTS = 3;
    private static final int SAMPLE_RATE = 48000;
    private static final int OPTIMAL_BUFFER_SIZE = 8192;
    private static final String MTK_PROCESSOR_PATH = "processor";
    private static final int AUDIO_SESSION_INVALID = -1;
    
    private ViewPager2 viewPager;
    private TabLayout tabLayout;
    private DSPFragment dspFragment;

    private AudioProcessor audioProcessor;
    private AudioProcessingService audioService;
    private AudioSettings audioSettings;
    private WebAudioCapturer webAudioCapturer;
    private AudioManager audioManager;
    private MediaProjectionManager mediaProjectionManager;
    private MediaProjection mediaProjection;
    private AudioTrack outputTrack;
    private AudioAttributes audioAttributes;
    private AudioFormat audioFormat;
    private AudioFocusRequest audioFocusRequest;

    private HandlerThread audioHandlerThread;
    private Handler audioHandler;
    private final Handler mainHandler = new Handler(Looper.getMainLooper());

    private final AtomicBoolean serviceBound = new AtomicBoolean(false);
    private final AtomicBoolean isAudioProcessorReady = new AtomicBoolean(false);
    private final AtomicBoolean isAudioRoutingReady = new AtomicBoolean(false);
    private final AtomicBoolean isProcessing = new AtomicBoolean(false);
    private int retryCount = 0;
    private int currentAudioSessionId = AUDIO_SESSION_INVALID;
    private int originalVolume;
    private Intent pendingMediaProjectionData;
    private int pendingMediaProjectionResultCode = -1;

    private AudioDeviceCallback audioDeviceCallback;
    
    
private final Object processLock = new Object();

    private final ServiceConnection serviceConnection = new ServiceConnection() {
        @Override
        public void onServiceConnected(ComponentName name, IBinder service) {
            try {
                AudioProcessingService.LocalBinder binder = (AudioProcessingService.LocalBinder) service;
                audioService = binder.getService();
                serviceBound.set(true);

                audioHandler.post(() -> {
                    if (pendingMediaProjectionResultCode != -1 && pendingMediaProjectionData != null) {
                        audioService.initializeMediaProjection(
                            pendingMediaProjectionResultCode,
                            pendingMediaProjectionData
                        );
                        pendingMediaProjectionResultCode = -1;
                        pendingMediaProjectionData = null;
                    }

                    initializeAudioProcessor();
                    setupAudioRouting();
                });
            } catch (ClassCastException e) {
                Log.e(TAG, "Wrong service type: " + e.getMessage());
                serviceBound.set(false);
            }
        }

        @Override
        public void onServiceDisconnected(ComponentName name) {
            serviceBound.set(false);
            isAudioProcessorReady.set(false);
            audioService = null;
            audioProcessor = null;
        }
    };

    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.activity_main);
        
        try {
            initializeHandlerThread();
            initializeBasicComponents();
            if (checkAndRequestPermissions()) {
                audioHandler.post(() -> {
                    initializeMediaTekAudio();
                    mainHandler.post(this::startMediaProjection);
                });
            }
        } catch (Exception e) {
            Log.e(TAG, "Error in onCreate: " + e.getMessage());
            Toast.makeText(this, "Ошибка инициализации", Toast.LENGTH_SHORT).show();
        }
    }

    private void initializeHandlerThread() {
        audioHandlerThread = new HandlerThread("AudioThread", android.os.Process.THREAD_PRIORITY_AUDIO);
        audioHandlerThread.start();
        audioHandler = new Handler(audioHandlerThread.getLooper());
    }

    private void initializeBasicComponents() {
        audioManager = (AudioManager) getSystemService(Context.AUDIO_SERVICE);
        mediaProjectionManager = (MediaProjectionManager) getSystemService(Context.MEDIA_PROJECTION_SERVICE);
        audioSettings = new AudioSettings(this);
        initializeUI();
        originalVolume = audioManager.getStreamVolume(AudioManager.STREAM_MUSIC);
        initializeAudioFormats();
    }

    private void initializeAudioFormats() {
        audioAttributes = new AudioAttributes.Builder()
            .setUsage(AudioAttributes.USAGE_MEDIA)
            .setContentType(AudioAttributes.CONTENT_TYPE_MUSIC)
            .setFlags(AudioAttributes.FLAG_LOW_LATENCY | AudioAttributes.FLAG_HW_AV_SYNC)
            .build();

        audioFormat = new AudioFormat.Builder()
            .setEncoding(AudioFormat.ENCODING_PCM_FLOAT)
            .setSampleRate(SAMPLE_RATE)
            .setChannelMask(AudioFormat.CHANNEL_OUT_STEREO)
            .build();
    }

    private void initializeMediaTekAudio() {
    try {
        // Настройка MediaTek Audio HAL
        audioManager.setParameters("MTK_AUDIO_TUNING_TOOL=1");
        audioManager.setParameters("MTK_AUDIO_32BIT=1");
        audioManager.setParameters("MTK_AUDIO_PATCH=DIRECT");
        audioManager.setParameters("MTK_AUDIO_PROCESSING=1");
        audioManager.setParameters("MTK_AUDIO_RAW_DATA_MODE=1");
        audioManager.setParameters("MTK_AUDIO_DEEP_BUFFER=0");
        audioManager.setParameters("SET_WEBAUDIO_ENABLE=1");
        audioManager.setParameters("WebAudio_Stream_Control=1");
        
    } catch (Exception e) {
        Log.e(TAG, "Error initializing MTK audio: " + e.getMessage());
    }
}
    
    private void setupAudioRouting() {
    audioHandler.post(() -> {
        if (audioManager != null) {
            try {
                // Устанавливаем базовый режим аудио
                audioManager.setMode(AudioManager.MODE_NORMAL);
                
                int minBuffer = AudioTrack.getMinBufferSize(
                    SAMPLE_RATE,
                    AudioFormat.CHANNEL_OUT_STEREO,
                    AudioFormat.ENCODING_PCM_FLOAT
                );
                
                // Используем больший буфер
                int optimizedBuffer = Math.max(minBuffer * 2, 4096);

                AudioAttributes attributes = new AudioAttributes.Builder()
                    .setUsage(AudioAttributes.USAGE_MEDIA)
                    .setContentType(AudioAttributes.CONTENT_TYPE_MUSIC)
                    .build(); // Убираем FLAG_LOW_LATENCY

                AudioFormat format = new AudioFormat.Builder()
                    .setEncoding(AudioFormat.ENCODING_PCM_FLOAT)
                    .setSampleRate(SAMPLE_RATE)
                    .setChannelMask(AudioFormat.CHANNEL_OUT_STEREO)
                    .build();

                // Создаем AudioTrack с базовыми параметрами
                if (outputTrack != null) {
                    outputTrack.release();
                }

                outputTrack = new AudioTrack.Builder()
                    .setAudioAttributes(attributes)
                    .setAudioFormat(format)
                    .setBufferSizeInBytes(optimizedBuffer)
                    .setTransferMode(AudioTrack.MODE_STREAM)
                    .setSessionId(audioManager.generateAudioSessionId())
                    .build();

                if (outputTrack.getState() == AudioTrack.STATE_INITIALIZED) {
                    outputTrack.play();
                } else {
                    throw new IllegalStateException("AudioTrack not initialized");
                }

                mainHandler.post(() -> {
                    setupAudioFocus();
                    setupAudioDeviceCallback();
                    isAudioRoutingReady.set(true);
                });

            } catch (Exception e) {
                Log.e(TAG, "Error in setupAudioRouting: " + e.getMessage());
                // Пробуем fallback вариант
                mainHandler.postDelayed(this::initializeFallbackAudio, 1000);
            }
        }
    });
}

private void initializeFallbackAudio() {
    try {
        // Пробуем создать с минимальными параметрами
        int minBuffer = AudioTrack.getMinBufferSize(
            44100, // Используем стандартную частоту
            AudioFormat.CHANNEL_OUT_STEREO,
            AudioFormat.ENCODING_PCM_16BIT // Используем 16-bit вместо float
        );

        outputTrack = new AudioTrack(
            AudioManager.STREAM_MUSIC,
            44100,
            AudioFormat.CHANNEL_OUT_STEREO,
            AudioFormat.ENCODING_PCM_16BIT,
            minBuffer,
            AudioTrack.MODE_STREAM
        );

        if (outputTrack.getState() == AudioTrack.STATE_INITIALIZED) {
            outputTrack.play();
        }
    } catch (Exception e) {
        Log.e(TAG, "Error in fallback audio initialization: " + e.getMessage());
    }
}

    private void initializeAudioProcessor() {
    audioHandler.post(() -> {
        try {
            if (currentAudioSessionId == AUDIO_SESSION_INVALID) {
                currentAudioSessionId = audioManager.generateAudioSessionId();
            }

            audioProcessor = new AudioProcessor(this);
            audioProcessor.attachToSession(currentAudioSessionId);

            webAudioCapturer = new WebAudioCapturer(this, SAMPLE_RATE, 8192);
            webAudioCapturer.setCallback((data, len) -> {
                if (audioProcessor != null && audioProcessor.isInitialized()) {
                    audioProcessor.processAudio(data);
                }
            });
            
            audioProcessor.setProcessingEnabled(true);
            audioProcessor.restoreProcessingState();
            
            isAudioProcessorReady.set(true);
            mainHandler.post(this::notifyFragmentsAudioProcessorReady);

        } catch (Exception e) {
            Log.e(TAG, "Error in initializeAudioProcessor: " + e.getMessage());
            isAudioProcessorReady.set(false);
            mainHandler.post(this::retryInitialization);
        }
    });
}

    private void setupAudioFocus() {
        audioFocusRequest = new AudioFocusRequest.Builder(AudioManager.AUDIOFOCUS_GAIN)
            .setAudioAttributes(audioAttributes)
            .setWillPauseWhenDucked(true)
            .setAcceptsDelayedFocusGain(true)
            .setOnAudioFocusChangeListener(this::handleAudioFocusChange)
            .build();

        int focusResult = audioManager.requestAudioFocus(audioFocusRequest);
        if (focusResult != AudioManager.AUDIOFOCUS_REQUEST_GRANTED) {
            Log.e(TAG, "Failed to get audio focus");
        }
    }

    private void setupAudioDeviceCallback() {
        audioDeviceCallback = new AudioDeviceCallback() {
            @Override
            public void onAudioDevicesAdded(AudioDeviceInfo[] addedDevices) {
                mainHandler.post(() -> {
                    audioManager.setStreamVolume(AudioManager.STREAM_MUSIC, 0, 0);
                });
            }

            @Override
            public void onAudioDevicesRemoved(AudioDeviceInfo[] removedDevices) {
                mainHandler.post(MainActivity.this::reinitializeAudioOutput);
            }
        };
        audioManager.registerAudioDeviceCallback(audioDeviceCallback, mainHandler);
    }

    private void startMediaProjection() {
        if (mediaProjectionManager != null && !serviceBound.get()) {
            try {
                startActivityForResult(
                    mediaProjectionManager.createScreenCaptureIntent(),
                    REQUEST_CODE_MEDIA_PROJECTION
                );
            } catch (Exception e) {
                Log.e(TAG, "Error requesting media projection: " + e.getMessage());
                Toast.makeText(this, "Ошибка запроса захвата аудио", Toast.LENGTH_SHORT).show();
            }
        }
    }

    @Override
    protected void onActivityResult(int requestCode, int resultCode, Intent data) {
        super.onActivityResult(requestCode, resultCode, data);
        if (requestCode == REQUEST_CODE_MEDIA_PROJECTION && resultCode == RESULT_OK) {
            try {
                pendingMediaProjectionResultCode = resultCode;
                pendingMediaProjectionData = data;

                Intent serviceIntent = new Intent(this, AudioProcessingService.class);
                serviceIntent.putExtra("resultCode", resultCode);
                serviceIntent.putExtra("resultData", data);
                
                if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.O) {
                    startForegroundService(serviceIntent);
                } else {
                    startService(serviceIntent);
                }
                
                bindService(serviceIntent, serviceConnection, Context.BIND_AUTO_CREATE);
                
            } catch (Exception e) {
                Log.e(TAG, "Error in onActivityResult: " + e.getMessage());
                Toast.makeText(this, "Failed to start audio capture", Toast.LENGTH_SHORT).show();
            }
        }
    }

    private void handleAudioFocusChange(int focusChange) {
        mainHandler.post(() -> {
            switch (focusChange) {
                case AudioManager.AUDIOFOCUS_GAIN:
                    if (!isProcessing.get() && audioService != null) {
                        audioService.startProcessing();
                        isProcessing.set(true);
                    }
                    if (outputTrack != null) {
                        outputTrack.setVolume(1.0f);
                    }
                    break;
                case AudioManager.AUDIOFOCUS_LOSS:
                case AudioManager.AUDIOFOCUS_LOSS_TRANSIENT:
                    if (isProcessing.get() && audioService != null) {
                        audioService.stopProcessing();
                        isProcessing.set(false);
                    }
                    break;
                case AudioManager.AUDIOFOCUS_LOSS_TRANSIENT_CAN_DUCK:
                    if (outputTrack != null) {
                        outputTrack.setVolume(0.5f);
                    }
                    break;
            }
        });
    }

    private void reinitializeAudioOutput() {
        audioHandler.post(() -> {
            try {
                if (outputTrack != null) {
                    outputTrack.stop();
                    outputTrack.flush();
                    outputTrack.release();
                    outputTrack = null;
                }
                setupAudioRouting();
            } catch (Exception e) {
                Log.e(TAG, "Error in reinitializeAudioOutput: " + e.getMessage());
            }
        });
    }
    
    @Override
    protected void onResume() {
        super.onResume();
        if (serviceBound.get() && audioService != null) {
            audioService.startProcessing();
            isProcessing.set(true);
        }
    }

    @Override
    protected void onPause() {
        super.onPause();
        if (audioProcessor != null) {
            audioProcessor.saveProcessingState();
        }
    }

    @Override
    protected void onDestroy() {
        cleanupResources();
        if (audioHandlerThread != null) {
            audioHandlerThread.quitSafely();
            try {
                audioHandlerThread.join(1000);
            } catch (InterruptedException e) {
                Log.e(TAG, "Error shutting down audio thread", e);
            }
        }
        super.onDestroy();
    }

    private void cleanupResources() {
        if (isProcessing.get() && audioService != null) {
            audioService.stopProcessing();
            isProcessing.set(false);
        }
        
        if (audioManager != null && audioDeviceCallback != null) {
            audioManager.unregisterAudioDeviceCallback(audioDeviceCallback);
        }

        if (audioFocusRequest != null) {
            audioManager.abandonAudioFocusRequest(audioFocusRequest);
        }

        if (serviceBound.get()) {
            unbindService(serviceConnection);
            serviceBound.set(false);
        }

        audioHandler.post(() -> {
            if (outputTrack != null) {
                outputTrack.stop();
                outputTrack.release();
                outputTrack = null;
            }

            if (audioProcessor != null) {
                audioProcessor.release();
                audioProcessor = null;
            }

            if (webAudioCapturer != null) {
                webAudioCapturer.stopCapture();
                webAudioCapturer = null;
            }
        });

        audioManager.setStreamVolume(AudioManager.STREAM_MUSIC, originalVolume, 0);
        stopService(new Intent(this, AudioProcessingService.class));
    }

    private void initializeUI() {
        viewPager = findViewById(R.id.viewPager);
        tabLayout = findViewById(R.id.tabLayout);

        ViewPagerAdapter pagerAdapter = new ViewPagerAdapter(this);
        viewPager.setAdapter(pagerAdapter);
        viewPager.setOffscreenPageLimit(2);

        new TabLayoutMediator(tabLayout, viewPager, (tab, position) -> {
            tab.setText(position == 0 ? "DSP" : "BROWSER");
        }).attach();

        tabLayout.setSelectedTabIndicatorColor(getResources().getColor(R.color.accent));
        tabLayout.setTabTextColors(
            getResources().getColor(R.color.gray),
            getResources().getColor(R.color.primary)
        );
    }

    private boolean checkAndRequestPermissions() {
    List<String> permissions = new ArrayList<>();
    
    // Основные разрешения для аудио
    String[] requiredPermissions = {
        Manifest.permission.RECORD_AUDIO,
        Manifest.permission.MODIFY_AUDIO_SETTINGS,
        Manifest.permission.FOREGROUND_SERVICE,
        Manifest.permission.BLUETOOTH,
        Manifest.permission.BLUETOOTH_CONNECT
    };
    
    // Проверяем основные разрешения
    for (String permission : requiredPermissions) {
        try {
            if (checkSelfPermission(permission) != PackageManager.PERMISSION_GRANTED) {
                permissions.add(permission);
            }
        } catch (Exception e) {
            Log.w(TAG, "Permission " + permission + " not available on this device");
        }
    }

    // Дополнительные разрешения для Android 13 и выше
    if (Build.VERSION.SDK_INT >= 33) {
        String[] androidTPermissions = {
            Manifest.permission.POST_NOTIFICATIONS,
            "android.permission.FOREGROUND_SERVICE_MEDIA_PROJECTION",
            "android.permission.FOREGROUND_SERVICE_MEDIA_PLAYBACK"
        };
        
        for (String permission : androidTPermissions) {
            try {
                if (checkSelfPermission(permission) != PackageManager.PERMISSION_GRANTED) {
                    permissions.add(permission);
                }
            } catch (Exception e) {
                Log.w(TAG, "Permission " + permission + " not available on this device");
            }
        }
    }

    // Запрашиваем разрешения, если необходимо
    if (!permissions.isEmpty()) {
        try {
            requestPermissions(permissions.toArray(new String[0]), PERMISSION_REQUEST_CODE);
            return false;
        } catch (Exception e) {
            Log.e(TAG, "Error requesting permissions: " + e.getMessage());
            return false;
        }
    }
    
    return true;
}

    @Override
public boolean onKeyDown(int keyCode, KeyEvent event) {
    if (keyCode == KeyEvent.KEYCODE_VOLUME_UP || keyCode == KeyEvent.KEYCODE_VOLUME_DOWN) {
        // Оставляем стандартную обработку
        return super.onKeyDown(keyCode, event);
    }
    return false;
}
    
    @Override
    public void onRequestPermissionsResult(int requestCode, @NonNull String[] permissions, @NonNull int[] grantResults) {
        super.onRequestPermissionsResult(requestCode, permissions, grantResults);
        if (requestCode == PERMISSION_REQUEST_CODE) {
            boolean allGranted = true;
            for (int result : grantResults) {
                if (result != PackageManager.PERMISSION_GRANTED) {
                    allGranted = false;
                    break;
                }
            }
            
            if (allGranted) {
                audioHandler.post(() -> {
                    initializeMediaTekAudio();
                    mainHandler.post(this::startMediaProjection);
                });
            } else {
                new AlertDialog.Builder(this)
                    .setTitle("Необходимы разрешения")
                    .setMessage("Для корректной работы приложения необходимы все запрошенные разрешения")
                    .setPositiveButton("Запросить снова", (dialog, which) -> checkAndRequestPermissions())
                    .setNegativeButton("Закрыть", (dialog, which) -> finish())
                    .setCancelable(false)
                    .show();
            }
        }
    }

    private void notifyFragmentsAudioProcessorReady() {
        if (isAudioProcessorReady.get()) {
            if (dspFragment == null) {
                dspFragment = (DSPFragment) getSupportFragmentManager()
                    .findFragmentByTag("f0");
            }
            if (dspFragment != null) {
                dspFragment.onAudioProcessorReady();
            }

            BrowserFragment browserFragment = (BrowserFragment) getSupportFragmentManager()
                .findFragmentByTag("f1");
            if (browserFragment != null) {
                browserFragment.startAudioProcessing();
            }
        }
    }

    private void retryInitialization() {
        if (retryCount < MAX_RETRY_ATTEMPTS) {
            retryCount++;
            mainHandler.postDelayed(() -> audioHandler.post(this::initializeAudioProcessor), 
                SERVICE_RETRY_INTERVAL);
        } else {
            Log.e(TAG, "Failed to initialize AudioProcessor after maximum retry attempts");
            Toast.makeText(this, "Ошибка инициализации аудио процессора", Toast.LENGTH_SHORT).show();
        }
    }

    public void attachWebViewToAudioCapture(WebView webView) {
        if (webAudioCapturer != null && webView != null) {
            webAudioCapturer.attachWebView(webView);
            Log.d(TAG, "WebView attached to WebAudioCapturer");
        }
    }

    private int getWebViewUid() {
        try {
            ApplicationInfo appInfo = getApplicationContext().getPackageManager()
                .getApplicationInfo("com.vlq.audioprocessor", 0);
            return appInfo.uid;
        } catch (PackageManager.NameNotFoundException e) {
            Log.e(TAG, "Error getting WebView UID: " + e.getMessage());
            return -1;
        }
    }

    public AudioProcessor getAudioProcessor() {
        return audioProcessor;
    }
    

    public AudioSettings getAudioSettings() {
        return audioSettings;
    }

    public boolean isAudioProcessorReady() {
        return isAudioProcessorReady.get() && audioProcessor != null && audioProcessor.isInitialized();
    }

    @Override
    public void onBackPressed() {
        BrowserFragment browserFragment = (BrowserFragment) getSupportFragmentManager()
            .findFragmentByTag("f1");
        
        if (browserFragment != null && browserFragment.isVisible() && browserFragment.canGoBack()) {
            browserFragment.goBack();
            return;
        }
        super.onBackPressed();
    }

    private class ViewPagerAdapter extends FragmentStateAdapter {
        public ViewPagerAdapter(FragmentActivity activity) {
            super(activity);
        }

        @Override
        public Fragment createFragment(int position) {
            Fragment fragment;
            if (position == 0) {
                fragment = new DSPFragment();
                dspFragment = (DSPFragment) fragment;
            } else {
                fragment = new BrowserFragment();
            }
            
            if (isAudioProcessorReady.get()) {
                if (fragment instanceof DSPFragment) {
                    ((DSPFragment) fragment).onAudioProcessorReady();
                } else if (fragment instanceof BrowserFragment) {
                    ((BrowserFragment) fragment).startAudioProcessing();
                }
            }
            
            return fragment;
        }

        @Override
        public int getItemCount() {
            return 2;
        }
    }
}

И

package com.vlq.audioprocessor;

public interface OnChannelUpdateListener {
    void onChannelLevelChanged(int channel, float level);
    void onChannelPeakChanged(int channel, float peak);
    // Добавляем новые методы для обновления UI
    void onVolumeTextUpdated(int channel, String text);
    void onBassTextUpdated(int channel, String text);
    void onLevelTextUpdated(int channel, String text);
    void onLPFStateUpdated(int channel, boolean enabled);
    void onAnalysisTextUpdated(String text);
}

И

package com.vlq.audioprocessor;

public class RmsCalculator {
    private final float[] buffer;
    private int position;
    private float sum;
    private float peak;
    private float decayRate;
    private final int windowSize;
    private boolean isInitialized;
    
    public RmsCalculator(int windowSize) {
        this.windowSize = windowSize;
        this.buffer = new float[windowSize];
        this.position = 0;
        this.sum = 0;
        this.peak = 0;
        this.decayRate = 0.9995f; // Коэффициент затухания пикового значения
        this.isInitialized = false;
        reset();
    }
    
    public void addValue(float value) {
        // Обновление RMS
        float oldValue = buffer[position];
        float newValue = value * value;
        sum = Math.max(0.0f, sum - oldValue + newValue);
        buffer[position] = newValue;
        position = (position + 1) % windowSize;

        // Обновление пикового значения
        float absValue = Math.abs(value);
        if (absValue > peak) {
            peak = absValue;
        } else {
            peak *= decayRate;
        }

        if (!isInitialized && position == 0) {
            isInitialized = true;
        }
    }
    
    public float getCurrentValue() {
        if (!isInitialized) {
            return 0.0f;
        }
        return (float) Math.sqrt(sum / windowSize);
    }

    public float getPeakValue() {
        return peak;
    }

    public float getDB() {
        float rms = getCurrentValue();
        if (rms < 1e-6f) {
            return AudioProcessorInterface.MIN_DB;
        }
        float db = (float) (20 * Math.log10(rms));
        return Math.max(AudioProcessorInterface.MIN_DB, 
                       Math.min(AudioProcessorInterface.MAX_DB, db));
    }

    public float getPeakDB() {
        if (peak < 1e-6f) {
            return AudioProcessorInterface.MIN_DB;
        }
        float db = (float) (20 * Math.log10(peak));
        return Math.max(AudioProcessorInterface.MIN_DB, 
                       Math.min(AudioProcessorInterface.MAX_DB, db));
    }

    public void reset() {
        sum = 0;
        peak = 0;
        position = 0;
        isInitialized = false;
        for (int i = 0; i < windowSize; i++) {
            buffer[i] = 0;
        }
    }

    public boolean isInitialized() {
        return isInitialized;
    }

    public int getWindowSize() {
        return windowSize;
    }

    public void setDecayRate(float rate) {
        if (rate > 0 && rate < 1) {
            this.decayRate = rate;
        }
    }

    public float getDecayRate() {
        return decayRate;
    }
}

И

package com.vlq.audioprocessor;

public class SpatialProcessor {
    private final int sampleRate;
    private float roomSize;
    private float reflectionAmount;
    private float[] delayBuffer;
    private int delayIndex;
    private static final int MAX_DELAY = 4800; // 100ms at 48kHz
    private float currentPosition;

    public SpatialProcessor(int sampleRate, float roomSize) {
        this.sampleRate = sampleRate;
        this.roomSize = Math.max(0.1f, Math.min(1.0f, roomSize));
        this.reflectionAmount = 0.3f;
        this.delayBuffer = new float[MAX_DELAY];
        this.delayIndex = 0;
        this.currentPosition = 0.0f;
    }

    public void setReflectionAmount(float amount) {
        this.reflectionAmount = Math.max(0.0f, Math.min(1.0f, amount));
    }

    public void setRoomSize(float size) {
        this.roomSize = Math.max(0.1f, Math.min(1.0f, size));
    }

    public float process(float input, float position) {
        // Вычисляем задержку на основе размера комнаты и позиции
        int delay = (int)(roomSize * MAX_DELAY * (1.0f + position * 0.5f));
        delay = Math.min(delay, MAX_DELAY - 1);

        // Сохраняем входной сигнал в буфер задержки
        delayBuffer[delayIndex] = input;

        // Вычисляем индекс для чтения задержанного сигнала
        int readIndex = delayIndex - delay;
        if (readIndex < 0) readIndex += MAX_DELAY;

        // Получаем задержанный сигнал
        float delayedSignal = delayBuffer[readIndex];

        // Обновляем индекс записи
        delayIndex = (delayIndex + 1) % MAX_DELAY;

        // Смешиваем прямой и отраженный сигналы
        return input + (delayedSignal * reflectionAmount);
    }

    public void release() {
        delayBuffer = null;
    }
    
    public void updatePosition(float position) {
        this.currentPosition = Math.max(-1.0f, Math.min(1.0f, position));
    }

    public void update() {
        // Обновление внутренних параметров при необходимости
        process(0.0f, currentPosition);
    }
}

И

package com.vlq.audioprocessor;

import androidx.fragment.app.Fragment;
import androidx.fragment.app.FragmentActivity;
import androidx.viewpager2.adapter.FragmentStateAdapter;

public class ViewPagerAdapter extends FragmentStateAdapter {
    public ViewPagerAdapter(FragmentActivity activity) {
        super(activity);
    }

    @Override
    public Fragment createFragment(int position) {
        return position == 0 ? new DSPFragment() : new BrowserFragment();
    }

    @Override
    public int getItemCount() {
        return 2;
    }
}

И


package com.vlq.audioprocessor;

import android.content.Context;
import android.media.AudioFormat;
import android.media.AudioRecord;
import android.media.MediaRecorder;
import android.media.projection.MediaProjection;
import android.os.Handler;
import android.os.HandlerThread;
import android.util.Log;
import android.webkit.WebView;
import android.media.AudioManager;

public class WebAudioCapturer {
    private static final String TAG = "WebAudioCapturer";
    private static final int SAMPLE_RATE = 44100;
    private static final int CHANNEL_CONFIG = AudioFormat.CHANNEL_IN_STEREO;
    private static final int AUDIO_FORMAT = AudioFormat.ENCODING_PCM_FLOAT;
    private static final int BUFFER_SIZE = AudioRecord.getMinBufferSize(
            SAMPLE_RATE, CHANNEL_CONFIG, AUDIO_FORMAT) * 2;

    private AudioRecord audioRecord;
    private HandlerThread handlerThread;
    private Handler handler;
    private volatile boolean isCapturing;
    private WebView attachedWebView;
    private final float[] captureBuffer;
    private final Object lock = new Object();
    private MediaProjection mediaProjection;
    private AudioManager audioManager;
    private AudioCaptureCallback callback = null;

    public interface AudioCaptureCallback {
        void onAudioDataCaptured(float[] audioData, int length);
    }
    
    public WebAudioCapturer(Context context, int sampleRate, int bufferSize) {
        this.audioManager = (AudioManager) context.getSystemService(Context.AUDIO_SERVICE);
        this.captureBuffer = new float[bufferSize];
    }

    public void setCallback(AudioCaptureCallback callback) {
        this.callback = callback;
        if (callback != null && isCapturing) {
            handler.post(captureRunnable);
        }
    }

    public void attachWebView(WebView webView) {
        synchronized (lock) {
            this.attachedWebView = webView;
            if (webView != null) {
                setupWebViewAudioBridge(webView);
            }
        }
    }

    private void setupWebViewAudioBridge(WebView webView) {
        webView.getSettings().setJavaScriptEnabled(true);
        webView.addJavascriptInterface(new WebAudioBridge(), "AudioBridge");
        
        String script = "javascript:" +
                "var audioContext = new (window.AudioContext || window.webkitAudioContext)();" +
                "var processor = audioContext.createScriptProcessor(4096, 2, 2);" +
                "processor.onaudioprocess = function(e) {" +
                "    var left = e.inputBuffer.getChannelData(0);" +
                "    var right = e.inputBuffer.getChannelData(1);" +
                "    var interleaved = new Float32Array(left.length * 2);" +
                "    for(var i = 0; i < left.length; i++) {" +
                "        interleaved[i * 2] = left[i];" +
                "        interleaved[i * 2 + 1] = right[i];" +
                "    }" +
                "    AudioBridge.processAudio(Array.from(interleaved));" +
                "};" +
                "processor.connect(audioContext.destination);";

        webView.evaluateJavascript(script, null);
    }

    public void startCapture(MediaProjection projection) {
        synchronized (lock) {
            if (isCapturing) {
                return;
            }

            this.mediaProjection = projection;

            try {
                if (audioManager != null) {
                    audioManager.setStreamVolume(AudioManager.STREAM_MUSIC, 0, 0);
                    audioManager.setStreamMute(AudioManager.STREAM_MUSIC, true);
                    audioManager.setParameters("MTK_AUDIO_PATH=processor");
                    audioManager.setParameters("SET_FORCE_ROUTE=1");
                    audioManager.setParameters("MTK_STREAM_TYPE=AUDIO_STREAM_PROC");
                    audioManager.setParameters("SET_WEBAUDIO_ENABLE=1");
                }

                audioRecord = new AudioRecord.Builder()
                    .setAudioSource(MediaRecorder.AudioSource.VOICE_RECOGNITION)
                    .setAudioFormat(new AudioFormat.Builder()
                        .setEncoding(AUDIO_FORMAT)
                        .setSampleRate(SAMPLE_RATE)
                        .setChannelMask(CHANNEL_CONFIG)
                        .build())
                    .setBufferSizeInBytes(BUFFER_SIZE)
                    .build();

                if (audioRecord.getState() == AudioRecord.STATE_INITIALIZED) {
                    audioRecord.startRecording();
                    isCapturing = true;
                    handlerThread = new HandlerThread("WebAudioCaptureThread");
                    handlerThread.start();
                    handler = new Handler(handlerThread.getLooper());
                    handler.post(captureRunnable);
                    Log.d(TAG, "Internal audio capture started");
                }
            } catch (Exception e) {
                Log.e(TAG, "Error starting capture: " + e.getMessage());
                releaseResources();
            }
        }
    }

    public void stopCapture() {
        synchronized (lock) {
            isCapturing = false;
            if (mediaProjection != null) {
                mediaProjection.stop();
                mediaProjection = null;
            }
            releaseResources();
            Log.d(TAG, "Web audio capture stopped");
        }
    }

    private final Runnable captureRunnable = new Runnable() {
        @Override
        public void run() {
            while (isCapturing) {
                int result = audioRecord.read(
                        captureBuffer, 0, BUFFER_SIZE, AudioRecord.READ_BLOCKING);
                
                if (result > 0 && callback != null) {
                    callback.onAudioDataCaptured(captureBuffer, result);
                }
            }
        }
    };

    public void release() {
        stopCapture();
        if (attachedWebView != null) {
            attachedWebView.evaluateJavascript(
                "if(audioContext) audioContext.close();", null);
            attachedWebView = null;
        }
    }

    private void releaseResources() {
        if (audioRecord != null) {
            try {
                audioRecord.stop();
                audioRecord.release();
            } catch (Exception e) {
                Log.e(TAG, "Error releasing AudioRecord: " + e.getMessage());
            }
            audioRecord = null;
        }

        if (handlerThread != null) {
            try {
                handlerThread.quitSafely();
            } catch (Exception e) {
                Log.e(TAG, "Error stopping handler thread: " + e.getMessage());
            }
            handlerThread = null;
        }

        handler = null;
    }

    private class WebAudioBridge {
        @android.webkit.JavascriptInterface
        public void processAudio(float[] audioData) {
            if (!isCapturing || callback == null) return;
            callback.onAudioDataCaptured(audioData, audioData.length);
        }
    }

    public boolean isCapturing() {
        return isCapturing;
    }
}

И

package com.vlq.audioprocessor;

public class WebAudioInterface {
    private final AudioProcessor audioProcessor;
    
    public WebAudioInterface(AudioProcessor processor) {
        this.audioProcessor = processor;
    }
    
    @android.webkit.JavascriptInterface
    public void updateChannelVolume(int channel, float volume) {
        if (audioProcessor != null) {
            audioProcessor.setChannelVolume(channel, volume);
        }
    }
    
    @android.webkit.JavascriptInterface
    public void updateChannelBass(int channel, float bass) {
        if (audioProcessor != null) {
            audioProcessor.setChannelBass(channel, bass);
        }
    }
    
    @android.webkit.JavascriptInterface
    public void updateChannelLPF(int channel, boolean enabled) {
        if (audioProcessor != null) {
            audioProcessor.setChannelLPF(channel, enabled);
        }
    }
}

И

package com.vlq.audioprocessor;

import android.content.Context;
import android.webkit.WebView;
import android.webkit.JavascriptInterface;
import android.util.Log;
import android.media.projection.MediaProjection;

public class WebViewAudioCapture {
    private WebView webView;
    private final AudioProcessor audioProcessor;
    private final Context context;
    private MediaProjection mediaProjection;
    
    private static final String TAG = "WebViewAudioCapture";
    
    // Добавляем внутренний класс AudioBridge
    private class AudioBridge {
        @JavascriptInterface
        public void processAudio(float[] audioData) {
            if (audioProcessor != null) {
                try {
                    audioProcessor.processWebAudio(audioData, audioData.length);
                } catch (Exception e) {
                    Log.e(TAG, "Error in AudioBridge processAudio: " + e.getMessage());
                }
            }
        }
    }

    public void setMediaProjection(MediaProjection projection) {
        this.mediaProjection = projection;
    }

    public WebViewAudioCapture(Context context, AudioProcessor processor) {
        this.context = context;
        this.audioProcessor = processor;
    }
    
    public void muteWebViewAudio() {
        if (webView != null) {
            webView.evaluateJavascript(
                "document.querySelectorAll('audio, video').forEach(el => {" +
                "    el.volume = 0;" +
                "    el.muted = true;" +
                "});",
                null
            );
        }
    }

    public void attachWebView(WebView webView) {
        webView.getSettings().setJavaScriptEnabled(true);
        webView.reload();
        this.webView = webView;
        if (webView != null) {
            setupWebView();
        }
    }
    
    private void initializeAudioCapture() {
        if (webView != null) {
            webView.evaluateJavascript(
                "window.audioContext && window.audioContext.close();" +
                "window.audioContext = new (window.AudioContext || window.webkitAudioContext)({sampleRate: 48000});" +
                "window.audioContext.destination.channelCount = 2;" +
                "window.audioContext.destination.channelCountMode = 'explicit';" +
                "window.audioContext.destination.channelInterpretation = 'speakers';" +
                "document.querySelectorAll('audio,video').forEach(el => { el.volume = 0; el.muted = true; });",
                null
            );
        }
    }

    private void setupWebViewAudioBridge(WebView webView) {
        webView.evaluateJavascript(
            "window.audioContext && window.audioContext.close();" +
            "window.audioContext = new (window.AudioContext || window.webkitAudioContext)({sampleRate: 48000});" +
            "window.audioContext.destination.channelCount = 2;" +
            "window.audioContext.destination.channelCountMode = 'explicit';" +
            "window.audioContext.destination.channelInterpretation = 'speakers';" +
            "document.querySelectorAll('audio,video').forEach(el => { el.volume = 0; el.muted = true; });",
            null
        );
    }

    private void setupWebView() {
        if (webView != null) {
            webView.getSettings().setJavaScriptEnabled(true);
            webView.addJavascriptInterface(new AudioBridge(), "AudioBridge");
            
            String script = "javascript:(function() {" +
                // Полностью перехватываем аудиоконтекст
                "    const origAudioContext = window.AudioContext || window.webkitAudioContext;" +
                "    class CustomAudioContext extends origAudioContext {" +
                "        constructor(options) {" +
                "            super(options);" +
                "            const origDestination = this.destination;" +
                "            const processor = this.createScriptProcessor(4096, 2, 2);" +
                "            const nullNode = this.createGain();" +
                "            nullNode.gain.value = 0;" +
                
                "            processor.onaudioprocess = function(e) {" +
                "                const inputL = e.inputBuffer.getChannelData(0);" +
                "                const inputR = e.inputBuffer.getChannelData(1);" +
                "                const buffer = new Float32Array(inputL.length * 2);" +
                "                for(let i = 0; i < inputL.length; i++) {" +
                "                    buffer[i * 2] = inputL[i];" +
                "                    buffer[i * 2 + 1] = inputR[i];" +
                "                }" +
                "                AudioBridge.processAudio(buffer);" +
                
                "                // Обнуляем выходной буфер оригинального звука" +
                "                const outputL = e.outputBuffer.getChannelData(0);" +
                "                const outputR = e.outputBuffer.getChannelData(1);" +
                "                outputL.fill(0);" +
                "                outputR.fill(0);" +
                "            };" +

                // Переопределяем destination
                "            Object.defineProperty(this, 'destination', {" +
                "                get: () => {" +
                "                    processor.connect(nullNode);" +
                "                    nullNode.connect(origDestination);" +
                "                    return processor;" +
                "                }," +
                "                configurable: false" +
                "            });" +
                "        }" +
                "    }" +

                "    window.AudioContext = CustomAudioContext;" +
                "    window.webkitAudioContext = CustomAudioContext;" +

                // Перехват создания медиа элементов
                "    const origCreateElement = document.createElement.bind(document);" +
                "    document.createElement = function(element) {" +
                "        const el = origCreateElement(element);" +
                "        if (element.toLowerCase() === 'audio' || element.toLowerCase() === 'video') {" +
                "            Object.defineProperty(el, 'volume', {" +
                "                value: 0," +
                "                writable: false," +
                "                configurable: false" +
                "            });" +
                "            Object.defineProperty(el, 'muted', {" +
                "                value: true," +
                "                writable: false," +
                "                configurable: false" +
                "            });" +
                
                "            const origPlay = el.play;" +
                "            el.play = function() {" +
                "                this.muted = true;" +
                "                this.volume = 0;" +
                "                return origPlay.apply(this, arguments);" +
                "            };" +
                "        }" +
                "        return el;" +
                "    };" +

                // Наблюдатель за DOM
                "    new MutationObserver((mutations) => {" +
                "        mutations.forEach(mutation => {" +
                "            mutation.addedNodes.forEach(node => {" +
                "                if (node instanceof HTMLMediaElement) {" +
                "                    node.volume = 0;" +
                "                    node.muted = true;" +
                "                }" +
                "            });" +
                "        });" +
                "    }).observe(document, { childList: true, subtree: true });" +

                // Блокировка API управления звуком
                "    const audioAPI = ['setVolume', 'play', 'unmute'];" +
                "    audioAPI.forEach(method => {" +
                "        window[method] = function() { return false; };" +
                "    });" +
                "})();";

            webView.evaluateJavascript(script, null);
        }
    }

    
    public void startCapture() {
        if (webView != null) {
            webView.post(() -> {
                setupWebViewAudioBridge(webView);
                webView.evaluateJavascript(
                    "document.readyState === 'complete' ? window.audioContext.resume() : " +
                    "document.addEventListener('DOMContentLoaded', () => window.audioContext.resume());",
                    null
                );
            });
        }
    }

    public void stopCapture() {
        if (webView != null) {
            webView.evaluateJavascript(
                "if(window.audioContext) { window.audioContext.close(); }",
                null
            );
        }
    }

    public void release() {
        if (webView != null) {
            webView.removeJavascriptInterface("AudioBridge");
            webView = null;
        }
    }
    
    @JavascriptInterface
public void processAudioData(String jsonData) {
    try {
        String[] values = jsonData.replace("[", "").replace("]", "").split(",");
        float[] buffer = new float[values.length];

        for (int i = 0; i < values.length; i++) {
            buffer[i] = Float.parseFloat(values[i]);
        }

        if (audioProcessor != null) {
            audioProcessor.processWebAudio(buffer, buffer.length);  // Передаем длину буфера
        }

    } catch (Exception e) {
        Log.e(TAG, "Ошибка обработки WebView аудио: " + e.getMessage());
    }
}
}

И

<?xml version="1.0" encoding="utf-8"?>
<shape xmlns:android="http://schemas.android.com/apk/res/android"
    android:shape="rectangle">
    <solid android:color="#1A1A1A" /> <!-- Слегка светлее черного -->
    <corners android:radius="8dp" />
    <stroke
        android:width="1dp"
        android:color="@color/primary" />
    <padding
        android:left="8dp"
        android:top="8dp"
        android:right="8dp"
        android:bottom="8dp" />
</shape>

И

<?xml version="1.0" encoding="utf-8"?>
<vector xmlns:android="http://schemas.android.com/apk/res/android"
    android:width="108dp"
    android:height="108dp"
    android:viewportWidth="108"
    android:viewportHeight="108">
    <path
        android:fillColor="#3DDC84"
        android:pathData="M0,0h108v108h-108z" />
    <path
        android:fillColor="#00000000"
        android:pathData="M9,0L9,108"
        android:strokeWidth="0.8"
        android:strokeColor="#33FFFFFF" />
    <path
        android:fillColor="#00000000"
        android:pathData="M19,0L19,108"
        android:strokeWidth="0.8"
        android:strokeColor="#33FFFFFF" />
    <path
        android:fillColor="#00000000"
        android:pathData="M29,0L29,108"
        android:strokeWidth="0.8"
        android:strokeColor="#33FFFFFF" />
    <path
        android:fillColor="#00000000"
        android:pathData="M39,0L39,108"
        android:strokeWidth="0.8"
        android:strokeColor="#33FFFFFF" />
    <path
        android:fillColor="#00000000"
        android:pathData="M49,0L49,108"
        android:strokeWidth="0.8"
        android:strokeColor="#33FFFFFF" />
    <path
        android:fillColor="#00000000"
        android:pathData="M59,0L59,108"
        android:strokeWidth="0.8"
        android:strokeColor="#33FFFFFF" />
    <path
        android:fillColor="#00000000"
        android:pathData="M69,0L69,108"
        android:strokeWidth="0.8"
        android:strokeColor="#33FFFFFF" />
    <path
        android:fillColor="#00000000"
        android:pathData="M79,0L79,108"
        android:strokeWidth="0.8"
        android:strokeColor="#33FFFFFF" />
    <path
        android:fillColor="#00000000"
        android:pathData="M89,0L89,108"
        android:strokeWidth="0.8"
        android:strokeColor="#33FFFFFF" />
    <path
        android:fillColor="#00000000"
        android:pathData="M99,0L99,108"
        android:strokeWidth="0.8"
        android:strokeColor="#33FFFFFF" />
    <path
        android:fillColor="#00000000"
        android:pathData="M0,9L108,9"
        android:strokeWidth="0.8"
        android:strokeColor="#33FFFFFF" />
    <path
        android:fillColor="#00000000"
        android:pathData="M0,19L108,19"
        android:strokeWidth="0.8"
        android:strokeColor="#33FFFFFF" />
    <path
        android:fillColor="#00000000"
        android:pathData="M0,29L108,29"
        android:strokeWidth="0.8"
        android:strokeColor="#33FFFFFF" />
    <path
        android:fillColor="#00000000"
        android:pathData="M0,39L108,39"
        android:strokeWidth="0.8"
        android:strokeColor="#33FFFFFF" />
    <path
        android:fillColor="#00000000"
        android:pathData="M0,49L108,49"
        android:strokeWidth="0.8"
        android:strokeColor="#33FFFFFF" />
    <path
        android:fillColor="#00000000"
        android:pathData="M0,59L108,59"
        android:strokeWidth="0.8"
        android:strokeColor="#33FFFFFF" />
    <path
        android:fillColor="#00000000"
        android:pathData="M0,69L108,69"
        android:strokeWidth="0.8"
        android:strokeColor="#33FFFFFF" />
    <path
        android:fillColor="#00000000"
        android:pathData="M0,79L108,79"
        android:strokeWidth="0.8"
        android:strokeColor="#33FFFFFF" />
    <path
        android:fillColor="#00000000"
        android:pathData="M0,89L108,89"
        android:strokeWidth="0.8"
        android:strokeColor="#33FFFFFF" />
    <path
        android:fillColor="#00000000"
        android:pathData="M0,99L108,99"
        android:strokeWidth="0.8"
        android:strokeColor="#33FFFFFF" />
    <path
        android:fillColor="#00000000"
        android:pathData="M19,29L89,29"
        android:strokeWidth="0.8"
        android:strokeColor="#33FFFFFF" />
    <path
        android:fillColor="#00000000"
        android:pathData="M19,39L89,39"
        android:strokeWidth="0.8"
        android:strokeColor="#33FFFFFF" />
    <path
        android:fillColor="#00000000"
        android:pathData="M19,49L89,49"
        android:strokeWidth="0.8"
        android:strokeColor="#33FFFFFF" />
    <path
        android:fillColor="#00000000"
        android:pathData="M19,59L89,59"
        android:strokeWidth="0.8"
        android:strokeColor="#33FFFFFF" />
    <path
        android:fillColor="#00000000"
        android:pathData="M19,69L89,69"
        android:strokeWidth="0.8"
        android:strokeColor="#33FFFFFF" />
    <path
        android:fillColor="#00000000"
        android:pathData="M19,79L89,79"
        android:strokeWidth="0.8"
        android:strokeColor="#33FFFFFF" />
    <path
        android:fillColor="#00000000"
        android:pathData="M29,19L29,89"
        android:strokeWidth="0.8"
        android:strokeColor="#33FFFFFF" />
    <path
        android:fillColor="#00000000"
        android:pathData="M39,19L39,89"
        android:strokeWidth="0.8"
        android:strokeColor="#33FFFFFF" />
    <path
        android:fillColor="#00000000"
        android:pathData="M49,19L49,89"
        android:strokeWidth="0.8"
        android:strokeColor="#33FFFFFF" />
    <path
        android:fillColor="#00000000"
        android:pathData="M59,19L59,89"
        android:strokeWidth="0.8"
        android:strokeColor="#33FFFFFF" />
    <path
        android:fillColor="#00000000"
        android:pathData="M69,19L69,89"
        android:strokeWidth="0.8"
        android:strokeColor="#33FFFFFF" />
    <path
        android:fillColor="#00000000"
        android:pathData="M79,19L79,89"
        android:strokeWidth="0.8"
        android:strokeColor="#33FFFFFF" />
</vector>

И

<?xml version="1.0" encoding="utf-8"?>
<vector xmlns:android="http://schemas.android.com/apk/res/android"
    android:width="108dp"
    android:height="108dp"
    android:viewportWidth="108"
    android:viewportHeight="108">
    <path
        android:fillColor="#FF000000"
        android:pathData="M44,54H64V74H44Z"/>
</vector>

И

<?xml version="1.0" encoding="utf-8"?>
<LinearLayout
     xmlns:android="http://schemas.android.com/apk/res/android"
     xmlns:app="http://schemas.android.com/apk/res-auto"
     android:layout_height="match_parent"
     android:layout_width="match_parent"
     android:background="@color/black"
     android:orientation="vertical">

    <com.google.android.material.appbar.AppBarLayout
         android:layout_height="wrap_content"
         android:layout_width="match_parent"
         android:background="@color/black">

        <TextView
             android:layout_height="wrap_content"
             android:layout_width="match_parent"
             android:gravity="center"
             android:padding="16dp"
             android:shadowRadius="2"
             android:textSize="18sp"
             android:textColor="@color/primary"
             android:shadowColor="@color/primary_dark"
             android:shadowDx="1"
             android:shadowDy="1"
             android:text="VLQ Audio Processor"
             android:textStyle="bold" />

        <com.google.android.material.tabs.TabLayout
             android:layout_height="wrap_content"
             android:layout_width="match_parent"
             app:tabMode="fixed"
             android:background="@color/black"
             app:tabIndicatorColor="@color/accent"
             app:tabGravity="fill"
             app:tabTextColor="@color/gray"
             app:tabSelectedTextColor="@color/primary"
             android:id="@+id/tabLayout" />

    </com.google.android.material.appbar.AppBarLayout>

    <androidx.viewpager2.widget.ViewPager2
         android:layout_height="match_parent"
         android:layout_width="match_parent"
         android:background="@color/black"
         android:id="@+id/viewPager" />

</LinearLayout>

И

<?xml version="1.0" encoding="utf-8"?>
<LinearLayout
     xmlns:android="http://schemas.android.com/apk/res/android"
     android:layout_height="match_parent"
     android:layout_width="match_parent"
     android:orientation="vertical">

    <LinearLayout
         android:layout_height="wrap_content"
         android:layout_width="match_parent"
         android:background="@color/light_gray"
         android:padding="8dp"
         android:orientation="horizontal">

        <ImageButton
             android:layout_height="40dp"
             android:layout_width="40dp"
             android:src="@android:drawable/ic_media_previous"
             android:contentDescription="Back"
             android:background="?attr/selectableItemBackgroundBorderless"
             android:id="@+id/buttonBack" />

        <ImageButton
             android:layout_height="40dp"
             android:layout_width="40dp"
             android:src="@android:drawable/ic_media_next"
             android:contentDescription="Forward"
             android:background="?attr/selectableItemBackgroundBorderless"
             android:id="@+id/buttonForward" />

        <EditText
             android:layout_height="match_parent"
             android:layout_width="0dp"
             android:imeOptions="actionGo"
             android:background="@color/white"
             android:hint="Enter URL"
             android:padding="8dp"
             android:layout_marginHorizontal="8dp"
             android:layout_weight="1"
             android:inputType="textUri"
             android:id="@+id/editTextUrl" />

        <ImageButton
             android:layout_height="40dp"
             android:layout_width="40dp"
             android:src="@android:drawable/ic_menu_rotate"
             android:contentDescription="Refresh"
             android:background="?attr/selectableItemBackgroundBorderless"
             android:id="@+id/buttonRefresh" />

    </LinearLayout>

    <ProgressBar
         android:layout_height="2dp"
         android:layout_width="match_parent"
         style="?android:attr/progressBarStyleHorizontal"
         android:id="@+id/progressBar" />

    <android.webkit.WebView
         android:layout_height="0dp"
         android:layout_width="match_parent"
         android:layout_weight="1"
         android:id="@+id/webView">

    </android.webkit.WebView>

</LinearLayout>

И

<?xml version="1.0" encoding="utf-8"?>
<ScrollView
     xmlns:android="http://schemas.android.com/apk/res/android"
     android:layout_height="match_parent"
     android:layout_width="match_parent"
     android:background="@color/black"
     android:padding="8dp">

    <LinearLayout
         android:layout_height="wrap_content"
         android:layout_width="match_parent"
         android:orientation="vertical">

        <TextView
             android:layout_height="wrap_content"
             android:layout_width="match_parent"
             android:padding="8dp"
             android:shadowRadius="2"
             android:textColor="@color/primary"
             android:shadowColor="@color/primary_dark"
             android:shadowDx="1"
             android:shadowDy="1"
             android:text="FRONT CHANNELS"
             android:textStyle="bold" />

        <LinearLayout
             android:layout_height="wrap_content"
             android:layout_width="match_parent"
             android:orientation="horizontal">

            <LinearLayout
                 android:layout_height="wrap_content"
                 android:layout_width="0dp"
                 android:orientation="vertical"
                 style="@style/ChannelCard"
                 android:layout_weight="1">

                <TextView
                     android:layout_height="wrap_content"
                     android:layout_width="wrap_content"
                     style="@style/ChannelTitle"
                     android:text="Left Front" />

                <TextView
                     android:layout_height="wrap_content"
                     android:layout_width="wrap_content"
                     style="@style/SliderLabel"
                     android:text="Volume" />

                <SeekBar
                     android:layout_height="wrap_content"
                     android:layout_width="match_parent"
                     android:max="100"
                     style="@style/CustomSeekBar"
                     android:progress="80"
                     android:id="@+id/seekBarLeftFrontVolume" />

                <TextView
                     android:layout_height="wrap_content"
                     android:layout_width="wrap_content"
                     style="@style/SliderLabel"
                     android:id="@+id/textViewLeftFrontVolume"
                     android:text="-1.9 dB" />

                <TextView
                     android:layout_height="wrap_content"
                     android:layout_width="wrap_content"
                     style="@style/SliderLabel"
                     android:text="Bass" />

                <SeekBar
                     android:layout_height="wrap_content"
                     android:layout_width="match_parent"
                     android:max="100"
                     style="@style/CustomSeekBar"
                     android:progress="50"
                     android:id="@+id/seekBarLeftFrontBass" />

                <TextView
                     android:layout_height="wrap_content"
                     android:layout_width="wrap_content"
                     style="@style/SliderLabel"
                     android:id="@+id/textViewLeftFrontBass"
                     android:text="-6.0 dB" />

                <CheckBox
                     android:layout_height="wrap_content"
                     android:layout_width="wrap_content"
                     style="@style/CustomCheckBox"
                     android:checked="true"
                     android:id="@+id/checkBoxLeftFrontLPF"
                     android:text="LPF" />

                <TextView
                     android:layout_height="wrap_content"
                     android:layout_width="wrap_content"
                     style="@style/SliderLabel"
                     android:id="@+id/textViewLeftFrontLevel"
                     android:text="Level: -12dB" />

            </LinearLayout>

            <LinearLayout
                 android:layout_height="wrap_content"
                 android:layout_width="0dp"
                 android:orientation="vertical"
                 style="@style/ChannelCard"
                 android:layout_weight="1">

                <TextView
                     android:layout_height="wrap_content"
                     android:layout_width="wrap_content"
                     style="@style/ChannelTitle"
                     android:text="Right Front" />

                <TextView
                     android:layout_height="wrap_content"
                     android:layout_width="wrap_content"
                     style="@style/SliderLabel"
                     android:text="Volume" />

                <SeekBar
                     android:layout_height="wrap_content"
                     android:layout_width="match_parent"
                     android:max="100"
                     style="@style/CustomSeekBar"
                     android:progress="80"
                     android:id="@+id/seekBarRightFrontVolume" />

                <TextView
                     android:layout_height="wrap_content"
                     android:layout_width="wrap_content"
                     style="@style/SliderLabel"
                     android:id="@+id/textViewRightFrontVolume"
                     android:text="-1.9 dB" />

                <TextView
                     android:layout_height="wrap_content"
                     android:layout_width="wrap_content"
                     style="@style/SliderLabel"
                     android:text="Bass" />

                <SeekBar
                     android:layout_height="wrap_content"
                     android:layout_width="match_parent"
                     android:max="100"
                     style="@style/CustomSeekBar"
                     android:progress="50"
                     android:id="@+id/seekBarRightFrontBass" />

                <TextView
                     android:layout_height="wrap_content"
                     android:layout_width="wrap_content"
                     style="@style/SliderLabel"
                     android:id="@+id/textViewRightFrontBass"
                     android:text="-6.0 dB" />

                <CheckBox
                     android:layout_height="wrap_content"
                     android:layout_width="wrap_content"
                     style="@style/CustomCheckBox"
                     android:checked="true"
                     android:id="@+id/checkBoxRightFrontLPF"
                     android:text="LPF" />

                <TextView
                     android:layout_height="wrap_content"
                     android:layout_width="wrap_content"
                     style="@style/SliderLabel"
                     android:id="@+id/textViewRightFrontLevel"
                     android:text="Level: -10dB" />

            </LinearLayout>

        </LinearLayout>

        <TextView
             android:layout_height="wrap_content"
             android:layout_width="match_parent"
             android:padding="8dp"
             android:shadowRadius="2"
             android:textColor="@color/primary"
             android:shadowColor="@color/primary_dark"
             android:shadowDx="1"
             android:shadowDy="1"
             android:text="REAR CHANNELS"
             android:textStyle="bold" />

        <LinearLayout
             android:layout_height="wrap_content"
             android:layout_width="match_parent"
             android:orientation="horizontal">

            <LinearLayout
                 android:layout_height="wrap_content"
                 android:layout_width="0dp"
                 android:orientation="vertical"
                 style="@style/ChannelCard"
                 android:layout_weight="1">

                <TextView
                     android:layout_height="wrap_content"
                     android:layout_width="wrap_content"
                     style="@style/ChannelTitle"
                     android:text="Left Rear" />

                <TextView
                     android:layout_height="wrap_content"
                     android:layout_width="wrap_content"
                     style="@style/SliderLabel"
                     android:text="Volume" />

                <SeekBar
                     android:layout_height="wrap_content"
                     android:layout_width="match_parent"
                     android:max="100"
                     style="@style/CustomSeekBar"
                     android:progress="70"
                     android:id="@+id/seekBarLeftRearVolume" />

                <TextView
                     android:layout_height="wrap_content"
                     android:layout_width="wrap_content"
                     style="@style/SliderLabel"
                     android:id="@+id/textViewLeftRearVolume"
                     android:text="-3.1 dB" />

                <TextView
                     android:layout_height="wrap_content"
                     android:layout_width="wrap_content"
                     style="@style/SliderLabel"
                     android:text="Bass" />

                <SeekBar
                     android:layout_height="wrap_content"
                     android:layout_width="match_parent"
                     android:max="100"
                     style="@style/CustomSeekBar"
                     android:progress="50"
                     android:id="@+id/seekBarLeftRearBass" />

                <TextView
                     android:layout_height="wrap_content"
                     android:layout_width="wrap_content"
                     style="@style/SliderLabel"
                     android:id="@+id/textViewLeftRearBass"
                     android:text="-6.0 dB" />

                <CheckBox
                     android:layout_height="wrap_content"
                     android:layout_width="wrap_content"
                     style="@style/CustomCheckBox"
                     android:checked="true"
                     android:id="@+id/checkBoxLeftRearLPF"
                     android:text="LPF" />

                <TextView
                     android:layout_height="wrap_content"
                     android:layout_width="wrap_content"
                     style="@style/SliderLabel"
                     android:id="@+id/textViewLeftRearLevel"
                     android:text="Level: -14dB" />

            </LinearLayout>

            <LinearLayout
                 android:layout_height="wrap_content"
                 android:layout_width="0dp"
                 android:orientation="vertical"
                 style="@style/ChannelCard"
                 android:layout_weight="1">

                <TextView
                     android:layout_height="wrap_content"
                     android:layout_width="wrap_content"
                     style="@style/ChannelTitle"
                     android:text="Right Rear" />

                <TextView
                     android:layout_height="wrap_content"
                     android:layout_width="wrap_content"
                     style="@style/SliderLabel"
                     android:text="Volume" />

                <SeekBar
                     android:layout_height="wrap_content"
                     android:layout_width="match_parent"
                     android:max="100"
                     style="@style/CustomSeekBar"
                     android:progress="70"
                     android:id="@+id/seekBarRightRearVolume" />

                <TextView
                     android:layout_height="wrap_content"
                     android:layout_width="wrap_content"
                     style="@style/SliderLabel"
                     android:id="@+id/textViewRightRearVolume"
                     android:text="-3.1 dB" />

                <TextView
                     android:layout_height="wrap_content"
                     android:layout_width="wrap_content"
                     style="@style/SliderLabel"
                     android:text="Bass" />

                <SeekBar
                     android:layout_height="wrap_content"
                     android:layout_width="match_parent"
                     android:max="100"
                     style="@style/CustomSeekBar"
                     android:progress="50"
                     android:id="@+id/seekBarRightRearBass" />

                <TextView
                     android:layout_height="wrap_content"
                     android:layout_width="wrap_content"
                     style="@style/SliderLabel"
                     android:id="@+id/textViewRightRearBass"
                     android:text="-6.0 dB" />

                <CheckBox
                     android:layout_height="wrap_content"
                     android:layout_width="wrap_content"
                     style="@style/CustomCheckBox"
                     android:checked="true"
                     android:id="@+id/checkBoxRightRearLPF"
                     android:text="LPF" />

                <TextView
                     android:layout_height="wrap_content"
                     android:layout_width="wrap_content"
                     style="@style/SliderLabel"
                     android:id="@+id/textViewRightRearLevel"
                     android:text="Level: -11dB" />

            </LinearLayout>

        </LinearLayout>

        <TextView
             android:layout_height="wrap_content"
             android:layout_width="match_parent"
             android:padding="8dp"
             android:shadowRadius="2"
             android:textColor="@color/primary"
             android:shadowColor="@color/primary_dark"
             android:shadowDx="1"
             android:shadowDy="1"
             android:text="SUBWOOFER"
             android:textStyle="bold" />

        <LinearLayout
             android:layout_height="wrap_content"
             android:layout_width="match_parent"
             android:orientation="vertical"
             style="@style/ChannelCard">

            <TextView
                 android:layout_height="wrap_content"
                 android:layout_width="wrap_content"
                 style="@style/SliderLabel"
                 android:text="Volume" />

            <SeekBar
                 android:layout_height="wrap_content"
                 android:layout_width="match_parent"
                 android:max="100"
                 style="@style/CustomSeekBar"
                 android:progress="60"
                 android:id="@+id/seekBarSubwooferVolume" />

            <TextView
                 android:layout_height="wrap_content"
                 android:layout_width="wrap_content"
                 style="@style/SliderLabel"
                 android:id="@+id/textViewSubwooferVolume"
                 android:text="-4.4 dB" />

            <TextView
                 android:layout_height="wrap_content"
                 android:layout_width="wrap_content"
                 style="@style/SliderLabel"
                 android:text="Bass" />

            <SeekBar
                 android:layout_height="wrap_content"
                 android:layout_width="match_parent"
                 android:max="100"
                 style="@style/CustomSeekBar"
                 android:progress="75"
                 android:id="@+id/seekBarSubwooferBass" />

            <TextView
                 android:layout_height="wrap_content"
                 android:layout_width="wrap_content"
                 style="@style/SliderLabel"
                 android:id="@+id/textViewSubwooferBass"
                 android:text="-2.5 dB" />

            <CheckBox
                 android:layout_height="wrap_content"
                 android:layout_width="wrap_content"
                 style="@style/CustomCheckBox"
                 android:checked="true"
                 android:id="@+id/checkBoxSubwooferLPF"
                 android:text="LPF" />

            <TextView
                 android:layout_height="wrap_content"
                 android:layout_width="wrap_content"
                 style="@style/SliderLabel"
                 android:id="@+id/textViewSubwooferLevel"
                 android:text="Level: -8dB" />

        </LinearLayout>

        <TextView
             android:layout_height="wrap_content"
             android:layout_width="match_parent"
             android:padding="8dp"
             android:shadowRadius="2"
             android:textColor="@color/primary"
             android:shadowColor="@color/primary_dark"
             android:shadowDx="1"
             android:shadowDy="1"
             android:text="REAL-TIME ANALYSIS"
             android:textStyle="bold" />

        <LinearLayout
             android:layout_height="wrap_content"
             android:layout_width="match_parent"
             android:orientation="vertical"
             style="@style/ChannelCard">

            <TextView
                 android:layout_height="wrap_content"
                 android:layout_width="match_parent"
                 android:textAlignment="center"
                 android:shadowRadius="2"
                 android:textColor="@color/accent"
                 android:shadowColor="@color/black"
                 android:shadowDx="1"
                 android:shadowDy="1"
                 android:id="@+id/textViewAnalysis"
                 android:text="LF:-12dB  RF:-10dB\nLR:-14dB  RR:-11dB  SUB:-8dB" />

        </LinearLayout>

    </LinearLayout>

</ScrollView>

И

<?xml version="1.0" encoding="utf-8"?>
<resources>
    <color name="primary">#FFD700</color> <!-- Желтый -->
    <color name="primary_dark">#FF4500</color> <!-- Красный -->
    <color name="accent">#FF69B4</color> <!-- Розовый -->
    <color name="white">#FFFFFF</color>
    <color name="black">#000000</color>
    <color name="gray">#757575</color>
    <color name="light_gray">#EEEEEE</color>
    <color name="highlight">#32CD32</color> <!-- Зеленый -->
    <color name="text_primary">#FFD700</color> <!-- Желтый текст -->
    <color name="text_secondary">#FF69B4</color> <!-- Розовый текст -->
    <color name="background">#000000</color> <!-- Черный фон -->
</resources>

И

<?xml version="1.0" encoding="utf-8"?>
<resources>
    <!-- Общие строки приложения -->
    <string name="app_name">DSP Browser Processor</string>
    <string name="dsp_tab">DSP</string>
    <string name="browser_tab">Browser</string>

    <!-- Строки для DSP процессора -->
    <string name="dsp_status">DSP Processor Status</string>
    <string name="btn_start">Start Processing</string>
    <string name="btn_stop">Stop Processing</string>
    <string name="front_channels">Front Channels</string>
    <string name="rear_channels">Rear Channels</string>
    <string name="subwoofer">Subwoofer</string>
    <string name="channel_left_front">Left Front</string>
    <string name="channel_right_front">Right Front</string>
    <string name="channel_left_rear">Left Rear</string>
    <string name="channel_right_rear">Right Rear</string>
    <string name="channel_subwoofer">Subwoofer</string>
    <string name="volume">Volume</string>
    <string name="bass_boost">Bass Boost</string>
    <string name="lpf">LPF (20-200Hz)</string>
    <string name="level_format">Level: %1$d dB</string>

    <!-- Строки для браузера -->
    <string name="browser_hint">Enter URL or search query</string>
    <string name="btn_back">Back</string>
    <string name="btn_forward">Forward</string>
    <string name="btn_search">Search</string>
    <string name="loading">Loading…</string>
    <string name="error_loading">Error loading page</string>

    <!-- Уведомления -->
    <string name="notification_channel_name">Audio Processing</string>
    <string name="notification_channel_description">Shows when audio processing is active</string>
    <string name="notification_title">Audio Processing Active</string>
    <string name="notification_text">Processing audio in background</string>

    <!-- Сообщения об ошибках -->
    <string name="error_audio_init">Failed to initialize audio system</string>
    <string name="error_permission">Required permissions not granted</string>
    <string name="error_projection">Failed to start audio capture</string>
</resources>

И

<?xml version="1.0" encoding="utf-8"?>
<resources xmlns:android="http://schemas.android.com/apk/res/android">
    <style name="AppTheme" parent="Theme.MaterialComponents.NoActionBar">
        <item name="colorPrimary">@color/primary</item>
        <item name="colorPrimaryDark">@color/primary_dark</item>
        <item name="colorAccent">@color/accent</item>
        <item name="android:windowBackground">@color/black</item>
        <item name="android:textColorPrimary">@color/primary</item>
        <item name="android:textColorSecondary">@color/accent</item>
        <item name="android:colorControlNormal">@color/primary</item>
        <item name="android:colorControlActivated">@color/accent</item>
        <item name="android:colorControlHighlight">@color/highlight</item>
    </style>

    <style name="ChannelCard">
        <item name="android:layout_width">match_parent</item>
        <item name="android:layout_height">wrap_content</item>
        <item name="android:layout_margin">8dp</item>
        <item name="android:padding">16dp</item>
        <item name="android:background">@drawable/card_background</item>
        <item name="android:elevation">4dp</item>
        <item name="android:outlineProvider">bounds</item>
        <item name="android:clipToPadding">false</item>
    </style>

    <style name="ChannelTitle">
        <item name="android:layout_width">wrap_content</item>
        <item name="android:layout_height">wrap_content</item>
        <item name="android:textSize">16sp</item>
        <item name="android:textStyle">bold</item>
        <item name="android:layout_marginBottom">8dp</item>
        <item name="android:textColor">@color/primary</item>
        <item name="android:shadowColor">@color/black</item>
        <item name="android:shadowDx">1</item>
        <item name="android:shadowDy">1</item>
        <item name="android:shadowRadius">2</item>
    </style>

    <style name="SliderLabel">
        <item name="android:layout_width">wrap_content</item>
        <item name="android:layout_height">wrap_content</item>
        <item name="android:textSize">14sp</item>
        <item name="android:layout_marginTop">4dp</item>
        <item name="android:textColor">@color/accent</item>
        <item name="android:shadowColor">@color/black</item>
        <item name="android:shadowDx">1</item>
        <item name="android:shadowDy">1</item>
        <item name="android:shadowRadius">1</item>
    </style>

    <style name="CustomSeekBar" parent="Widget.AppCompat.SeekBar">
        <item name="android:progressTint">@color/primary</item>
        <item name="android:thumbTint">@color/accent</item>
        <item name="android:progressBackgroundTint">@color/gray</item>
    </style>

    <style name="CustomCheckBox" parent="Widget.AppCompat.CompoundButton.CheckBox">
        <item name="android:textColor">@color/primary</item>
        <item name="android:buttonTint">@color/accent</item>
    </style>
</resources>

И

<?xml version="1.0" encoding="utf-8"?>
<manifest xmlns:android="http://schemas.android.com/apk/res/android"
    xmlns:tools="http://schemas.android.com/tools">

    <uses-permission android:name="android.permission.INTERNET" />
    <uses-permission android:name="android.permission.MODIFY_AUDIO_SETTINGS" />
    <uses-permission android:name="android.permission.RECORD_AUDIO" />
    <uses-permission android:name="android.permission.FOREGROUND_SERVICE" />
    <uses-permission android:name="android.permission.POST_NOTIFICATIONS" />
    <uses-permission android:name="android.permission.BLUETOOTH" />
    <uses-permission android:name="android.permission.BLUETOOTH_CONNECT" />
    <uses-permission android:name="android.permission.MEDIA_CONTENT_CONTROL" />
    <uses-permission android:name="android.permission.WAKE_LOCK" />
    
    <!-- Разрешения для Android 14 (API 34) -->
    <uses-permission android:name="android.permission.FOREGROUND_SERVICE_MEDIA_PROJECTION" />
    <uses-permission android:name="android.permission.FOREGROUND_SERVICE_MEDIA_PLAYBACK" />
    <uses-permission android:name="android.permission.FOREGROUND_SERVICE_DATA_SYNC" />
    <uses-permission android:name="android.permission.START_FOREGROUND_SERVICES_FROM_BACKGROUND" />

    <application
        android:allowBackup="true"
        android:icon="@mipmap/ic_launcher"
        android:label="VLQ Audio Processor"
        android:theme="@style/Theme.MaterialComponents.Light.NoActionBar"
        android:usesCleartextTraffic="true"
        android:hardwareAccelerated="true"
        android:largeHeap="true"
        tools:targetApi="34">

        <activity
            android:name=".MainActivity"
            android:exported="true"
            android:launchMode="singleTask"
            android:screenOrientation="portrait"
            android:enableOnBackInvokedCallback="true">
            <intent-filter>
                <action android:name="android.intent.action.MAIN" />
                <category android:name="android.intent.category.LAUNCHER" />
            </intent-filter>
        </activity>

        <service
            android:name=".AudioProcessingService"
            android:enabled="true"
            android:exported="false"
            android:foregroundServiceType="mediaProjection|mediaPlayback|dataSync">
            <intent-filter>
                <action android:name="android.media.browse.MediaBrowserService" />
            </intent-filter>
        </service>

        <receiver 
            android:name="androidx.media.session.MediaButtonReceiver"
            android:exported="false">
            <intent-filter>
                <action android:name="android.intent.action.MEDIA_BUTTON" />
            </intent-filter>
        </receiver>

    </application>

    <uses-feature 
        android:name="android.hardware.audio.output" 
        android:required="true" />
    <uses-feature 
        android:name="android.hardware.microphone" 
        android:required="true" />
    <uses-feature 
        android:name="android.hardware.audio.low_latency" 
        android:required="false" />
    <uses-feature 
        android:name="android.hardware.bluetooth"
        android:required="false" />

</manifest>

И

plugins {
    id 'com.android.application'
}

android {
    namespace 'com.vlq.audioprocessor'
    compileSdk 34 // Обновляем до последней версии

    defaultConfig {
        applicationId "com.vlq.audioprocessor"
        minSdk 30
        targetSdk 34 // Обновляем таргет
        versionCode 1
        versionName "1.0"
        
        ndk {
            abiFilters 'armeabi-v7a', 'arm64-v8a', 'x86', 'x86_64'
        }
    }

    buildTypes {
        release {
            minifyEnabled true
            shrinkResources true
            proguardFiles getDefaultProguardFile('proguard-android-optimize.txt'), 'proguard-rules.pro'
        }
        debug {
            minifyEnabled false
            debuggable true
        }
    }

    compileOptions {
        sourceCompatibility JavaVersion.VERSION_17
        targetCompatibility JavaVersion.VERSION_17
    }

    buildFeatures {
        viewBinding true
    }
}

dependencies {
    implementation 'androidx.appcompat:appcompat:1.6.1'
    implementation 'com.google.android.material:material:1.11.0'
    implementation 'androidx.webkit:webkit:1.8.0'
    implementation 'androidx.media:media:1.7.0'
    implementation 'androidx.viewpager2:viewpager2:1.0.0'
    implementation 'androidx.window:window:1.2.0'
    implementation 'androidx.media2:media2-session:1.2.1'
    implementation 'androidx.collection:collection:1.3.0'
}